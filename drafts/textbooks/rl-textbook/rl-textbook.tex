\documentclass[12pt]{memoir}

\usepackage{geometry} 					% поля страницы

\usepackage{cmap}                       % Поддержка поиска русских слов в PDF (pdflatex)
\usepackage[T2A]{fontenc}				% Поддержка русских букв
\usepackage[utf8]{inputenc}            	% Выбор языка и кодировки
\usepackage[english, russian]{babel}	% Языки: русский, английский

\usepackage[unicode]{hyperref}			% Русский язык для оглавления pdf
\usepackage{bookmark}					% Оглавление в pdf
\usepackage{graphicx} 					% Подключаем пакет работы с графикой
\usepackage{memhfixc}

\usepackage{amsmath,amssymb}

\usepackage{csquotes}

\graphicspath{{../../../images/}} 			% Пути к изображениям

\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}	% Геомтерия страницы

\usepackage[
	%	autolang=hyphen,
	language=auto,
	autolang=other,
	backend=biber,
	style=gost-numeric
]{biblatex}
\addbibresource{rl.bib}

\DeclareSourcemap{
	\maps[datatype=bibtex, overwrite]{
		\map{
			\step[fieldset=langid, fieldvalue=english]
			\step[fieldset=doi, null]
			\step[fieldset=issn, null]
			\step[fieldset=isbn, null]
			\step[fieldset=url, null]
			\step[fieldsource=language, fieldset=langid, origfieldval]
		}
	}
}

\let\cleardoublepage\clearpage

\begin{document}
	\pagestyle{empty}
		\begin{center}
			{\bfseries  Министерство науки и высшего образования Российский Федерации \\
				Московский физико-технический институт\\
				(государственный университет)
				
			}

			\vspace{-5pt}
			\noindent\rule{\textwidth}{2pt}
			
			\vspace{50pt}
			{\Large\bfseries А.\,И.~Панов}
			
			\vspace{100pt}
			{\Huge\bfseries Методы и алгоритмы машинного обучения с подкреплением}
			
			\vspace{20pt}
			{\Large\itshape Учебно-методическое пособие}
			
			\vfill
			{\bfseries Москва\\
				МФТИ\\
				2018
			}
		\end{center}

	
	\frontmatter
	
	В пособии рассмотрены основные 
	
	\clearpage
	\tableofcontents %% содержание
		
	\mainmatter
	
	\chapter*{Введение}
	\addcontentsline{toc}{chapter}{Введение}
	Обучение с подкрепление (reinforcement learning, RL) является разделом машинного обучения, активно развивающимся направлением в искусственном интеллекте. Несмотря на то, что формально обучение с подкреплением относится к разделу приобретения знаний, оно кардинально отличается от таких методов, как обучение с учителем или без учителя. В первую очередь, здесь явно выделен субъект приобретения знаний (агент), который принимает решения и некоторым образом влияет на источник анализируемых данных (среду). Эта агентная постановка очень близка по своей методологии к одному из определений искусственного интеллекта, который давали одни из основоположников искусственного интеллекта Рассел и Норвиг \cite{AIBook2006}:
	\begin{displayquote}
		\textit{Искусственный интеллект --- это наука об <<интеллектуальных агентах>>, т.е. о некотором устройстве или программе, которая воспринимает свою среду и выполняет действия, которые максимизируют ее шансы на успех при достижении какой-то цели.}
	\end{displayquote}

	Наличие у агента некоторого набора возможных способов воздействия на среду (действий) и его стремления достигнуть некоторой поставленной заранее цели в этой среде позволяют естественным образом применять обучение с подкреплением в более сложных интеллектуальных системах, которые разрабатываются для синтеза целенаправленного поведения: в интеллектуальных динамических системах и в частности в робототехнике \cite{Osipov2011}. В обучении с подкреплением наиболее тесно переплетаются методы планирования поведения, представления и приобретения знаний. В настоящее время именно подсистемы, реализующие методы обучения с подкреплением, становятся центральными элементами комплексных систем управления поведением автономных объектов, взамен ранее занимавших главенствующую позицию подсистем представления знаний. Таким образом, наблюдается переход от более статичных когнитивных архитектур (например, Soar \cite{Laird2012}), к более активным обучающимся архитектурам (например, знаковым \cite{Osipov2018a}).
	 
	Успехи в развитии методов обучения с подкреплением возродили интерес к разработке агентов, действующих в искусственных средах, в том числе игровых. Были разработаны обучающиеся агенты, демонстрирующие иногда результаты, превосходящие уровень человека, для сред компьютерных игр (Atari \cite{Mnih2013}, DOOM \cite{For2017}, Starcraft \cite{Vinyals2017}, Minecraft \cite{Oh2016}), так и для более серьезных, приближенных к условиям, в которых действуют люди в реальной жизни (Go \cite{Silver2016}, OpenAI Universe\footnote{\url{https://blog.openai.com/universe/}}). Демонстрируемые успехи, понятные и знакомые даже далеким от искусственного интеллекта людям, породили большую волну новых исследований и сейчас секции по обучению с подкреплением занимают самую большую часть научных конференций (ICML, NIPS, IJCAI).
	
	Настоящее учебное пособие призвано дать краткий обзор современных подходов в обучении с подкреплением и является сжатым описанием основных алгоритмов, в том числе тех, которые появились буквально в последние несколько лет. Все подходы распределены на группы (обучения с моделью, по стратегиям и т.п.), каждой выделена отдельная глава. Границы между этими группами зачастую условным и некоторые подходы могут быть отнесены сразу к нескольким направлениям. Так как обучение с подкреплением развивается очень динамично и каждый день появляются новые работы, настоящий обзор не может быть полным. Особое внимание уделено перспективному обучению с подкреплением и некоторым нейрофизиологическим и психологическим обоснованиям.
	
	В подготовке этого пособия были использованы материалы больших монографий по обучению с подкреплением, которые могут служить основной дополнительной лит литературой: книга одних из основоположников этого направления Саттона и Барто \cite{Sutton2011}, краткий обзор Жепешвари \cite{Szepesvari2010} и ряд Интернет ресурсов \footnote{блог Массимиалано Патачола \url{https://mpatacchiola.github.io/blog/2016/12/09/dissecting-reinforcement-learning.html}, курс Школа Яндекса \url{https://github.com/yandexdataschool/Practical\_RL}, блог Мустафы Алзантота \url{https://medium.com/@m.alzantot/deep-reinforcement-learning-demystified-episode-0-2198c05a6124}.}.
	
	В качестве короткой исторической справки необходимо отметить, что идеи, лежащие в основе современной теории обучения с подкреплением, высказывались еще на первых этапах становления искусственного интеллекта с 60-х гг. XX в. (отечественные работы по автоматам Цетлина и Стефанюка \cite{Stefanuk2004}, зарубежные инженерные работы Вальц и Фу и др.\cite{Waltz1965}) и были заимствованы из области психологии, где еще с начала XX в. существовало понятие обусловленности поведения и условных рефлексов (Павлов, Скиннер).
	
	\chapter{Основные понятия}
		\section{Марковский процесс принятия решений}
			
		
		\section{Динамическое программирование}
	
		\section{Методы Монте-Карло}
		
		\section{Q-обучение}
	
	\chapter{Приближенные методы}
		\section{Предсказание с изменением стратегии}
		
		\section{Предсказание без изменения стратегии}
		
		\section{Нейронные сети как аппроксиматоры}
	
	\chapter{Перспективные направления}
	
		\section{Иерархическое обучение с подкреплением}
			\subsection{Иерархия действий: Options}
			
			\subsection{Иерархия автоматов: HAM}
			
			\subsection{Оптимизация функции оценки: MaxQ}
			
			\subsection{Автоматическое формирование иерархий}
		\section{Внутренняя мотивация}
		
	
	\chapter{Обучение с подкреплением и другие науки}

		\section{Психология}
		
		\section{Нейрофизиология}

		\section{Робототехника}
	

	\chapter*{Заключение}
	\addcontentsline{toc}{chapter}{Заключение}
	Немного о целях
	\printbibliography
\end{document}