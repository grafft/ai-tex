Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Sun2006,
abstract = {This paper describes how meta-cognitive processes (i.e., the self monitoring and regulating of cognitive processes) may be captured within a cognitive architecture Clarion. Some currently popular cognitive architectures lack sufficiently complex built-in meta-cognitive mechanisms. However, a sufficiently complex meta-cognitive mechanism is important, in that it is an essential part of cognition and without it, human cognition may not function properly. We contend that such a meta-cognitive mechanism should be an integral part of a cognitive architecture. Thus, such a mechanism has been developed within the Clarion cognitive architecture. The paper demonstrates how human data of two meta-cognitive experiments are simulated using Clarion. The simulations show that the meta-cognitive processes represented by the experimental data (and beyond) can be adequately captured within the Clarion framework. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi and Mathews, Robert},
doi = {10.1016/j.cogsys.2005.09.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Sun, Zhang, Mathews/Sun, Zhang, Mathews - 2006 - Modeling meta-cognition in a cognitive architecture.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive modeling,Metacognition,Neural networks},
number = {4},
pages = {327--338},
title = {{Modeling meta-cognition in a cognitive architecture}},
volume = {7},
year = {2006}
}
@article{Merrick2017,
abstract = {This paper surveys value systems for developmental cognitive robotics. A value system permits a biological brain to increase the likelihood of neural responses to selected external phenomena. Many machine learning algorithms capture the essence of this learning process. However, computational value systems aim not only to support learning, but also autonomous attention focus to direct learning. This combination of unsupervised attention focus and learning aims to address the grand challenge of autonomous mental development for machines. This survey examines existing value systems for developmental cognitive robotics in this context. We examine the definitions of value used???including recent pioneering work in intrinsic motivation as value???as well as initialisation strategies for innate values, update strategies for acquired value and the data structures used for storing value. We examine the extent to which existing value systems support attention focus, learning and prediction in an unsupervised setting. The types of robots and applications in which these value systems are used are also examined, as well as the ways that these applications are evaluated. Finally, we study the strengths and limitations of current value systems for developmental cognitive robots and conclude with a set of research challenges for this field.},
author = {Merrick, Kathryn},
doi = {10.1016/j.cogsys.2016.08.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Merrick/Merrick - 2017 - Value systems for developmental cognitive robotics A survey.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognition,Developmental systems,Intrinsic motivation,Robotics,Value systems},
pages = {38--55},
publisher = {Elsevier B.V.},
title = {{Value systems for developmental cognitive robotics: A survey}},
url = {http://dx.doi.org/10.1016/j.cogsys.2016.08.001},
volume = {41},
year = {2017}
}
@article{Frintrop2010,
author = {Frintrop, Simone and Rome, Erich and Christensen, Henrik I.},
doi = {10.1145/1658349.1658355},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/ACM Transactions on Applied Perception/Frintrop, Rome, Christensen/Frintrop, Rome, Christensen - 2010 - Computational visual attention systems and their cognitive foundations.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
number = {1},
pages = {1--39},
title = {{Computational visual attention systems and their cognitive foundations}},
url = {http://portal.acm.org/citation.cfm?doid=1658349.1658355},
volume = {7},
year = {2010}
}
@article{2010b,
author = {Кулинич, Александр},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Проблемы Управления/Кулинич/Кулинич - 2010 - Компьютерные системы моделирования когнитивных карт подходы и методы.pdf:pdf},
journal = {Проблемы Управления},
language = {russian},
pages = {2 -- 16},
title = {{Компьютерные системы моделирования когнитивных карт: подходы и методы}},
url = {https://m.cyberleninka.ru/article/n/kompyuternye-sistemy-modelirovaniya-kognitivnyh-kart-podhody-i-metody},
volume = {№3},
year = {2010}
}
@article{Fu2014a,
author = {Fu, XiaoLan and Cai, LianHong and Liu, Ye YongJin and Jia, Jia and Chen, WenFeng and Yi, Zhang and Zhao, GuoZhen and Liu, Ye YongJin and Wu, ChangXu},
doi = {10.1007/s11432-013-4911-9},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Science China Information Sciences/Fu et al/Fu et al. - 2014 - A computational cognition model of perception, memory, and judgment.pdf:pdf},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {computational cognition model,judgment,memory,perception},
language = {english},
number = {3},
pages = {1--15},
title = {{A computational cognition model of perception, memory, and judgment}},
url = {http://link.springer.com/10.1007/s11432-013-4911-9},
volume = {57},
year = {2014}
}
@article{Schneider1999,
abstract = {This paper addresses the issue of how visual-spatial working memory, attention, and scene representation are related. The first section introduces a modified two-stage conception of visual-spatial processing. "Stage one" refers to low-level visual-spatial processing and computes in parallel for the currently available retinal information "object candidates," here called "visual-spatial units." An attentional process called "unit selection" allows access to stage two for one of these units at a time. Stage two contains high-level visual-spatial information that can be used for goal-directions (e.g., verbal report, grasping). It consists of three parallel processing streams. First, the currently selected unit is recognized; second, a spatial-motor program for the selected unit is computed; and third, an "object file" is set up for the selected unit. An object file contains temporary episodic representations of detailed high-level visual-spatial attributes of an "object" plus an "index." An index acts as a pointer and is bound via temporary connections to the attributes of the file. Section two of this paper specifies one part of stage two in more detail, namely visual-spatial working memory (VSWM). It can contain up to four object files. A first central claim is that during sensory-based processing for working memory ("access"), one object file is always "on-line," and up to three other object files are "off-line". A second central claim is that the process of setting up an object file depends on the number and the activation level of already stored files. Based on the concept of activation-based competition between object files, it is postulated that the more files that are stored and the higher their activation is, the longer it takes for a newly set up object file to reach a sufficient level of activation. Activation-based competition is also used to explain "short-term forgetting" by "interference." A third central claim about VSWM is that a "refreshment" process exists that increases the activation level of an index of an object file in order to prevent forgetting or in order to bring the file back to the state of controlling the current action. Finally, section three gives a selective look at a number of experimental data such as the attentional blink, backward masking, dwell time effects, transsaccadic memory, and change blindness. New explanations are offered and new predictions made.},
author = {Schneider, W X},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Psychological research/Schneider/Schneider - 1999 - Visual-spatial working memory, attention, and scene representation a neuro-cognitive theory.pdf:pdf},
issn = {0340-0727},
journal = {Psychological research},
keywords = {Attention,Attention: physiology,Cognitive Science,Humans,Memory,Models,Perceptual Masking,Psychological,Psychophysics,Short-Term,Short-Term: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
number = {2-3},
pages = {220--36},
pmid = {10472201},
title = {{Visual-spatial working memory, attention, and scene representation: a neuro-cognitive theory}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10472201},
volume = {62},
year = {1999}
}
@article{Pulvermuller2010,
abstract = {Action and perception are functionally linked in the brain, but a hotly debated question is whether perception and comprehension of stimuli depend on motor circuits. Brain language mechanisms are ideal for addressing this question. Neuroimaging investigations have found specific motor activations when subjects understand speech sounds, word meanings and sentence structures. Moreover, studies involving transcranial magnetic stimulation and patients with lesions affecting inferior frontal regions of the brain have shown contributions of motor circuits to the comprehension of phonemes, semantic categories and grammar. These data show that language comprehension benefits from frontocentral action systems, indicating that action and perception circuits are interdependent.},
author = {Pulverm{\"{u}}ller, Friedemann and Fadiga, Luciano},
doi = {10.1038/nrn2811},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Nature reviews. Neuroscience/Pulverm{\"{u}}ller, Fadiga/Pulverm{\"{u}}ller, Fadiga - 2010 - Active perception sensorimotor circuits as a cortical basis for language.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Language,Neural Pathways,Neural Pathways: physiology,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology},
number = {5},
pages = {351--360},
pmid = {20383203},
publisher = {Nature Publishing Group},
title = {{Active perception: sensorimotor circuits as a cortical basis for language.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20383203{\%}5Cnhttp://dx.doi.org/10.1038/nrn2811},
volume = {11},
year = {2010}
}
@article{Sergin2008,
author = {Sergin, A. V. and Sergin, V. Ya.},
journal = {Neural Network World},
number = {3},
pages = {227--244},
title = {{Model of perception: The hierarchy of inclusive sensory characteristics and top-down cascade transfer of excitation}},
volume = {18},
year = {2008}
}
@article{Taatgen2005,
abstract = {Emerging parallel processing and increased flexibility during the acquisition of cognitive skills form a combination that is hard to reconcile with rule-based models that often produce brittle behavior. Rule-based models can exhibit these properties by adhering to 2 principles: that the model gradually learns task-specific rules from instructions and experience, and that bottom-up processing is used whenever possible. In a model of learning perfect time-sharing in dual tasks (Schumacher et al., 2001), speedup learning and bottom-up activation of instructions can explain parallel behavior. In a model of a complex dynamic task (Carnegie Mellon University Aegis Simulation Program [CMU-ASP], Anderson et al., 2004), parallel behavior is explained by the transition from serially organized instructions to rules that are activated by both top-down (goal-driven) and bottom-up (perceptually driven) factors. Parallelism lets the model opportunistically reorder instructions, leading to the gradual emergence of new task strategies.},
author = {Taatgen, Niels},
doi = {10.1207/s15516709cog0000_23},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive science/Taatgen/Taatgen - 2005 - Modeling parallelization and flexibility improvements in skill acquisition from dual tasks to complex dynamic skills.pdf:pdf},
isbn = {0364-0213},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {cognitive architecture,complex systems,computer,dual tasking,human,instruction,interaction,knowledge,learning,psychology,representation,situated cognition,skill acquisition and learning,symbolic computational modeling},
number = {3},
pages = {421--455},
pmid = {21702780},
title = {{Modeling parallelization and flexibility improvements in skill acquisition: from dual tasks to complex dynamic skills}},
volume = {29},
year = {2005}
}
@article{Samsonovich2005,
abstract = {We start by assuming that the self is implemented in the brain as a functional unit, with a definite set of properties. We deduce the fundamental properties of the self from an analysis of neurological disorders and from introspection. We formulate a functionalist concept of the self based on these properties reduced to constraints. We use the formalism of schemas in our functionalist analysis, i.e. a symbolic level description of brain dynamics. We then reformulate the functionalist model at a connectionist level and address the emergent "context shifting" problem. We suggest how the model might be mapped onto the functional neuroanatomy of the brain, and how it could be used to give an account of a range of neurological disorders, including hippocampal amnesia, various forms of schizophrenia, multiple personality, autism, PTSD, hemineglect, and reversible anosognosia. Finally, we briefly discuss future perspectives and possible applications of computer implementations of the model.},
author = {Samsonovich, Alexei V. and Nadel, Lynn},
doi = {10.1016/S0010-9452(08)70284-3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cortex/Samsonovich, Nadel/Samsonovich, Nadel - 2005 - Fundamental Principles and Mechanisms of the Conscious Self.pdf:pdf},
isbn = {0010-9452 (Print)},
issn = {00109452},
journal = {Cortex},
keywords = {contextual reinstatement,episodic memory,hippocampus},
number = {5},
pages = {669--689},
pmid = {16209330},
title = {{Fundamental Principles and Mechanisms of the Conscious Self}},
volume = {41},
year = {2005}
}
@article{Chersi2014,
abstract = {A growing body of evidence in cognitive psychology and neuroscience suggests a deep interconnection between sensory-motor and language systems in the brain. Based on recent neurophysiological findings on the anatomo-functional organization of the fronto-parietal network, we present a computational model showing that language processing may have reused or co-developed organizing principles, functionality, and learning mechanisms typical of premotor circuit. The proposed model combines principles of Hebbian topological self-organization and prediction learning. Trained on sequences of either motor or linguistic units, the network develops independent neuronal chains, formed by dedicated nodes encoding only context-specific stimuli. Moreover, neurons responding to the same stimulus or class of stimuli tend to cluster together to form topologically connected areas similar to those observed in the brain cortex. Simulations support a unitary explanatory framework reconciling neurophysiological motor data with established behavioral evidence on lexical acquisition, access, and recall.},
author = {Chersi, Fabian and Ferro, Marcello and Pezzulo, Giovanni and Pirrelli, Vito},
doi = {10.1111/tops.12094},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Topics in cognitive science/Chersi et al/Chersi et al. - 2014 - Topological self-organization and prediction learning support both action and lexical chains in the brain.pdf:pdf},
issn = {1756-8765},
journal = {Topics in cognitive science},
keywords = {computational modeling,lexical chains,motor chains,prediction,self-organizing maps,serial working memory,somatotopic organization},
number = {3},
pages = {476--91},
pmid = {24935737},
title = {{Topological self-organization and prediction learning support both action and lexical chains in the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24935737},
volume = {6},
year = {2014}
}
@article{Dipoppa2013,
abstract = {Cognitive effort leads to a seeming cacophony of brain oscillations. For example, during tasks engaging working memory (WM), specific oscillatory frequency bands modulate in space and time. Despite ample data correlating such modulation to task performance, a mechanistic explanation remains elusive. We propose that flexible control of neural oscillations provides a unified mechanism for the rapid and controlled transitions between the computational operations required by WM. We show in a spiking network model that modulating the input oscillation frequency sets the network in different operating modes: rapid memory access and load is enabled by the beta-gamma oscillations, maintaining a memory while ignoring distractors by the theta, rapid memory clearance by the alpha. The various frequency bands determine the dynamic gating regimes enabling the necessary operations for WM, whose succession explains the need for the complex oscillatory brain dynamics during effortful cognition.},
author = {Dipoppa, Mario and Gutkin, Boris S},
doi = {10.1073/pnas.1303270110},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Dipoppa, Gutkin/Dipoppa, Gutkin - 2013 - Flexible frequency control of cortical oscillations enables computations required for w.pdf:pdf},
isbn = {1303270110},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Biological Clocks,Biological Clocks: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Humans,Memory,Memory: physiology,Models, Neurological,Neurons,Neurons: physiology},
number = {31},
pages = {12828--33},
pmid = {23858465},
title = {{Flexible frequency control of cortical oscillations enables computations required for working memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3732977{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2013}
}
@article{Crawford2016,
author = {Crawford, Eric and Gingerich, Matthew and Eliasmith, Chris},
doi = {10.1111/cogs.12261},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Crawford, Gingerich, Eliasmith/Crawford, Gingerich, Eliasmith - 2016 - Biologically Plausible, Human-Scale Knowledge Representation.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {biologically plausible,connectionism,knowledge representation,neural network,scaling,vector symbolic architecture,wordnet},
number = {4},
pages = {782--821},
pmid = {26173464},
title = {{Biologically Plausible, Human-Scale Knowledge Representation}},
url = {http://doi.wiley.com/10.1111/cogs.12261},
volume = {40},
year = {2016}
}
@article{Parkhurst2002,
abstract = {A biologically motivated computational model of bottom-up visual selective attention was used to examine the degree to which stimulus salience guides the allocation of attention. Human eye movements were recorded while participants viewed a series of digitized images of complex natural and artificial scenes. Stimulus dependence of attention, as measured by the correlation between computed stimulus salience and fixation locations, was found to be significantly greater than that expected by chance alone and furthermore was greatest for eye movements that immediately follow stimulus onset. The ability to guide attention of three modeled stimulus features (color, intensity and orientation) was examined and found to vary with image type. Additionally, the effect of the drop in visual sensitivity as a function of eccentricity on stimulus salience was examined, modeled, and shown to be an important determiner of attentional allocation. Overall, the results indicate that stimulus-driven, bottom-up mechanisms contribute significantly to attentional guidance under natural viewing conditions.},
author = {Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Vision research/Parkhurst, Law, Niebur/Parkhurst, Law, Niebur - 2002 - Modeling the role of salience in the allocation of overt visual attention.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Analysis of Variance,Attention,Attention: physiology,Biological,Computer Simulation,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Models,Normal Distribution,Visual Perception,Visual Perception: physiology},
number = {1},
pages = {107--23},
pmid = {11804636},
title = {{Modeling the role of salience in the allocation of overt visual attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11804636},
volume = {42},
year = {2002}
}
@article{Sokolov2004,
author = {Соколов, Е. Н.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Психология. Журнал Высшей школы экономики/Соколов/Соколов - 2004 - Нейроны сознания.pdf:pdf},
journal = {Психология. Журнал Высшей школы экономики},
language = {russian},
number = {2},
pages = {3--15},
title = {{Нейроны сознания}},
volume = {1},
year = {2004}
}
@article{Pezzulo2014,
abstract = {A network of brain structures including hippocampus (HC), prefrontal cortex, and striatum controls goal-directed behavior and decision making. However, the neural mechanisms underlying these functions are unknown. Here, we review the role of 'internally generated sequences': structured, multi-neuron firing patterns in the network that are not confined to signaling the current state or location of an agent, but are generated on the basis of internal brain dynamics. Neurophysiological studies suggest that such sequences fulfill functions in memory consolidation, augmentation of representations, internal simulation, and recombination of acquired information. Using computational modeling, we propose that internally generated sequences may be productively considered a component of goal-directed decision systems, implementing a sampling-based inference engine that optimizes goal acquisition at multiple timescales of on-line choice, action control, and learning. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {Pezzulo, Giovanni and van der Meer, Matthijs a a and Lansink, Carien S. and Pennartz, Cyriel M a},
doi = {10.1016/j.tics.2014.06.011},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in Cognitive Sciences/Pezzulo et al/Pezzulo et al. - 2014 - Internally generated sequences in learning and executing goal-directed behavior.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {decision making,forward sweep,generative models,hippocampus,inference,prospection,reinforcement learning,replay,spatial navigation,theta rhythm,ventral striatum},
number = {12},
pages = {647--657},
pmid = {25156191},
publisher = {Elsevier Ltd},
title = {{Internally generated sequences in learning and executing goal-directed behavior}},
url = {http://dx.doi.org/10.1016/j.tics.2014.06.011},
volume = {18},
year = {2014}
}
@article{Sun2004,
abstract = {This paper explores the interaction between implicit and explicit processes during skill learning, in terms of top-down learning (that is, learning that goes from explicit to implicit knowledge) versus bottom-up learning (that is, learning that goes from implicit to explicit knowledge). Instead of studying each type of knowledge (implicit or explicit) in isolation, we stress the interaction between the two types, especially in terms of one type giving rise to the other, and its effects on learning. The work presents an integrated model of skill learning that takes into account both implicit and explicit processes and both top-down and bottom-up learning. We examine and simulate human data in the Tower of Hanoi task. The paper shows how the quantitative data in this task may be captured using either top-down or bottom-up approaches, although top-down learning is a more apt explanation of the human data currently available. These results illustrate the two different directions of learning (top-down versus bottom-up), and thereby provide a new perspective on skill learning. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi},
doi = {10.1016/j.cogsys.2003.07.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Sun, Zhang/Sun, Zhang - 2004 - Top-down versus bottom-up learning in cognitive skill acquisition.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
pages = {63--89},
title = {{Top-down versus bottom-up learning in cognitive skill acquisition}},
volume = {5},
year = {2004}
}
@article{Chernavsky2012c,
abstract = {Рассматривается одна из возможных схем нейропроцессорной конструкции, способной решать задачи, традиционно относимые к мышлению и творчеству. Выделена подсистема, обрабатывающая образную информацию; ее важная составляющая — ―размытое множество‖, содержащее всю образную информацию, доступную системе. Выделена подсистема, способная решать логические задачи. Подсистема распознавания процесса и построения прогноза позволяет ввести понятие континуального времени. Показано, что решение творческих задач (при недостатке информации или противоречивости алгоритмов) в символьной подсистеме невозможно и требует обращения к размытому (образному) множеству.},
author = {Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А. and Чернавская, О. Д.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Сложные системы/Чернавский et al/Чернавский et al. - 2012 - Процесс мышления в контексте динамической теории информации. Часть III один из вариантов конструкции нейропро.pdf:pdf},
journal = {Сложные системы},
keywords = {мышление,научное творчество,нейропроцессор,самоорганизация,символьная система},
language = {russian},
number = {4},
pages = {25--37},
title = {{Процесс мышления в контексте динамической теории информации. Часть III: один из вариантов конструкции нейропроцессоров для моделирования процесса мышления}},
volume = {3},
year = {2012}
}
@article{Wang2012,
abstract = {In this review, I briefly summarize current neurobiological studies of decision-making that bear on two general themes. The first focuses on the nature of neural representation and dynamics in a decision circuit. Experimental and computational results suggest that ramping-to-threshold in the temporal domain and trajectory of population activity in the state space represent a duality of perspectives on a decision process. Moreover, a decision circuit can display several different dynamical regimes, such as the ramping mode and the jumping mode with distinct defining properties. The second is concerned with the relationship between biologically-based mechanistic models and normative-type models. A fruitful interplay between experiments and these models at different levels of abstraction have enabled investigators to pose increasingly refined questions and gain new insights into the neural basis of decision-making. In particular, recent work on multi-alternative decisions suggests that deviations from rational models of choice behavior can be explained by established neural mechanisms. ?? 2012 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Wang, Xiao Jing},
doi = {10.1016/j.conb.2012.08.006},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Current Opinion in Neurobiology/Wang/Wang - 2012 - Neural dynamics and circuit mechanisms of decision-making.pdf:pdf},
isbn = {1873-6882 (Electronic)$\backslash$r0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {1039--1046},
pmid = {23026743},
publisher = {Elsevier Ltd},
title = {{Neural dynamics and circuit mechanisms of decision-making}},
url = {http://dx.doi.org/10.1016/j.conb.2012.08.006},
volume = {22},
year = {2012}
}
@article{Zendehrouh2015,
author = {Zendehrouh, Sareh},
doi = {10.1016/j.neunet.2015.08.006},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural Networks/Zendehrouh/Zendehrouh - 2015 - A new computational account of cognitive control over reinforcement-based decision-making Modeling of a probabilisti.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {112--123},
publisher = {Elsevier Ltd},
title = {{A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608015001604},
volume = {71},
year = {2015}
}
@article{Stankevich2006,
author = {Станкевич, Л. А. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Труды СПИИРАН/Станкевич, Серебряков/Станкевич, Серебряков - 2006 - Когнитивные системы и агенты.pdf:pdf},
journal = {Труды СПИИРАН},
language = {russian},
number = {3},
pages = {71--87},
title = {{Когнитивные системы и агенты}},
volume = {1},
year = {2006}
}
@article{Sandamirskaya2013,
abstract = {Dynamic Field Theory (DFT) is an established framework for modeling embodied cognition. In DFT, elementary cognitive functions such as memory formation, formation of grounded representations, attentional processes, decision making, adaptation, and learning emerge from neuronal dynamics. The basic computational element of this framework is a Dynamic Neural Field (DNF). Under constraints on the time-scale of the dynamics, the DNF is computationally equivalent to a soft winner-take-all (WTA) network, which is considered one of the basic computational units in neuronal processing. Recently, it has been shown how a WTA network may be implemented in neuromorphic hardware, such as analog Very Large Scale Integration (VLSI) device. This paper leverages the relationship between DFT and soft WTA networks to systematically revise and integrate established DFT mechanisms that have previously been spread among different architectures. In addition, I also identify some novel computational and architectural mechanisms of DFT which may be implemented in neuromorphic VLSI devices using WTA networks as an intermediate computational layer. These specific mechanisms include the stabilization of working memory, the coupling of sensory systems to motor dynamics, intentionality, and autonomous learning. I further demonstrate how all these elements may be integrated into a unified architecture to generate behavior and autonomous learning.},
author = {Sandamirskaya, Yulia},
doi = {10.3389/fnins.2013.00276},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Frontiers in neuroscience/Sandamirskaya/Sandamirskaya - 2014 - Dynamic neural fields as a step toward cognitive neuromorphic architectures.pdf:pdf},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {Dynamic Neural Fields,autonomous learning,cognitive neuromorphic architecture,neural dynamics,soft winner take all},
pages = {276},
pmid = {24478620},
title = {{Dynamic neural fields as a step toward cognitive neuromorphic architectures}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnins.2013.00276/abstract{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3898057/},
volume = {7},
year = {2014}
}
@article{Karpov2014,
author = {Карпов, В. Э.},
doi = {10.7868/S0002338814050096},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Известия РАН. Теория и системы управления/Карпов/Карпов - 2014 - Эмоции и темперамент роботов. Поведенческие аспекты.pdf:pdf},
issn = {0002-3388},
journal = {Известия РАН. Теория и системы управления},
language = {russian},
number = {5},
pages = {166--185},
title = {{Эмоции и темперамент роботов. Поведенческие аспекты}},
year = {2014}
}
@phdthesis{Rasmussen2014,
author = {Rasmussen, Daniel},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Rasmussen/Rasmussen - 2014 - Hierarchical reinforcement learning in a biologically plausible neural architecture.pdf:pdf},
pages = {175},
school = {Unversetu of Waterloo},
title = {{Hierarchical reinforcement learning in a biologically plausible neural architecture}},
year = {2014}
}
@article{DeWolf2016,
abstract = {We present a spiking neuron model of the motor cortices and cerebellum of the motor control system. The model consists of anatomically organized spiking neurons encompassing premotor, primary motor, and cerebellar cortices. The model proposes novel neural computations within these areas to control a nonlinear three-link arm model that can adapt to unknown changes in arm dynamics and kinematic structure. We demonstrate the mathematical stability of both forms of adaptation, suggesting that this is a robust approach for common biological problems of changing body size (e.g. during growth), and unexpected dynamic perturbations (e.g. when moving through different media, such as water or mud). To demonstrate the plausibility of the proposed neural mechanisms, we show that the model accounts for data across 19 studies of the motor control system. These data include a mix of behavioural and neural spiking activity, across subjects performing adaptive and static tasks. Given this proposed characterization of the biological processes involved in motor control of the arm, we provide several experimentally testable predictions that distinguish our model from previous work.},
author = {DeWolf, Travis and Stewart, Terrence C. and Slotine, Jean-Jacques and Eliasmith, Chris},
doi = {10.1098/rspb.2016.2134},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Royal Society B Biological Sciences/DeWolf et al/DeWolf et al. - 2016 - A spiking neural model of adaptive arm control.pdf:pdf},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {computational biology,neuroscience},
month = {nov},
number = {1843},
pages = {20162134},
pmid = {27903878},
title = {{A spiking neural model of adaptive arm control}},
url = {http://rspb.royalsocietypublishing.org/lookup/doi/10.1098/rspb.2016.2134},
volume = {283},
year = {2016}
}
@article{Konovalov,
author = {Konovalov, Arkady and Hu, Jie and Ruff, Christian C},
doi = {10.1016/j.copsyc.2018.04.009},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Current Opinion in Psychology/Konovalov, Hu, Ruff/Konovalov, Hu, Ruff - Unknown - ScienceDirect Neurocomputational approaches to social behavior.pdf:pdf},
issn = {2352-250X},
journal = {Current Opinion in Psychology},
pages = {41--47},
publisher = {Elsevier Ltd},
title = {{ScienceDirect Neurocomputational approaches to social behavior}},
url = {https://doi.org/10.1016/j.copsyc.2018.04.009},
volume = {24}
}
@article{Sanborn2010,
author = {Sanborn, Adam N. and Griffiths, Thomas L. and Shiffrin, Richard M.},
doi = {10.1016/j.cogpsych.2009.07.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Psychology/Sanborn, Griffiths, Shiffrin/Sanborn, Griffiths, Shiffrin - 2010 - Uncovering mental representations with Markov chain Monte Carlo.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
number = {2},
pages = {63--106},
publisher = {Elsevier Inc.},
title = {{Uncovering mental representations with Markov chain Monte Carlo}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010028509000449},
volume = {60},
year = {2010}
}
@incollection{Taylor,
author = {Taylor, Neill R. and Panchev, Christo and Hartley, Matthew and Kasderidis, Stathis and Taylor, John G.},
booktitle = {Artificial Neural Networks - ICANN 2006},
editor = {Kollias, Stefanos D. and Stafylopatis, Andreas and Duch, W{\l}odzis{\l}aw and Oja, Erkki},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Artificial Neural Networks - ICANN 2006/Taylor et al/Taylor et al. - 2006 - Occlusion , Attention and Object Representations.pdf:pdf},
pages = {592--601},
publisher = {Springer-Verlag},
title = {{Occlusion , Attention and Object Representations}},
year = {2006}
}
@article{Keramati2011a,
abstract = {Reinforcement learning models address animal's behavioral adaptation to its changing “external” environment, and are based on the assumption that Pavlo- vian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are con- cerned with behavioral adaptation in response to the “internal” state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that in- tegrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identi- cal. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.},
author = {Keramati, Mehdi and Gutkin, Boris},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Nips/Keramati, Gutkin/Keramati, Gutkin - 2011 - A Reinforcement Learning theory for homeostatic regulation.pdf:pdf},
isbn = {9781618395993},
journal = {Nips},
pages = {82--90},
title = {{A Reinforcement Learning theory for homeostatic regulation}},
year = {2011}
}
@article{Yan2014,
abstract = {The accessibility verification of the assembly/disassembly plays an important role in the process of product design. In the last decade, the sampling based motion planners have been successfully applied to solve the accessibility verification. However, the narrow passage which is a common problem in the assembly tasks is still a bottleneck. Meanwhile, the requirement of perception and emotion assessment drives the interaction between users and automatic path planners in the virtual assembly process. In this paper, a curve matching method is used to explore the implicit relationship between the topological information of scenarios and the motion of objects, based on which an interactive motion planning framework that can learn from experience is constructed. Our framework consists of two main processes: a learning process and a motion generation process. In the former process, the motion segment (a part of motion path) and its related scenario segment (a part of workspace passed through by the object) are gathered, after an interactive motion planning process finds a collision-free motion path or reaches the conclusion of inaccessibility. According to the similarity between the skeletons of scenario segments, the gathered scenario segments and motion segments are organized by a hierarchical structure in the motion library. The latter process permits users to control only one point in the workspace for the selection of a new scenario, and then the similar scenarios are retrieved from the motion library, to help quickly detect the connectivity of the new scenario and generate a repaired motion path to guide users with feasible manipulations. We highlight the performance of our framework on a challenging problem in 2D, in which a non-convex object passes through a cluttered environment filled with randomly shaped and located non-convex obstacles.},
author = {Yan, Yu and Poirson, Emilie and Bennis, Fouad},
doi = {10.1016/j.cad.2014.07.007},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Computer-Aided Design/Yan, Poirson, Bennis/Yan, Poirson, Bennis - 2014 - An interactive motion planning framework that can learn from experience.pdf:pdf},
issn = {00104485},
journal = {Computer-Aided Design},
keywords = {accessibility verification,assembly path planning},
pages = {23--38},
publisher = {Elsevier Ltd},
title = {{An interactive motion planning framework that can learn from experience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010448514001584},
volume = {59},
year = {2014}
}
@article{Borji2013,
abstract = {Modeling visual attention--particularly stimulus-driven, saliency-based attention--has been a very active research area over the past 25 years. Many different models of attention are now available which, aside from lending theoretical contributions to other fields, have demonstrated successful applications in computer vision, mobile robotics, and cognitive systems. Here we review, from a computational perspective, the basic concepts of attention implemented in these models. We present a taxonomy of nearly 65 models, which provides a critical comparison of approaches, their capabilities, and shortcomings. In particular, 13 criteria derived from behavioral and computational studies are formulated for qualitative comparison of attention models. Furthermore, we address several challenging issues with models, including biological plausibility of the computations, correlation with eye movement datasets, bottom-up and top-down dissociation, and constructing meaningful performance measures. Finally, we highlight current research trends in attention modeling and provide insights for future.},
author = {Borji, Ali and Itti, Laurent},
doi = {10.1109/TPAMI.2012.89},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE transactions on pattern analysis and machine intelligence/Borji, Itti/Borji, Itti - 2013 - State-of-the-art in visual attention modeling.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Fixation,Humans,Models,Neurological,Ocular,Ocular: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {1},
pages = {185--207},
pmid = {22487985},
title = {{State-of-the-art in visual attention modeling}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22487985},
volume = {35},
year = {2013}
}
@article{Rawlinson2012,
abstract = {The Memory-Prediction Framework (MPF) and its Hierarchical-Temporal Memory implementation (HTM) have been widely applied to unsupervised learning problems, for both classification and prediction. To date, there has been no attempt to incorporate MPF/HTM in reinforcement learning or other adaptive systems; that is, to use knowledge embodied within the hierarchy to control a system, or to generate behaviour for an agent. This problem is interesting because the human neocortex is believed to play a vital role in the generation of behaviour, and the MPF is a model of the human neocortex.We propose some simple and biologically-plausible enhancements to the Memory-Prediction Framework. These cause it to explore and interact with an external world, while trying to maximize a continuous, time-varying reward function. All behaviour is generated and controlled within the MPF hierarchy. The hierarchy develops from a random initial configuration by interaction with the world and reinforcement learning only. Among other demonstrations, we show that a 2-node hierarchy can learn to successfully play "rocks, paper, scissors" against a predictable opponent.},
author = {Rawlinson, David and Kowadlo, Gideon},
doi = {10.1371/journal.pone.0029264},
editor = {Vasilaki, Eleni},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/PloS one/Rawlinson, Kowadlo/Rawlinson, Kowadlo - 2012 - Generating adaptive behaviour within a memory-prediction framework.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Adaptation,Algorithms,Behavior,Behavior: physiology,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Models,Neocortex,Neocortex: physiology,Neurological,Pattern Recognition,Psychological,Psychological: physiology,Reinforcement (Psychology),Reward,User-Computer Interface,Visual,Visual: physiology},
number = {1},
pages = {e29264},
pmid = {22272231},
publisher = {Public Library of Science},
title = {{Generating adaptive behaviour within a memory-prediction framework}},
url = {http://dx.plos.org/10.1371/journal.pone.0029264},
volume = {7},
year = {2012}
}
@article{Caro2015,
abstract = {Metacognition has been used in artificial intelligence to increase the level of autonomy of intelligent systems. However the design of systems with metacognitive capabilities is a difficult task due to the number and complexity of processes involved. This paper presents a domain-specific visual language specifically developed for modeling metacognition in intelligent systems called M++. In M++ the specifications of the cognitive level (object-level) and metacognitive level (meta-level) are supported in a metamodel configured according to the standard Meta-Object Facility (MOF) of Model-Driven Architecture (MDA) methodology. M++ allows the generation of metacognitive diagrams in a visual editor named MetaThink. A validation process was conducted to ensure the reliability of M++ in terms of quality of the notation and consistency of generated models. The validation was performed using two techniques: (i) empirical study and (ii) model tracing. The results given in the experimental study demonstrate that M++ is a useful notation for the process of modeling metacognitive components in intelligent systems. Metacognitive models generated from the validation process using the Tracing technique were consistent with the MOF-based metamodel. M++ contribute to cognitive architecture research adding precision to metacognitive concepts and enabling cognitive architecture researchers to do fast and exploratory prototyping of metacognitive systems using MetaThink tool.},
author = {Caro, Manuel F. and Josyula, Darsana P. and Jim{\'{e}}nez, Jovani A. and Kennedy, Catriona M. and Cox, Michael T.},
doi = {10.1016/j.bica.2015.06.004},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Caro et al/Caro et al. - 2015 - A domain-specific visual language for modeling metacognition in intelligent systems.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Domain-specific visual language,Intelligent system,MOF,Metacognition,Modeling tool},
pages = {75--90},
title = {{A domain-specific visual language for modeling metacognition in intelligent systems}},
volume = {13},
year = {2015}
}
@article{Blanke2015,
abstract = {Recent work in human cognitive neuroscience has linked self-consciousness to the processing of multisen- sory bodily signals (bodily self-consciousness [BSC]) in fronto-parietal cortex and more posterior temporo- parietal regions.Wehighlight the behavioral, neurophysiological, neuroimaging, and computational laws that subtend BSCin humans and non-human primates.Wepropose thatBSCincludes body-centered perception (hand, face, and trunk), based on the integration of proprioceptive, vestibular, and visual bodily inputs, and involves spatio-temporal mechanisms integrating multisensory bodily stimuli within peripersonal space (PPS). We develop four major constraints of BSC (proprioception, body-related visual information, PPS, and embodiment) and argue that the fronto-parietal and temporo-parietal processing of trunk-centered multisensory signals in PPS is of particular relevance for theoretical models and simulations of BSC and eventually of self-consciousness.},
author = {Blanke, Olaf and Slater, Mel and Serino, Andrea},
doi = {10.1016/j.neuron.2015.09.029},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neuron/Blanke, Slater, Serino/Blanke, Slater, Serino - 2015 - Behavioral, Neural, and Computational Principles of Bodily Self-Consciousness.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {145--166},
publisher = {Elsevier Inc.},
title = {{Behavioral, Neural, and Computational Principles of Bodily Self-Consciousness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008181},
volume = {88},
year = {2015}
}
@article{Langley2009a,
abstract = {In this paper, we review Icarus, a cognitive architecture that utilizes hierarchical skills and concepts for reactive execution in physical environments. In addition, we present two extensions to the framework. The first involves the incorporation of means-ends analysis, which lets the system compose known skills to solve novel problems. The second involves the storage of new skills that are based on successful means-ends traces. We report experimental studies of these mechanisms on three distinct domains. Our results suggest that the two methods interact to acquire useful skill hierarchies that generalize well and that reduce the effort required to handle new tasks. We conclude with a discussion of related work on learning and prospects for additional research, including extending the framework to cover developmental phenomena. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Langley, Pat and Choi, Dongkyu and Rogers, Seth},
doi = {10.1016/j.cogsys.2008.07.003},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Langley, Choi, Rogers/Langley, Choi, Rogers - 2009 - Acquisition of hierarchical reactive skills in a unified cognitive architecture.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive architecture,Hierarchical skills,Incremental learning,Problem solving,Reactive control},
number = {4},
pages = {316--332},
title = {{Acquisition of hierarchical reactive skills in a unified cognitive architecture}},
volume = {10},
year = {2009}
}
@article{Buschman2015,
abstract = {The brain has a limited capacity and therefore needs mechanisms to selectively enhance the information most relevant to one's current behavior. We refer to these mechanisms as "attention." Attention acts by increasing the strength of selected neural representations and preferentially routing them through the brain's large-scale network. This is a critical component of cognition and therefore has been a central topic in cognitive neuroscience. Here we review a diverse literature that has studied attention at the level of behavior, networks, circuits, and neurons. We then integrate these disparate results into a unified theory of attention.},
author = {Buschman, Timothy J and Kastner, Sabine},
doi = {10.1016/j.neuron.2015.09.017},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neuron/Buschman, Kastner/Buschman, Kastner - 2015 - From Behavior to Neural Dynamics An Integrated Theory of Attention.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {127--144},
pmid = {26447577},
publisher = {Elsevier Inc.},
title = {{From Behavior to Neural Dynamics: An Integrated Theory of Attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26447577 http://dx.doi.org/10.1016/j.neuron.2015.09.017},
volume = {88},
year = {2015}
}
@article{Botvinick2009a,
abstract = {Research on human and animal behavior has long emphasized its hierarchical structure-the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
doi = {10.1016/j.cognition.2008.08.011},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognition/Botvinick, Niv, Barto/Botvinick, Niv, Barto - 2009 - Hierarchically organized behavior and its neural foundations a reinforcement learning perspective.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Animals,Humans,Models,Nerve Net,Nerve Net: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Problem Solving,Problem Solving: physiology,Psychological,Reinforcement (Psychology)},
number = {3},
pages = {262--80},
pmid = {18926527},
title = {{Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2783353{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {113},
year = {2009}
}
@book{Baars1988,
address = {New York},
author = {Baars, Bernard J.},
publisher = {Cambridge University Press},
title = {{A cognitive theory of consciousness}},
year = {1988}
}
@inproceedings{Chen2016,
address = {Austin},
author = {Chen, Stephanie Y and Bartels, Daniel M and Urminsky, Oleg},
booktitle = {Proceedings of the 38th Annual Conference of the Cognitive Science Society},
editor = {Papafragou, A. and Grodner, D. and Mirman, D. and Trueswell, J.C.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 38th Annual Conference of the Cognitive Science Society/Chen, Bartels, Urminsky/Chen, Bartels, Urminsky - 2016 - Is the Self - Concept like other Concepts The Causal Structure of Identity.pdf:pdf},
keywords = {causal,concepts and categories,personal identity,reasoning,self-concept},
pages = {1727--1732},
publisher = {Cognitive Science Society},
title = {{Is the Self - Concept like other Concepts ? The Causal Structure of Identity}},
year = {2016}
}
@inproceedings{Cubek2015,
author = {Cubek, Richard and Ertel, Wolfgang},
booktitle = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015/Cubek, Ertel/Cubek, Ertel - 2015 - High-Level Learning from Demonstration wit.pdf:pdf},
isbn = {9781479969234},
pages = {2592--2597},
publisher = {IEEE},
title = {{High-Level Learning from Demonstration with Conceptual Spaces and Subspace Clustering}},
year = {2015}
}
@article{Fan2016,
abstract = {Hierarchical temporal memory (HTM) tries to mimic the computing in cerebral-neocortex. It identifies spatial and temporal patterns in the input for making inferences. This may require large number of computationally expensive tasks like, dot-product evaluations. Nano-devices that can provide direct mapping for such primitives are of great interest. In this work we show that the computing blocks for HTM can be mapped using low-voltage, fast-switching, magneto-metallic spin-neurons combined with emerging resistive cross-bar network (RCN). Results show possibility of more than 200x lower energy as compared to 45nm CMOS ASIC design},
archivePrefix = {arXiv},
arxivId = {1402.2902},
author = {Fan, Deliang and Sharad, Mrigank and Sengupta, Abhronil and Roy, Kaushik},
doi = {10.1109/TNNLS.2015.2462731},
eprint = {1402.2902},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Transactions on Neural Networks and Learning Systems/Fan et al/Fan et al. - 2016 - Hierarchical Temporal Memory Based on Spin-Neurons and Resistive Memory for Energy-Efficient Brain-Inspired Computin.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Hierarchical temporal memory (HTM),magnetic domain walls (DWs),memristors,neural network hardware,spin Hall effect (SHE),spin transfer torque},
number = {9},
pages = {1907--1919},
title = {{Hierarchical Temporal Memory Based on Spin-Neurons and Resistive Memory for Energy-Efficient Brain-Inspired Computing}},
volume = {27},
year = {2016}
}
@article{Ivanitsky1997,
author = {Ivanitsky, A. M.},
journal = {Neuroscience and Behavioral Physiology},
number = {4},
pages = {414--426},
title = {{Information synthesis in key parts of the cerebral cortex as the basis of subjective experience}},
volume = {27},
year = {1997}
}
@article{Ruvolo2013,
abstract = {The problem of learning multiple consecutive tasks, known as lifelong learning, is of great importance to the creation of intelligent, general-purpose, and flexible machines. In this paper, we develop a method for online multi-task learning in the lifelong learning setting. The proposed Efficient Lifelong Learning Algorithm (ELLA) maintains a sparsely shared basis for all task models, transfers knowledge from the basis to learn each new task, and refines the basis over time to maximize performance across all tasks. We show that ELLA has strong connections to both online dictionary learning for sparse coding and state-of-the-art batch multi-task learning methods, and provide robust theoretical performance guarantees. We show empirically that ELLA yields nearly identical performance to batch multi-task learning while learning tasks sequentially in three orders of magnitude (over 1,000x) less time.},
author = {Ruvolo, Paul and Eaton, Eric},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 30th International Conference on Machine Learning/Ruvolo, Eaton/Ruvolo, Eaton - 2013 - ELLA An efficient lifelong learning algorithm.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning},
number = {1},
pages = {507--515},
title = {{ELLA: An efficient lifelong learning algorithm}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/ICML2013{\_}ruvolo13},
volume = {28},
year = {2013}
}
@incollection{Hexmoor1996,
abstract = {Routine interactions in the world of an autonomous agent are a major source of learning for the agent. In my approach an agent interacts in the world in several different ways, from cognitive to automatic. I show that an agent can learn and also improve its routine interactions in its different modes of interaction in the world. I present a formalism and use for a goal structure known as goal sketch [11]. Rewards and punishments generated from a goal sketch which indicate progress in goal satisfaction are used to improve automatic interactions and enhance agent's strategies and concepts about action. I will discuss my experiments with a physical robot that uses a goal sketch in order to generate rewards and punishments which are then used in improving robot skills and discovering new actions.},
author = {Hexmoor, Henry},
booktitle = {Intelligent Agents II Agent Theories, Architectures, and Languages},
doi = {10.1007/3540608052_61},
editor = {Wooldridge, Michael and Muller, J{\"{o}}rg P. and Tambe, Milind},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Intelligent Agents II Agent Theories, Architectures, and Languages/Hexmoor/Hexmoor - 1996 - Learning Routines.pdf:pdf},
pages = {97--110},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Learning Routines}},
year = {1996}
}
@article{Grossberg2014,
author = {Grossberg, Stephen},
doi = {10.1016/j.brainres.2014.11.018},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Brain Research/Grossberg/Grossberg - 2015 - From brain synapses to systems for learning and memory Object recognition, spatial navigation, timed conditioning, an.pdf:pdf},
issn = {00068993},
journal = {Brain Research},
keywords = {3D vision,Adaptive resonance theory,Adaptively controlled conditioning,Attention,Autism,Category learning,Cognitive working memory,Eye movement,Grid cell,Laminar cortical circuits,Learning,Medial temporal amnesia,Memory,Place cell,Predictive remapping,Spatial navigation,Speech perception,Time cell,mGluR},
pages = {270--293},
publisher = {Elsevier},
title = {{From brain synapses to systems for learning and memory: Object recognition, spatial navigation, timed conditioning, and movement control}},
url = {http://dx.doi.org/10.1016/j.brainres.2014.11.018 http://linkinghub.elsevier.com/retrieve/pii/S0006899314015650},
volume = {1621},
year = {2015}
}
@article{Sommerville2005,
abstract = {Adults and children readily construct action representations organized with respect to an ultimate goal. These representations allow one to predict the consequences of action, interpret and describe actions, and categorize action sequences. In this paper, we explore the ontogeny of hierarchically organized action representations, and its relation to infants' ability to produce similar sequences. To do so, we examine infants' perception and performance of a means-end sequence: pulling a cloth to retrieve a toy. Using a visual habituation paradigm, we demonstrate that 12-month-old infants understand that the initial step of the cloth-pulling sequence is directed toward the ultimate goal of attaining the toy, and use their knowledge of the causal constraints of the sequence to make this goal attribution. Ten-month-olds, however, appear transitional with respect to this understanding: their ability to identify the goal of the cloth-pulling sequence is related to their own ability to planfully solve a similar sequence. These findings are consistent with a burgeoning body of literature suggesting an intimate link between action production and perception, and suggest that this link is in place by at least 10 months of age. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sommerville, Jessica A. and Woodward, Amanda L.},
doi = {10.1016/j.cognition.2003.12.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognition/Sommerville, Woodward/Sommerville, Woodward - 2005 - Pulling out the intentional structure of action The relation between action processing and action product.pdf:pdf},
isbn = {0010-0277},
issn = {00100277},
journal = {Cognition},
keywords = {Action processing,Action production,Intentional structure},
number = {1},
pages = {1--30},
pmid = {15629472},
title = {{Pulling out the intentional structure of action: The relation between action processing and action production in infancy}},
volume = {95},
year = {2005}
}
@inproceedings{Kachergis2016,
address = {Austin},
author = {Kachergis, George and Berends, Floris and de Kleijn, Roy and Hommel, Bernhard},
booktitle = {Proceedings of the 38th Annual Conference of the Cognitive Science Society},
editor = {Papafragou, A. and Grodner, D. and Mirman, D. and Trueswell, J.C.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 38th Annual Conference of the Cognitive Science Society/Kachergis et al/Kachergis et al. - 2016 - Human Reinforcement Learning of Sequential Action.pdf:pdf},
keywords = {movement trajectory,quential action,reinforcement learning,se-,sequence learning,serial reaction time task},
pages = {193--198},
publisher = {Cognitive Science Society},
title = {{Human Reinforcement Learning of Sequential Action}},
year = {2016}
}
@article{Balaguer2016,
author = {Balaguer, Jan and Spiers, Hugo and Hassabis, Demis and Summerfield, Christopher},
doi = {10.1016/j.neuron.2016.03.037},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neuron/Balaguer et al/Balaguer et al. - 2016 - Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {893--903},
pmid = {27196978},
publisher = {The Authors},
title = {{Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316300575},
volume = {90},
year = {2016}
}
@incollection{Zhdanov1997,
address = {М.},
author = {Жданов, А. А.},
booktitle = {Сборник «Вопросы кибернетики". Научный совет по комплексной проблеме «Кибернетика» РАН. Вып. 3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Сборник «Вопросы кибернетики. Научный совет по комплексной проблеме «Кибернетика» РАН. Вып. 3/Жданов/Жданов - 1997 - Формальная модель нейрона и нейросети в методологии автономного адаптивного управлении.pdf:pdf},
language = {russian},
pages = {258--274},
title = {{Формальная модель нейрона и нейросети в методологии автономного адаптивного управлении}},
year = {1997}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ma, Wei Ji and Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/nn1790},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Nature Neuroscience/Ma et al/Ma et al. - 2006 - Bayesian inference with probabilistic population codes.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {11},
pages = {1432--1438},
pmid = {17057707},
title = {{Bayesian inference with probabilistic population codes}},
volume = {9},
year = {2006}
}
@article{Miconi2017,
abstract = {{\textless}p{\textgreater}Neural activity during cognitive tasks exhibits complex dynamics that flexibly encode task-relevant variables. Chaotic recurrent networks, which spontaneously generate rich dynamics, have been proposed as a model of cortical computation during cognitive tasks. However, existing methods for training these networks are either biologically implausible, and/or require a continuous, real-time error signal to guide learning. Here we show that a biologically plausible learning rule can train such recurrent networks, guided solely by delayed, phasic rewards at the end of each trial. Networks endowed with this learning rule can successfully learn nontrivial tasks requiring flexible (context-dependent) associations, memory maintenance, nonlinear mixed selectivities, and coordination among multiple outputs. The resulting networks replicate complex dynamics previously observed in animal cortex, such as dynamic encoding of task features and selective integration of sensory inputs. We conclude that recurrent neural networks offer a plausible model of cortical dynamics during both learning and performance of flexible behavior.{\textless}/p{\textgreater}},
archivePrefix = {arXiv},
arxivId = {1507.08973},
author = {Miconi, Thomas},
doi = {10.7554/eLife.20899},
eprint = {1507.08973},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/eLife/Miconi/Miconi - 2017 - Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks.pdf:pdf},
isbn = {0894-0282},
issn = {2050084X},
journal = {eLife},
pages = {1--24},
pmid = {22352717},
title = {{Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks}},
volume = {6},
year = {2017}
}
@book{Vityaev2006,
address = {Новосибирск},
author = {Витяев, Е. Е.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Витяев/Витяев - 2006 - Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов Монография.pdf:pdf},
language = {russian},
pages = {293},
publisher = {Новосиб. гос. ун-т},
title = {{Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов: Монография}},
year = {2006}
}
@article{Hampshire2016,
abstract = {The ability to learn new tasks rapidly is a prominent characteristic of human behaviour. This ability relies on flexible cognitive systems that adapt in order to encode temporary programs for processing non-automated tasks. Previous functional imaging studies have revealed distinct roles for the lateral frontal cortices (LFCs) and the ventral striatum in intentional learning processes. However, the human LFCs are complex; they house multiple distinct sub-regions, each of which co-activates with a different functional network. It remains unclear how these LFC networks differ in their functions and how they coordinate with each other, and the ventral striatum, to support intentional learning. Here, we apply a suite of fMRI connectivity methods to determine how LFC networks activate and interact at different stages of two novel tasks, in which arbitrary stimulus-response rules are learnt either from explicit instruction or by trial-and-error. We report that the networks activate en masse and in synchrony when novel rules are being learnt from instruction. However, these networks are not homogeneous in their functions; instead, the directed connectivities between them vary asymmetrically across the learning timecourse and they disengage from the task sequentially along a rostro-caudal axis. Furthermore, when negative feedback indicates the need to switch to alternative stimulus-response rules, there is additional input to the LFC networks from the ventral striatum. These results support the hypotheses that LFC networks interact as a hierarchical system during intentional learning and that signals from the ventral striatum have a driving influence on this system when the internal program for processing the task is updated.},
author = {Hampshire, Adam and Hellyer, Peter J. and Parkin, Beth and Hiebert, Nole and MacDonald, Penny and Owen, Adrian M. and Leech, Robert and Rowe, James},
doi = {10.1016/j.neuroimage.2015.11.060},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/NeuroImage/Hampshire et al/Hampshire et al. - 2016 - Network mechanisms of intentional learning.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Caudate,Dynamic causal modelling,Frontal cortex,Functional connectivity,Learning},
pages = {123--134},
publisher = {The Authors},
title = {{Network mechanisms of intentional learning}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.11.060},
volume = {127},
year = {2016}
}
@article{Lakhman2013,
author = {Лахман, К. В. and Бурцев, М. С.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Математическая биология и биоинформатика/Лахман, Бурцев/Лахман, Бурцев - 2013 - Механизмы кратковременной памяти в целенаправленном поведении нейросетевых агентов.pdf:pdf},
journal = {Математическая биология и биоинформатика},
language = {russian},
number = {2},
pages = {419--431},
title = {{Механизмы кратковременной памяти в целенаправленном поведении нейросетевых агентов}},
volume = {8},
year = {2013}
}
@article{Samsonovich2014,
abstract = {A key capability that distinguishes humans from intelligent agents is the ability to generate and select new goals in an unexpected situation, while re-prioritizing existing goals. This level of cognitive autonomy becomes practically vital for actors working as team members with humans or in unpredictable environments. The work is focused on a new perspective on this problem based on biologically inspired cognitive architectures (BICA). Aspects of goal reasoning and goal management capabilities that are currently available in selected BICA are reviewed. A generalizing model of goal reasoning as a form of metacognition is defined, that integrates multiple mechanisms. On top of the traditional cognitive cycle, the model includes a goal-reasoning cycle triggered by notable phenomena. This goal reasoning cycle integrates mechanisms like agitation of desires by drives and their instantiation in goals, or metacognitive reasoning about goals. The model is illustrated by consideration of specific scenarios at micro- and macro-cognitive scales to evaluate the use and potential capabilities of this goal reasoning model for BICA. New capabilities that will be enabled based on this approach are expected to increase the human compatibility and cognitive autonomy of future intelligent agents. The general goal reasoning capability is a key component included in the BICA Challenge and is required for integration of intelligent agents into human teams.},
author = {Samsonovich, Alexei V.},
doi = {10.1016/j.bica.2014.07.003},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Samsonovich/Samsonovich - 2014 - Goal reasoning as a general form of metacognition in BICA.pdf:pdf},
isbn = {2212-683X},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Autonomy,Cognitive architectures,Goal reasoning,Intelligent agents},
pages = {105--122},
publisher = {Elsevier B.V.},
title = {{Goal reasoning as a general form of metacognition in BICA}},
url = {http://dx.doi.org/10.1016/j.bica.2014.07.003},
volume = {9},
year = {2014}
}
@article{Subagdja2015,
author = {Subagdja, Budhitama and Tan, Ah-Hwee},
doi = {10.1016/j.neucom.2015.02.038},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neurocomputing/Subagdja, Tan/Subagdja, Tan - 2015 - Neural modeling of sequential inferences and learning over episodic memory.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Adaptive resonance theory,Episodic memory,Transitive inference},
pages = {1--14},
publisher = {Elsevier},
title = {{Neural modeling of sequential inferences and learning over episodic memory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231215001873},
year = {2015}
}
@inproceedings{Licato2015,
abstract = {The ability to generate explanations of perceived events and of one's own actions is of central importance to how we make sense of the world. When modeling explanation generation, one common tactic used by cognitive systems is to construct a linkage of previously created cause- effect pairs. But where do such cause-effect pairs come from in the first place, and how can they be created automatically by cognitive systems? In this paper, we discuss the development of causal representations in children, by analyzing the literature surrounding a Piagetian experiment, and show how the conditions making cause-effect pair creation possi- ble can start to be modeled using a combination of feature-extraction techniques and the structured knowledge representation in the hybrid cognitive architecture CLARION. We create a task in PAGI World for learning causality, and make this task available for download.},
author = {Licato, John and Marton, Nick and Dong, Boning and Sun, Ron and Bringsjord, Selmer},
booktitle = {Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition},
editor = {Lieto, Antonio and Battaglino, Cristina and Radicioni, Daniele P. and Sanguinetti, Manuela},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition/Licato et al/Licato et al. - 2015 - Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generatio.pdf:pdf},
keywords = {analogy,clarion,cognitive architecture,explanation},
pages = {29--39},
series = {CEUR Workshop Proceedings},
title = {{Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generation in a Cognitive Architecture}},
year = {2015}
}
@article{Deco2015,
abstract = {The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks - in particular, network communities and hubs - support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.},
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L},
doi = {10.1038/nrn3963},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Nature reviews. Neuroscience/Deco et al/Deco et al. - 2015 - Rethinking segregation and integration contributions of whole-brain modelling.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
number = {7},
pages = {430--439},
pmid = {26081790},
publisher = {Nature Publishing Group},
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}},
url = {http://www.nature.com.sire.ub.edu/nrn/journal/v16/n7/full/nrn3963.html},
volume = {16},
year = {2015}
}
@incollection{Palomino2016,
abstract = {This paper presents a novel attention-based cognitive architecture for a social robot. This architecture aims to join perception and reasoning considering a double interplay: the current task biases the perceptual process whereas perceived items determine the behaviours to be accomplished, considering the present context and role of the agent. Therefore, the proposed architecture represents a bidirectional solution to the perception-reasoning-action loop closing problem. The proposal is divided into two levels of performance, employing anObject-BasedVisual Attention model as perception system and a general purpose Planning Framework at the top deliberative level. The architecture has been tested using a real and unrestricted environment that involves a real robot, time-varying tasks and daily life situations.},
author = {Palomino, Antonio Jes{\'{u}}s and Marfil, Rebeca and Bandera, Juan Pedro and Bandera, Antonio},
booktitle = {Robot 2015: Second Iberian Robotics Conference},
doi = {10.1007/978-3-319-27149-1},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Robot 2015 Second Iberian Robotics Conference/Palomino et al/Palomino et al. - 2016 - A New Cognitive Architecture for Bidirectional Loop Closing.pdf:pdf},
isbn = {978-3-319-27148-4},
keywords = {attention model,bidirectional,cognitive architecture,social robot},
pages = {721--732},
series = {Advances in Intelligent Systems and Computing},
title = {{A New Cognitive Architecture for Bidirectional Loop Closing}},
url = {http://link.springer.com/10.1007/978-3-319-27149-1},
year = {2016}
}
@article{Donnarumma2015,
abstract = {Distributed and hierarchical models of control are nowadays popular in computational modeling and robotics. In the artificial neural network literature, complex behaviors can be produced by composing elementary building blocks or motor primitives, possibly organized in a layered structure. However, it is still unknown how the brain learns and encodes multiple motor primitives, and how it rapidly reassembles, sequences and switches them by exerting cognitive control. In this paper we advance a novel proposal, a hierarchical programmable neural network architecture, based on the notion of programmability and an interpreter-programmer computational scheme. In this approach, complex (and novel) behaviors can be acquired by embedding multiple modules (motor primitives) in a single, multi-purpose neural network. This is supported by recent theories of brain functioning in which skilled behaviors can be generated by combining functional different primitives embedded in ‘‘reusable'' areas of ‘‘recycled'' neurons. Such neuronal substrate supports flexible cognitive control, too. Modules are seen as interpreters of behaviors having controlling input parameters, or programs that encode structures of networks to be interpreted. Flexible cognitive control can be exerted by a programmer module feeding the interpreters with appropriate input parameters, without modifying connectivity. Our results in a multiple T-maze robotic scenario show how this computational framework provides a robust, scalable and flexible scheme that can be iterated at different hierarchical layers permitting to learn, encode and control multiple qualitatively different behaviors.},
author = {Donnarumma, F. and Prevete, R. and de Giorgio, A. and Montone, G. and Pezzulo, G.},
doi = {10.1177/1059712315609412},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Adaptive Behavior/Donnarumma et al/Donnarumma et al. - 2015 - Learning programs is better than learning dynamics A programmable neural network hierarchical architecture in.pdf:pdf},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {cognitive control,distributed representation,hierarchical organization,neuronal reuse,programming neural networks},
pages = {(In press)},
title = {{Learning programs is better than learning dynamics: A programmable neural network hierarchical architecture in a multi-task scenario}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/1059712315609412},
year = {2015}
}
@article{Klampfl2013,
abstract = {Numerous experimental data suggest that simultaneously or sequentially activated assemblies of neurons play a key role in the storage and computational use of long-term memory in the brain. However, a model that elucidates how these memory traces could emerge through spike-timing-dependent plasticity (STDP) has been missing. We show here that stimulus-specific assemblies of neurons emerge automatically through STDP in a simple cortical microcircuit model. The model that we consider is a randomly connected network of well known microcircuit motifs: pyramidal cells with lateral inhibition. We show that the emergent assembly codes for repeatedly occurring spatiotemporal input patterns tend to fire in some loose, sequential manner that is reminiscent of experimentally observed stereotypical trajectories of network states. We also show that the emergent assembly codes add an important computational capability to standard models for online computations in cortical microcircuits: the capability to integrate information from long-term memory with information from novel spike inputs.},
author = {Klampfl, Stefan and Maass, Wolfgang},
doi = {10.1523/JNEUROSCI.5044-12.2013},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/The Journal of neuroscience the official journal of the Society for Neuroscience/Klampfl, Maass/Klampfl, Maass - 2013 - Emergence of dynamic memory traces in cortical microcircuit models through STDP.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Memory,Memory: physiology,Models,Neural Networks (Computer),Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology},
number = {28},
pages = {11515--11529},
pmid = {23843522},
title = {{Emergence of dynamic memory traces in cortical microcircuit models through STDP.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23843522},
volume = {33},
year = {2013}
}
@article{Rensink2000,
author = {Rensink, Ronald A.},
doi = {10.1080/135062800394667},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Visual Cognition/Rensink/Rensink - 2000 - The Dynamic Representation of Scenes.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
number = {1-3},
pages = {17--42},
title = {{The Dynamic Representation of Scenes}},
url = {http://www.tandfonline.com/doi/abs/10.1080/135062800394667},
volume = {7},
year = {2000}
}
@article{Martin2017,
author = {Martin, Andrea E. and Doumas, Leonidas A. A.},
doi = {10.1371/journal.pbio.2000663},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/PLOS Biology/Martin, Doumas/Martin, Doumas - 2017 - A mechanism for the cortical computation of hierarchical linguistic structure.pdf:pdf},
isbn = {1111111111},
issn = {1545-7885},
journal = {PLOS Biology},
number = {3},
pages = {e2000663},
title = {{A mechanism for the cortical computation of hierarchical linguistic structure}},
url = {http://dx.plos.org/10.1371/journal.pbio.2000663},
volume = {15},
year = {2017}
}
@article{Navalpakkam2005,
abstract = {We propose a computational model for the task-specific guidance of visual attention in real-world scenes. Our model emphasizes four aspects that are important in biological vision: determining task-relevance of an entity, biasing attention for the low-level visual features of desired targets, recognizing these targets using the same low-level features, and incrementally building a visual map of task-relevance at every scene location. Given a task definition in the form of keywords, the model first determines and stores the task-relevant entities in working memory, using prior knowledge stored in long-term memory. It attempts to detect the most relevant entity by biasing its visual attention system with the entity's learned low-level features. It attends to the most salient location in the scene, and attempts to recognize the attended object through hierarchical matching against object representations stored in long-term memory. It updates its working memory with the task-relevance of the recognized entity and updates a topographic task-relevance map with the location and relevance of the recognized entity. The model is tested on three types of tasks: single-target detection in 343 natural and synthetic images, where biasing for the target accelerates target detection over twofold on average; sequential multiple-target detection in 28 natural images, where biasing, recognition, working memory and long term memory contribute to rapidly finding all targets; and learning a map of likely locations of cars from a video clip filmed while driving on a highway. The model's performance on search for single features and feature conjunctions is consistent with existing psychophysical data. These results of our biologically-motivated architecture suggest that the model may provide a reasonable approximation to many brain processes involved in complex task-driven visual behaviors.},
author = {Navalpakkam, Vidhya and Itti, Laurent},
doi = {10.1016/j.visres.2004.07.042},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Vision research/Navalpakkam, Itti/Navalpakkam, Itti - 2005 - Modeling the influence of task on attention.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Attention: physiology,Cues,Humans,Memory,Memory: physiology,Models,Pattern Recognition,Psychological,Psychophysics,Recognition (Psychology),Recognition (Psychology): physiology,Visual,Visual Perception,Visual Perception: physiology},
number = {2},
pages = {205--31},
pmid = {15581921},
title = {{Modeling the influence of task on attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15581921},
volume = {45},
year = {2005}
}
@inproceedings{Siagian2007a,
author = {Siagian, Christian and Itti, Laurent},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE International Conference on Intelligent Robots and Systems/Siagian, Itti/Siagian, Itti - 2007 - Biologically-Inspired Robotics Vision Monte-Carlo Localization in the Outdoor Environment.pdf:pdf},
pages = {1723--1730},
title = {{Biologically-Inspired Robotics Vision Monte-Carlo Localization in the Outdoor Environment}},
year = {2007}
}
@article{Borisyuk2004,
abstract = {We develop a new oscillatory model that combines consecutive selection of objects and discrimination between new and familiar objects. The model works with visual information and fulfils the following operations: (1) separation of different objects according to their spatial connectivity; (2) consecutive selection of objects located in the visual field into the attention focus; (3) extraction of features; (4) representation of objects in working memory; (5) novelty detection of objects. The functioning of the model is based on two main principles: the synchronization of oscillators through phase-locking and resonant increase of the amplitudes of oscillators if they work in-phase with other oscillators. The results of computer simulation of the model are described for visual stimuli representing printed words.},
author = {Borisyuk, Roman M and Kazanovich, Yakov B},
doi = {10.1016/j.neunet.2004.03.005},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/Borisyuk, Kazanovich/Borisyuk, Kazanovich - 2004 - Oscillatory model of attention-guided object selection and novelty detectio.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Attention,Attention: physiology,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Humans,Mathematics,Memory,Memory: physiology,Models,Neurological,Photic Stimulation,Photic Stimulation: methods,Psychological,Signal Detection,Visual Perception,Visual Perception: physiology},
number = {7},
pages = {899--915},
pmid = {15312834},
title = {{Oscillatory model of attention-guided object selection and novelty detection}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15312834},
volume = {17},
year = {2004}
}
@article{Damerow2016,
abstract = {Most current approaches to scene understanding lack the capability to adapt object and situation models to behavioral needs not anticipated by the human system designer. Here, we give a detailed description of a system architecture for self-referential autonomous learning which enables the refinement of object and situation models during operation in order to optimize behavior. This includes structural learning of hierarchical models for situations and behaviors that is triggered by a mismatch between expected and actual action outcome. Besides proposing architectural concepts, we also describe a first implementation of our system within a simulated traffic scenario to demonstrate the feasibility of our approach.},
author = {Damerow, Florian and Knoblauch, Andreas and K{\"{o}}rner, Ursula and Eggert, Julian and K{\"{o}}rner, Edgar},
doi = {10.1007/s12559-016-9407-7},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Computation/Damerow et al/Damerow et al. - 2016 - Toward Self-Referential Autonomous Learning of Object and Situation Models.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {autonomous learning {\'{a}} hierarchical,self-referential control {\'{a}} scene,situation model,understanding {\'{a}}},
pages = {1--17},
title = {{Toward Self-Referential Autonomous Learning of Object and Situation Models}},
url = {http://link.springer.com/10.1007/s12559-016-9407-7},
year = {2016}
}
@article{Itti1998,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Transactions on pattern analysis and machine intelligence/Itti, Koch, Niebur/Itti, Koch, Niebur - 1998 - A model of Siliency-Based Visual Attention for Rapid Scene Analysis.pdf:pdf},
journal = {IEEE Transactions on pattern analysis and machine intelligence},
number = {11},
pages = {1254--1259},
title = {{A model of Siliency-Based Visual Attention for Rapid Scene Analysis}},
volume = {20},
year = {1998}
}
@inproceedings{Tarasov2016,
author = {Тарасов, В. Б.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Тарасов/Тарасов - 2016 - От спецификации когнитонов и инженерии интенций к обобщенной архитектуре деятельности агентов.pdf:pdf},
language = {russian},
pages = {94--114},
title = {{От спецификации когнитонов и инженерии интенций к обобщенной архитектуре деятельности агентов}},
year = {2016}
}
@article{Botvinick2012,
abstract = {The hierarchical structure of human and animal behavior has been of critical interest in neuroscience for many years. Yet understanding the neural processes that give rise to such structure remains an open challenge. In recent research, a new perspective on hierarchical behavior has begun to take shape, inspired by ideas from machine learning, and in particular the framework of hierarchical reinforcement learning. Hierarchical reinforcement learning builds on traditional reinforcement learning mechanisms, extending them to accommodate temporally extended behaviors or subroutines. The resulting computational paradigm has begun to influence both theoretical and empirical work in neuroscience, conceptually aligning the study of hierarchical behavior with research on other aspects of learning and decision making, and giving rise to some thought-provoking new findings. ?? 2012.},
author = {Botvinick, Matthew Michael},
doi = {10.1016/j.conb.2012.05.008},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Current Opinion in Neurobiology/Botvinick/Botvinick - 2012 - Hierarchical reinforcement learning and decision making.pdf:pdf},
isbn = {0818653302},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {956--962},
pmid = {22695048},
publisher = {Elsevier Ltd},
title = {{Hierarchical reinforcement learning and decision making}},
url = {http://dx.doi.org/10.1016/j.conb.2012.05.008},
volume = {22},
year = {2012}
}
@article{Culhane1995,
author = {Tsotsos, John K. and Culhane, Sean M and Wai, Winky Yan Kei and Lai, Yuzhong and Davis, Neal and Nuflo, Fernando},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Artificial Intelligence/Tsotsos et al/Tsotsos et al. - 1995 - Modeling visual attention via selective tuning.pdf:pdf},
journal = {Artificial Intelligence},
number = {78},
pages = {507--545},
title = {{Modeling visual attention via selective tuning}},
year = {1995}
}
@article{DeWolf2011,
abstract = {Our empirical, neuroscientific understanding of biological motor systems has been rapidly growing in recent years. However, this understanding has not been systematically mapped to a quantitative characterization of motor control based in control theory. Here, we attempt to bridge this gap by describing the neural optimal control hierarchy (NOCH), which can serve as a foundation for biologically plausible models of neural motor control. The NOCH has been constructed by taking recent control theoretic models of motor control, analyzing the required processes, generating neurally plausible equivalent calculations and mapping them on to the neural structures that have been empirically identified to form the anatomical basis of motor control. We demonstrate the utility of the NOCH by constructing a simple model based on the identified principles and testing it in two ways. First, we perturb specific anatomical elements of the model and compare the resulting motor behavior with clinical data in which the corresponding area of the brain has been damaged. We show that damaging the assigned functions of the basal ganglia and cerebellum can cause the movement deficiencies seen in patients with Huntington's disease and cerebellar lesions. Second, we demonstrate that single spiking neuron data from our model's motor cortical areas explain major features of single-cell responses recorded from the same primate areas. We suggest that together these results show how NOCH-based models can be used to unify a broad range of data relevant to biological motor control in a quantitative, control theoretic framework.},
author = {DeWolf, T and Eliasmith, C},
doi = {10.1088/1741-2560/8/6/065009},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Journal of Neural Engineering/DeWolf, Eliasmith/DeWolf, Eliasmith - 2011 - The neural optimal control hierarchy for motor control.pdf:pdf},
isbn = {1741-2552},
issn = {1741-2560},
journal = {Journal of Neural Engineering},
number = {6},
pages = {065009},
pmid = {22056418},
title = {{The neural optimal control hierarchy for motor control}},
volume = {8},
year = {2011}
}
@article{Raghubir2006,
abstract = {This paper examines centrality of physical position as a cue that leads to systematic biases in people' decisions to retain or eliminate a participant from a group. Termed the "center-stage" effect, we argue that people use their belief that "important people sit in the middle" as a schematic cue that they substitute for individuating performance information for individuals who occupy central positions when the goal is to eliminate all but one of the group members. This leads to the errors of those in center-positions being overlooked: or making them the "centers-of-inattention." Study 1 examines people's lay beliefs regarding positions using two stylized placement tasks (a group interview and classroom seating scenarios). These suggest that people believe that more attention is paid to those in the center than those on the extremes. Study 2 tests the center-stage effect using observational data from a real television show, The Weakest Link. Results show that players assigned at random to central positions are more likely to win the game than those in extreme positions. Study 3, a laboratory experiment manipulating attention paid to the game shows that observers overlook the errors of players in the center to a greater extent than the errors of players in extreme positions. Study 4 replicates the game in the laboratory with direct process measures to show that players playing the game make the same error. Study 5 shows that in a stylized group interview setting, participants who believe that "important people sit in the middle" find the performance of candidates in the extreme position easier to recall than the performance of those in the central position, and are more likely to choose them. Study 6 shows that the "center-stage" effects are weaker when the end-game rule allows for two (vs one) contestants to be retained. Overall results converge to show that the use of the "center-stage" heuristic substitutes for the effortful processing of individuating information, leading to a biased (favorable) assessment of people in the center. Implications for decision-making are discussed. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Raghubir, Priya and Valenzuela, Ana},
doi = {10.1016/j.obhdp.2005.06.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Organizational Behavior and Human Decision Processes/Raghubir, Valenzuela/Raghubir, Valenzuela - 2006 - Center-of-inattention Position biases in decision-making.pdf:pdf},
isbn = {07495978},
issn = {07495978},
journal = {Organizational Behavior and Human Decision Processes},
keywords = {Perceptual biases,Performance appraisal,Salience effects,Visual information processing},
number = {1},
pages = {66--80},
title = {{Center-of-inattention: Position biases in decision-making}},
volume = {99},
year = {2006}
}
@article{Fermin2016,
abstract = {Humans can select actions by learning, planning, or retrieving motor memories. Reinforcement Learning (RL) associates these processes with three major classes of strategies for action selection: exploratory RL learns state-action values by exploration, model-based RL uses internal models to simulate future states reached by hypothetical actions, and motor-memory RL selects past successful state-action mapping. In order to investigate the neural substrates that implement these strategies, we conducted a functional magnetic resonance imaging (fMRI) experiment while humans performed a sequential action selection task under conditions that promoted the use of a specific RL strategy. The ventromedial prefrontal cortex and ventral striatum increased activity in the exploratory condition; the dorsolateral prefrontal cortex, dorsomedial striatum, and lateral cerebellum in the model-based condition; and the supplementary motor area, putamen, and anterior cerebellum in the motor-memory condition. These findings suggest that a distinct prefrontal-basal ganglia and cerebellar network implements the model-based RL action selection strategy.},
author = {Fermin, Alan S. R. and Yoshida, Takehiko and Yoshimoto, Junichiro and Ito, Makoto and Tanaka, Saori C. and Doya, Kenji},
doi = {10.1038/srep31378},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Scientific Reports/Fermin et al/Fermin et al. - 2016 - Model-based action planning involves cortico-cerebellar and basal ganglia networks.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {August},
pages = {31378},
pmid = {27539554},
publisher = {Nature Publishing Group},
title = {{Model-based action planning involves cortico-cerebellar and basal ganglia networks}},
url = {http://www.nature.com/articles/srep31378},
volume = {6},
year = {2016}
}
@article{Plebe2016a,
abstract = {Neural computation has an influential role in the study of human capacities and behaviors. It has been the dominant approach in the vision science of the last half century, and it is currently one of the fundamental methods of investigation for most higher cognitive func- tions. Yet, neurocomputational approaches to moral behavior are lacking. Computational modeling in general has been scarcely pursued in morality, and existent non-neural attempts have failed to account for the mental processes involved in morality. In this paper we argue that recently the situation has evolved in a way that subverted the insufficient knowledge on the basic organization of moral cognition in brain circuits, making the project of modeling morality in neurocomputational terms feasible. We will present an original architecture that combines reinforcement learning and Hebbian learning, aimed at simulating forms of moral behavior in a simple artificial context. The relationship between language and morality is controversial. In the analytic tradition of philosophy, morality is essentially the lan- guage of morals. On the other side, current cognitive ethology has shown how non human species display behaviors that are surprisingly similar to those prescribed by human ethics. Nevertheless, morality in humans is deeply entrenched with language, and the semantics of words like ‘wrong' resists consensual explanations. The model here proposed includes an auditory processing pathway, with the purpose of showing how the coding of ‘‘wrong”, even if highly simplified with respect to its rich content in natural language, can emerge in the course of moral learning.},
author = {Plebe, Alessio},
doi = {10.1016/j.cogsys.2015.12.012},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Plebe/Plebe - 2016 - What is ‘wrong' in a neural model.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {amygdala,moral cognition,neural computation,orbitofrontal cortex,self-organization},
pages = {4--14},
title = {{What is ‘wrong' in a neural model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041716000085},
volume = {39},
year = {2016}
}
@article{Thilakarathne2015a,
abstract = {Human awareness under different circumstances is complex and non-trivial to understand. Nevertheless, due to the importance of awareness for safety and efficiency in many domains (e.g., the aviation domain), it is necessary to study the processes behind situation awareness, to eliminate possible errors in action selection that may lead to disasters. Interesting models for situation awareness have been presented, mainly from an ecological psychology perspective, but they are debatable with respect to the latest neurocognitive evidences. With the developments in brain imaging and recording techniques, more and more detailed information on complex cognitive processes becomes available. This provides room to further investigate the mechanisms behind many cognitive phenomena, including situation awareness. This paper presents a computational cognitive agent model for situation awareness from the perspective of action selection, which is inspired by neurocognitive evidences. The model integrates bottom-up and top-down cognitive processes, related to various cognitive states: perception, desires, attention, intention, (prior and retrospective) awareness, ownership, feeling, and communication. Based on the model, various cognitive effects can be explained, such as perceptual load, predictive processes, inferential processes, cognitive controlling, unconscious bias, and conscious bias. A model like this will be useful in domains that benefit from complex simulations of socio-technical systems (e.g. the aviation domain) based on computational models of human behaviour. In such domains, existing agent-based simulations are limited, since most of the agent models do not include realistic nature-inspired processes. The validity of the model is illustrated based on simulations for the aviation domain, focusing on a particular situation where an agent has biased perception, poor comprehension, habitual driven projection, and conflict between prior and retrospective effects on action execution.},
author = {Thilakarathne, Dilhan J.},
doi = {10.1016/j.bica.2015.04.010},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Thilakarathne/Thilakarathne - 2015 - Modelling of situation awareness with perception, attention, and prior and retrospective awareness.pdf:pdf;:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Thilakarathne/Thilakarathne - 2015 - Modelling of situation awareness with perception, attention, and prior and retrospective awareness.pdf:pdf},
isbn = {2212-683X},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Bottom-up,Cognitive modelling,Prior and retrospective awareness,Situation awareness,Top-down,prior and retrospective,situation awareness},
pages = {77--104},
publisher = {Elsevier B.V.},
title = {{Modelling of situation awareness with perception, attention, and prior and retrospective awareness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000195 http://dx.doi.org/10.1016/j.bica.2015.04.010},
volume = {12},
year = {2015}
}
@article{Gottlieb2013,
abstract = {Intelligent animals devote much time and energy to exploring and obtaining information, but the underlying mechanisms are poorly understood. We review recent developments on this topic that have emerged from the traditionally separate fields of machine learning, eye movements in natural behavior, and studies of curiosity in psychology and neuroscience. These studies show that exploration may be guided by a family of mechanisms that range from automatic biases toward novelty or surprise to systematic searches for learning progress and information gain in curiosity-driven behavior. In addition, eye movements reflect visual information searching in multiple conditions and are amenable for cellular-level investigations. This suggests that the oculomotor system is an excellent model system for understanding information-sampling mechanisms. {\textcopyright} 2013 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Gottlieb, Jacqueline and Oudeyer, Pierre Yves and Lopes, Manuel and Baranes, Adrien},
doi = {10.1016/j.tics.2013.09.001},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in Cognitive Sciences/Gottlieb et al/Gottlieb et al. - 2013 - Information-seeking, curiosity, and attention Computational and neural mechanisms.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {11},
pages = {585--593},
pmid = {24126129},
publisher = {Elsevier Ltd},
title = {{Information-seeking, curiosity, and attention: Computational and neural mechanisms}},
url = {http://dx.doi.org/10.1016/j.tics.2013.09.001},
volume = {17},
year = {2013}
}
@article{Raymond1992,
author = {Raymond, J. E. and Shapiro, K. L.},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {18},
pages = {849--860},
title = {{Temporary suppression of visual processing in an RSVP task: an attentional blink?}},
year = {1992}
}
@article{Rafferty2015a,
author = {Rafferty, Anna N. and Brunskill, Emma and Griffiths, Thomas L. and Shafto, Patrick},
doi = {10.1111/cogs.12290},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Rafferty et al/Rafferty et al. - 2016 - Faster Teaching via POMDP Planning.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {automated teaching,concept learning,partially observable markov decision,process},
month = {aug},
number = {6},
pages = {1290--1332},
title = {{Faster Teaching via POMDP Planning}},
url = {http://doi.wiley.com/10.1111/cogs.12290},
volume = {40},
year = {2016}
}
@article{Habenschuss2013,
abstract = {Experimental data from neuroscience suggest that a substantial amount of knowledge is stored in the brain in the form of probability distributions over network states and trajectories of network states. We provide a theoretical foundation for this hypothesis by showing that even very detailed models for cortical microcircuits, with data-based diverse nonlinear neurons and synapses, have a stationary distribution of network states and trajectories of network states to which they converge exponentially fast from any initial state. We demonstrate that this convergence holds in spite of the non-reversibility of the stochastic dynamics of cortical microcircuits. We further show that, in the presence of background network oscillations, separate stationary distributions emerge for different phases of the oscillation, in accordance with experimentally reported phase-specific codes. We complement these theoretical results by computer simulations that investigate resulting computation times for typical probabilistic inference tasks on these internally stored distributions, such as marginalization or marginal maximum-a-posteriori estimation. Furthermore, we show that the inherent stochastic dynamics of generic cortical microcircuits enables them to quickly generate approximate solutions to difficult constraint satisfaction problems, where stored knowledge and current inputs jointly constrain possible solutions. This provides a powerful new computing paradigm for networks of spiking neurons, that also throws new light on how networks of neurons in the brain could carry out complex computational tasks such as prediction, imagination, memory recall and problem solving.},
author = {Habenschuss, Stefan and Jonke, Zeno and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003311},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/PLoS Computational Biology/Habenschuss, Jonke, Maass/Habenschuss, Jonke, Maass - 2013 - Stochastic Computations in Cortical Microcircuit Models.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pages = {e1003311},
pmid = {24244126},
title = {{Stochastic Computations in Cortical Microcircuit Models}},
volume = {9},
year = {2013}
}
@article{Tabor2013,
abstract = {Human participants and recurrent ("connectionist") neural networks were both trained on a categorization system abstractly similar to natural language systems involving irregular ("strong") classes and a default class. Both the humans and the networks exhibited staged learning and a generalization pattern reminiscent of the Elsewhere Condition (Kiparsky, 1973). Previous connectionist accounts of related phenomena have often been vague about the nature of the networks' encoding systems. We analyzed our network using dynamical systems theory, revealing topological and geometric properties that can be directly compared with the mechanisms of non-connectionist, rule-based accounts. The results reveal that the networks "contain" structures related to mechanisms posited by rule-based models, partly vindicating the insights of these models. On the other hand, they support the one mechanism (OM), as opposed to the more than one mechanism (MOM), view of symbolic abstraction by showing how the appearance of MOM behavior can arise emergently from one underlying set of principles. The key new contribution of this study is to show that dynamical systems theory can allow us to explicitly characterize the relationship between the two perspectives in implemented models.},
author = {Tabor, Whitney and Cho, Pyeong W and Dankowicz, Harry},
doi = {10.1111/cogs.12072},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive science/Tabor, Cho, Dankowicz/Tabor, Cho, Dankowicz - 2013 - Birth of an abstraction a dynamical systems account of the discovery of an elsewhere principle in a categ.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {Adult,Computer Simulation,Concept Formation,Concept Formation: physiology,Female,Generalization (Psychology),Generalization (Psychology): physiology,Humans,Learning,Learning: physiology,Male,Models,Problem Solving,Problem Solving: physiology,Psychological},
number = {7},
pages = {1193--227},
pmid = {23931713},
title = {{Birth of an abstraction: a dynamical systems account of the discovery of an elsewhere principle in a category learning task}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23931713},
volume = {37},
year = {2013}
}
@book{Steyvers2003,
abstract = {Information about the structure of a causal system can come in the form of observational data-random samples of the system's autonomous behavior-or interventional data-samples conditioned on the particular values of one or more variables that have been experimentally manipulated. Here we study people's ability to infer causal structure from both observation and intervention, and to choose informative interventions on the basis of observational data. In three causal inference tasks, participants were to some degree capable of distinguishing between competing causal hypotheses on the basis of purely observational data. Performance improved substantially when participants were allowed to observe the effects of interventions that they performed on the systems. We develop computational models of how people infer causal structure from data and how they plan intervention experiments, based on the representational framework of causal graphical models and the inferential principles of optimal Bayesian decision-making and maximizing expected information gain. These analyses suggest that people can make rational causal inferences, subject to psychologically reasonable representational assumptions and computationally reasonable processing constraints. {\textcopyright} 2003 Cognitive Science Society, Inc. All rights reserved.},
author = {Steyvers, Mark and Tenenbaum, Joshua B. and Wagenmakers, Eric Jan and Blum, Ben},
booktitle = {Cognitive Science},
doi = {10.1016/S0364-0213(03)00010-7},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Steyvers et al/Steyvers et al. - 2003 - Inferring causal networks from observations and interventions.pdf:pdf},
isbn = {1949824764},
issn = {03640213},
keywords = {Active learning,Bayesian models,Bayesian networks,Causal reasoning,Computer simulation,Decision making,Human experimentation,Hypothesis testing,Interventions,Observational learning,Rational inference,Structure learning,Web experiments},
number = {3},
pages = {453--489},
title = {{Inferring causal networks from observations and interventions}},
volume = {27},
year = {2003}
}
@inproceedings{Menager2016,
address = {Austin},
author = {Menager, David Henri and Choi, Dongkyu},
booktitle = {Proceedings of the 38th Annual Conference of the Cognitive Science Society},
editor = {Papafragou, A. and Grodner, D. and Mirman, D. and Trueswell, J.C.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 38th Annual Conference of the Cognitive Science Society/Menager, Choi/Menager, Choi - 2016 - A Robust Implementation of Episodic Memory for a Cognitive Architecture.pdf:pdf},
keywords = {cognitive architectures,episodic memory,expectations,impasse resolution,sensing,virtual},
pages = {620--625},
publisher = {Cognitive Science Society},
title = {{A Robust Implementation of Episodic Memory for a Cognitive Architecture}},
year = {2016}
}
@article{Aoun2014,
author = {Aoun, Mario Antoine and Boukadoum, Mounir},
doi = {10.1109/ICCI-CC.2014.6921451},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing/Aoun, Boukadoum/Aoun, Boukadoum - 2014 - Learning algorithm and neurocomputing architecture for NDS Neurons.pdf:pdf},
isbn = {978-1-4799-6081-1},
journal = {2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing},
keywords = {chaos control,chaotic spiking neural network,inputs to a pool,liquid,nds neuron,nonlinear transient computation,of,online signature verification,property,sp mentions that different,state machines,stdp},
pages = {126--132},
publisher = {Ieee},
title = {{Learning algorithm and neurocomputing architecture for NDS Neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6921451},
year = {2014}
}
@article{Cisek2007,
author = {Cisek, P.},
doi = {10.1098/rstb.2007.2054},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Philosophical Transactions of the Royal Society B Biological Sciences/Cisek/Cisek - 2007 - Cortical mechanisms of action selection the affordance competition hypothesis.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {action selection,cerebral cortex,computational modelling,decision making},
number = {1485},
pages = {1585--1599},
title = {{Cortical mechanisms of action selection: the affordance competition hypothesis}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2007.2054},
volume = {362},
year = {2007}
}
@article{Kappel2017,
abstract = {Synaptic connections between neurons in the brain are dynamic because of continuously ongoing spine dynamics, axonal sprouting, and other processes. In fact, it was recently shown that the spontaneous synapse-autonomous component of spine dynamics is at least as large as the component that depends on the history of pre- and postsynaptic neural activity. These data are inconsistent with common models for network plasticity, and raise the questions how neural circuits can maintain a stable computational function in spite of these continuously ongoing processes, and what functional uses these ongoing processes might have. Here, we present a rigorous theoretical framework for these seemingly stochastic spine dynamics and rewiring processes in the context of reward-based learning tasks. We show that spontaneous synapse-autonomous processes, in combination with reward signals such as dopamine, can explain the capability of networks of neurons in the brain to configure themselves for specific computational tasks, and to compensate automatically for later changes in the network or task. Furthermore we show theoretically and through computer simulations that stable computational performance is compatible with continuously ongoing synapse-autonomous changes. After reaching good computational performance it causes primarily a slow drift of network architecture and dynamics in task-irrelevant dimensions, as observed for neural activity in motor cortex and other areas. On the more abstract level of reinforcement learning the resulting model gives rise to an understanding of reward-driven network plasticity as continuous sampling of network configurations.},
archivePrefix = {arXiv},
arxivId = {1704.04238},
author = {Kappel, David and Legenstein, Robert and Habenschuss, Stefan and Hsieh, Michael and Maass, Wolfgang},
doi = {10.1523/ENEURO.0301-17.2018},
eprint = {1704.04238},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Kappel et al/Kappel et al. - 2017 - A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-ba.pdf:pdf},
issn = {2373-2822},
keywords = {control,processes,reward-modulated stdp,spine dynamics,stochastic synaptic plasticity,synapse-autonomous,synaptic rewiring,task-irrelevant dimensions in motor},
number = {April},
pages = {1--27},
title = {{A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning}},
url = {http://arxiv.org/abs/1704.04238},
volume = {5},
year = {2017}
}
@article{Zhang2015,
author = {Zhang, Yunfeng and Paik, Jaehyon and Pirolli, Peter},
doi = {10.1111/tops.12143},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Topics in Cognitive science/Zhang, Paik, Pirolli/Zhang, Paik, Pirolli - 2015 - Reinforcement Learning and Counterfactual Reasoning Explain Adaptive Behavior in a Changing Environment.pdf:pdf},
journal = {Topics in Cognitive science},
keywords = {change detection,cognitive,counterfactual reasoning,modeling,optimal foraging,reinforcement learning},
number = {2},
pages = {368--381},
title = {{Reinforcement Learning and Counterfactual Reasoning Explain Adaptive Behavior in a Changing Environment}},
volume = {7},
year = {2015}
}
@inproceedings{Howard2015,
abstract = {We have created a high-fidelity model of 9 regions of the brain involved in making sense of complex and uncertain situations. Sense making is a proactive form of situation awareness requiring sifting through information of various types to form hypotheses about evolving situations. The MINDS model (Mirroring Intelligence in a Neural Description of Sensemaking) reveals the neural principles and cognitive tradeoffs that explain weaknesses in human reasoning and decision-making.},
author = {Howard, Michael D. and Bhattacharyya, Rajan and Chelian, Suhas E. and Phillips, Matthew E. and Pilly, Praveen K. and Ziegler, Matthias D.},
booktitle = {2015 IEEE Aerospace Conference},
doi = {10.1109/AERO.2015.7118968},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/2015 IEEE Aerospace Conference/Howard et al/Howard et al. - 2015 - The neural basis of decision-making during sensemaking Implications for human-system interaction.pdf:pdf},
isbn = {978-1-4799-5379-0},
keywords = {Brain modeling,Cognition,Computational modeling,Decision making,MINDS computational model,Semantics,Tuning,Uncertainty,brain,cognition,decision making,decision-making,human computer interaction,human-system interaction,mirroring intelligence-in-a-neural description-of-,neural nets,neural principle,situation awareness},
pages = {1--16},
publisher = {IEEE},
shorttitle = {Aerospace Conference, 2015 IEEE},
title = {{The neural basis of decision-making during sensemaking: Implications for human-system interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7118968},
year = {2015}
}
@article{Madl2014,
author = {Madl, Tamas and Chen, Ke and Montaldi, Daniela and Trappl, Robert},
doi = {10.1016/j.neunet.2015.01.002},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural Networks/Madl et al/Madl et al. - 2014 - Computational cognitive models of spatial memory a review.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {computational cognitive modeling,spatial memory models},
pages = {18--43},
publisher = {Elsevier Ltd},
title = {{Computational cognitive models of spatial memory: a review}},
url = {http://dx.doi.org/10.1016/j.neunet.2015.01.002},
volume = {65},
year = {2014}
}
@article{Francisco2011,
author = {Francisco, San},
doi = {10.1007/978-4-431-54595-8},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Francisco/Francisco - 2011 - Cognitive Neuroscience Robotics.pdf:pdf},
isbn = {978-4-431-54594-1},
keywords = {attention,attentional resources,cocktail party phenomenon,coherence theory,divided attention,feature integration theory,multitasking,orientation,selective,skill-rule-knowledge based model,spotlight,srk model,useful field of view,visual search,working memory},
pages = {1--22},
title = {{Cognitive Neuroscience Robotics}},
year = {2011}
}
@inproceedings{Drix2014,
author = {Drix, Damien and Hafner, Verena V},
booktitle = {Joint IEEE International Conference on Development and Learning},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Joint IEEE International Conference on Development and Learning/Drix, Hafner/Drix, Hafner - 2014 - Learning proprioceptive and motor features.pdf:pdf},
isbn = {9781479975402},
pages = {374--378},
title = {{Learning proprioceptive and motor features}},
year = {2014}
}
@article{Botvinick2008,
abstract = {The recognition of hierarchical structure in human behavior was one of the founding insights of the cognitive revolution. Despite decades of research, however, the computational mechanisms underlying hierarchically organized behavior are still not fully understood. Recent findings from behavioral and neuroscientific research have fueled a resurgence of interest in the problem, inspiring a new generation of computational models. In addition to developing some classic proposals, these models also break fresh ground, teasing apart different forms of hierarchical structure, placing a new focus on the issue of learning and addressing recent findings concerning the representation of behavioral hierarchies within the prefrontal cortex. In addition to offering explanations for some key aspects of behavior and functional neuroanatomy, the latest models also pose new questions for empirical research. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Botvinick, Matthew M.},
doi = {10.1016/j.tics.2008.02.009},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in Cognitive Sciences/Botvinick/Botvinick - 2008 - Hierarchical models of behavior and prefrontal function.pdf:pdf},
isbn = {1364-6613 (Print)$\backslash$n1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {5},
pages = {201--208},
pmid = {18420448},
title = {{Hierarchical models of behavior and prefrontal function}},
volume = {12},
year = {2008}
}
@unpublished{Intelligence2012,
author = {Chella, Antonio and Manzotti, Ricardo},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Chella, Manzotti/Chella, Manzotti - 2012 - Strong Artificial Intelligence and Consciousness.pdf:pdf},
pages = {2--3},
title = {{Strong Artificial Intelligence and Consciousness}},
year = {2012}
}
@article{Liu2014,
author = {Liu, Zhi and Zou, Wenbin and Li, Lina and Shen, Liquan and {Le Meur}, Olivier},
doi = {10.1109/LSP.2013.2292873},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Signal Processing Letters/Liu et al/Liu et al. - 2014 - Co-Saliency Detection Based on Hierarchical Segmentation.pdf:pdf},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
number = {1},
pages = {88--92},
title = {{Co-Saliency Detection Based on Hierarchical Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6675796},
volume = {21},
year = {2014}
}
@article{Singer2009,
abstract = {The cerebral cortex presents itself as a distributed dynamical system with the characteristics of a small world network. The neuronal correlates of cognitive and executive processes often appear to consist of the coordinated activity of large assemblies of widely distributed neurons. These features require mechanisms for the selective routing of signals across densely interconnected networks, the flexible and context dependent binding of neuronal groups into functionally coherent assemblies and the task and attention dependent integration of subsystems. In order to implement these mechanisms, it is proposed that neuronal responses should convey two orthogonal messages in parallel. They should indicate (1) the presence of the feature to which they are tuned and (2) with which other neurons (specific target cells or members of a coherent assembly) they are communicating. The first message is encoded in the discharge frequency of the neurons (rate code) and it is proposed that the second message is contained in the precise timing relationships between individual spikes of distributed neurons (temporal code). It is further proposed that these precise timing relations are established either by the timing of external events (stimulus locking) or by internal timing mechanisms. The latter are assumed to consist of an oscillatory modulation of neuronal responses in different frequency bands that cover a broad frequency range from {\textless}2 Hz (delta) to {\textgreater}40 Hz (gamma) and ripples. These oscillations limit the communication of cells to short temporal windows whereby the duration of these windows decreases with oscillation frequency. Thus, by varying the phase relationship between oscillating groups, networks of functionally cooperating neurons can be flexibly configurated within hard wired networks. Moreover, by synchronizing the spikes emitted by neuronal populations, the saliency of their responses can be enhanced due to the coincidence sensitivity of receiving neurons in very much the same way as can be achieved by increasing the discharge rate. Experimental evidence will be reviewed in support of the coexistence of rate and temporal codes. Evidence will also be provided that disturbances of temporal coding mechanisms are likely to be one of the pathophysiological mechanisms in schizophrenia.},
author = {Singer, Wolf},
doi = {10.1007/s11571-009-9087-z},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Neurodynamics/Singer/Singer - 2009 - Distributed processing and temporal codes in neuronal networks.pdf:pdf},
isbn = {1871-4080 (Print)},
issn = {1871-4080},
journal = {Cognitive Neurodynamics},
keywords = {Attention,Cerebral cortex,Feature binding,Gamma frequency,Neuronal coding,Oscillations,Response selection,Synchrony,Temporal codes},
month = {sep},
number = {3},
pages = {189--196},
pmid = {19562517},
title = {{Distributed processing and temporal codes in neuronal networks}},
url = {http://link.springer.com/10.1007/s11571-009-9087-z},
volume = {3},
year = {2009}
}
@article{Dong2011a,
abstract = {We present a new model of sensorimotor learning in a systems-level cognitive model, LIDA. Sensorimotor learning helps an agent properly interact with its environment using past experi- ences. This new model stores and updates the rewards of pairs of data, motor commands and their contexts, using the concept of reinforcement learning; thus the agent is able to generate (output) effective commands in certain contexts based on its reward history. Following Global Workspace Theory, the primary basis of LIDA, the process of updating rewards in sensorimotor learning is cued by the agent's conscious content, the most salient portion of the agent's under- standing of the current situation, issued by the Global Workspace module of LIDA. Furthermore, we add a dynamic learning rate to control the extent to which a newly arriving reward may affect the reward update. This learning rate control mechanism is inspired by a hypothesis from neuroscience regarding memory of errors. Our experimental results show that sensorimotor learning using a dynamic learning rate improves performance in a simulated movement of push- ing a box.},
author = {Dong, Daqi and Franklin, Stan},
doi = {10.1016/j.bica.2015.09.005},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Dong, Franklin/Dong, Franklin - 2015 - Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {a learning rate control,action,cognitive modeling,execution,in lida and add,in this paper,learning rate,lida 1,lida model,mechanism,sensorimotor learning,this is,we implement sensorimotor learning},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate}},
volume = {14},
year = {2015}
}
@book{Cox2011,
abstract = {The capacity to think about our own thinking may lie at the heart of what it means to be both human and intelligent. Philosophers and cognitive scientists have investigated these matters for many years. Researchers in artificial intelligence have gone further, attempting to implement actual machines that mimic, simulate, and perhaps even replicate this capacity, called metareasoning. In this volume, leading authorities offer a variety of perspectives--drawn from philosophy, cognitive psychology, and computer science--on reasoning about the reasoning process. The book offers a simple model of reasoning about reason as a framework for its discussions. Following this framework, the contributors consider metalevel control of computational activities, introspective monitoring, distributed metareasoning, and, putting all these aspects of metareasoning together, models of the self. Taken together, the chapters offer an integrated narrative on metareasoning themes from both artificial intelligence and cognitive science perspectives.},
doi = {10.7551/mitpress/9780262014809.001.0001},
editor = {Cox, Michael T. and Raja, Anita},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Unknown/Unknown - 2011 - Metareasoning Thinking about thinking.pdf:pdf},
isbn = {9780262014809},
pages = {340},
publisher = {The MIT Press},
title = {{Metareasoning: Thinking about thinking}},
year = {2011}
}
@article{Hasselmo2006,
author = {Howard, Marc W. and Fotedar, Mrigankka S. and Datey, Aditya V. and Hasselmo, Michael E.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Psychology Review/Howard et al/Howard et al. - 2005 - The Temporal Context Model in spatial navigation and relational learning Toward a common explanation of medial te.pdf:pdf},
journal = {Psychology Review},
number = {1},
pages = {75--116},
title = {{The Temporal Context Model in spatial navigation and relational learning: Toward a common explanation of medial temporal lobe function across domains}},
volume = {112},
year = {2005}
}
@incollection{Dobnik2013,
author = {Dobnik, Simon and Cooper, Robin},
booktitle = {Constraint Solving and Language Processing},
doi = {10.1007/978-3-642-41578-4_5},
editor = {Duchier, Denys and Parmentier, Yannick},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Constraint Solving and Language Processing/Dobnik, Cooper/Dobnik, Cooper - 2013 - Modelling language, action, and perception in Type Theory with Records.pdf:pdf},
keywords = {action,formal semantics,language,learning and classification,perception,scriptions,spatial de-},
pages = {70--91},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling language, action, and perception in Type Theory with Records}},
year = {2013}
}
@article{Walther2006,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural networks/Walther, Koch/Walther, Koch - 2006 - Modeling attention to salient proto-objects.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Attention,Biological,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models,Neural Networks (Computer),Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,ROC Curve,Visual,Visual: physiology},
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling attention to salient proto-objects}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17098563},
volume = {19},
year = {2006}
}
@article{Murray2017,
abstract = {Working memory (WM) and decision making (DM) are fundamental cognitive functions involving a distributed interacting network of brain areas, with the posterior parietal and prefrontal cortices (PPC and PFC) at the core. However, the shared and distinct roles of these areas and the nature of their coordination in cognitive function remain poorly understood. Biophysically-based computational models of cortical circuits have provided insights into the mechanisms supporting these functions, yet they have primarily focused on the local microcircuit level, raising questions about the principles for distributed cognitive computation in multi-regional networks. To examine these issues, we developed a distributed circuit model of two reciprocally interacting modules representing PPC and PFC circuits. The circuit architecture includes hierarchical differences in local recurrent structure and implements reciprocal long-range projections. This parsimonious model captures a range of behavioral and neuronal features of fronto-parietal circuits across multiple WM and DM paradigms. In the context of WM, both areas exhibit persistent activity, but in response to intervening distractors, PPC transiently encodes distractors, while PFC filters distractors and supports WM robustness. With regards to DM, the PPC module generates graded representations of accumulated evidence supporting target selection, while the PFC module generates more categorical responses related to action or choice. These findings suggest computational principles for distributed, hierarchical processing in cortex during cognitive function, and provide a framework for extension to multi-regional models.},
author = {Murray, John D and Jaramillo, Jorge and Wang, Xiao-Jing},
doi = {10.1523/JNEUROSCI.0343-17.2017},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/The Journal of Neuroscience/Murray, Jaramillo, Wang/Murray, Jaramillo, Wang - 2017 - Working Memory and Decision-Making in a Frontoparietal Circuit Model.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
month = {dec},
number = {50},
pages = {12167--12186},
title = {{Working Memory and Decision-Making in a Frontoparietal Circuit Model}},
url = {https://www.biorxiv.org/content/early/2017/02/06/104802 http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0343-17.2017},
volume = {37},
year = {2017}
}
@article{Triesman1980,
author = {Triesman, A. M. and Gelade, G.},
journal = {Cognitive Psyhology},
pages = {97--136},
title = {{A Feature Integration Theory of Attention}},
volume = {12},
year = {1980}
}
@article{Llinas1998a,
author = {Llinas, R. and Ribary, U. and Contreras, D. and Pedroarena, C.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Philosophical transactions of the Royal Society of London. Series B. Biological sciences/Llinas et al/Llinas et al. - 1998 - The neuronal basis for consciousness.pdf:pdf},
journal = {Philosophical transactions of the Royal Society of London. Series B. Biological sciences},
keywords = {coincidence detection,consciousness,facilitation,gamma oscillations,thalamocortical,voltage sensitive dye},
number = {353},
pages = {1841--1849},
title = {{The neuronal basis for consciousness}},
volume = {353},
year = {1998}
}
@article{Takac2015,
author = {Takac, Martin and Knott, Alistair and Knott, Alistair},
doi = {10.1007/s12559-015-9330-3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Computation/Takac, Knott, Knott/Takac, Knott, Knott - 2015 - A Neural Network Model of Episode Representations in Working Memory.pdf:pdf},
issn = {1866-9964},
journal = {Cognitive Computation},
keywords = {Action preparation,Language processing,Neural network modelling,Sequence learning,Working memory,modelling {\'{a}} sequence learning,network,working memory {\'{a}} neural,{\'{a}} action preparation {\'{a}}},
pages = {1--17},
publisher = {Springer US},
title = {{A Neural Network Model of Episode Representations in Working Memory}},
year = {2015}
}
@incollection{Osaka2016,
abstract = {‘Working memory' refers to the capacity-constrained active memory in which information is temporarily maintained and concurrently processed for the use in an ongoing goal-directed activity. The neural mechanisms responsible for con- sciousness are located in certain brain regions, such as the DLPFC, PPC TPJ and ACC, and these brain regions are coupled with a network that includes the central executive of working memory. In this chapter, we explore the nature of the neural basis of working memory and try to explain the mechanisms of working memory. In order to understand the neural basis of active consciousness, we also investigate how information is controlled by the neural basis of working memory. We use reading span test (RST), which measures the working memory capacity to memo- rize the target words of sentences during reading, to measure individual differences in working memory capacity.},
author = {Osaka, Mariko},
booktitle = {Cognitive Neuroscience Robotics B},
doi = {10.1007/978-4-431-54598-9_3},
editor = {Kasaki, Masashi and Ishiguro, Hiroshi and Asada, Minoru and Osaka, Mariko and Fujikado, Takashi},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Neuroscience Robotics B/Osaka/Osaka - 2016 - Working Memory as a Basis of Consciousness.pdf:pdf},
isbn = {978-4-431-54594-1},
pages = {39--57},
publisher = {Springer Japan},
title = {{Working Memory as a Basis of Consciousness}},
url = {http://link.springer.com/10.1007/978-4-431-54598-9{\_}3},
year = {2016}
}
@article{Treur2016,
author = {Treur, Jan},
doi = {10.1016/j.bica.2016.02.002},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Treur/Treur - 2016 - Dynamic modeling based on a temporal–causal network modeling approach.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
pages = {131--168},
publisher = {Elsevier B.V.},
title = {{Dynamic modeling based on a temporal–causal network modeling approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300147},
volume = {16},
year = {2016}
}
@article{Lamme2003,
abstract = {Now that the study of consciousness is warmly embraced by cognitive scientists, much confusion seems to arise between the concepts of visual attention and visual awareness. Often, visual awareness is equated to what is in the focus of attention. There are, however, two sets of arguments to separate attention from awareness: a psychological/theoretical one and a neurobiological one. By combining these arguments I present definitions of visual attention and awareness that clearly distinguish between the two, yet explain why attention and awareness are so intricately related. In fact, there seems more overlap between mechanisms of memory and awareness than between those of attention and awareness.},
author = {Lamme, V. a F},
doi = {10.1016/S1364-6613(02)00013-X},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in Cognitive Sciences/Lamme/Lamme - 2003 - Why visual attention and awareness are different.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {1},
pages = {12--18},
pmid = {12517353},
title = {{Why visual attention and awareness are different}},
volume = {7},
year = {2003}
}
@inproceedings{Ragni2012,
author = {Ragni, Marco and Neubert, Stefanie},
booktitle = {ECAI 2012: 20h European Conference on Artificial Intelligence: Proceedings},
doi = {10.3233/978-1-61499-098-7-666},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/ECAI 2012 20h European Conference on Artificial Intelligence Proceedings/Ragni, Neubert/Ragni, Neubert - 2012 - Solving Raven's IQ-tests An AI and Cognitive Modeling Approach.pdf:pdf},
isbn = {9781614990987},
pages = {666--671},
title = {{Solving Raven's IQ-tests : An AI and Cognitive Modeling Approach}},
year = {2012}
}
@article{Vartanov2011,
author = {Вартанов, А. В.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Нейрокомпьютеры разработка, применение/Вартанов/Вартанов - 2011 - Механизмы семантики человек - нейрон - модель.pdf:pdf},
journal = {Нейрокомпьютеры: разработка, применение},
keywords = {coding,consciousness,meaning,semantics,sign},
language = {russian},
number = {12},
pages = {54--64},
title = {{Механизмы семантики: человек - нейрон - модель}},
year = {2011}
}
@article{Gopnik2004,
abstract = {The authors outline a cognitive and computational account of causal learning in children. They propose that children use specialized cognitive systems that allow them to recover an accurate “causal map” of the world: an abstract, coherent, learned representation of the causal relations among events. This kind of knowledge can be perspicuously understood in terms of the formalism of directed graphical causal models, or Bayes nets. Children's causal learning and inference may involve computations similar to those for learning causal Bayes nets and for predicting with them. Experimental results suggest that 2to 4-year-old children construct new causal maps and that their learning is consistent with the Bayes net formalism.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gopnik, A and Glymour, C and Sobel, D M and Schulz, L E and Kushnir, T and Danks, D},
doi = {10.1037/0033-295X.111.1.3},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Psychological Review/Gopnik et al/Gopnik et al. - 2004 - A theory of causal learning in children.pdf:pdf},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {SLC, complex systems},
pages = {3--32},
pmid = {14756583},
title = {{A theory of causal learning in children}},
year = {2004}
}
@article{Zeng2017,
author = {Zeng, Yi and Zhao, Yuxuan and Bai, Jun and Xu, Bo},
doi = {10.1007/s12559-017-9505-1},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Computation/Zeng et al/Zeng et al. - 2017 - Toward Robot Self-Consciousness (II) Brain-Inspired Robot Bodily Self Model for Self-Recognition.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {model,robot bodily self,robot self-consciousness,self-recognition,stdp learning},
month = {aug},
title = {{Toward Robot Self-Consciousness (II): Brain-Inspired Robot Bodily Self Model for Self-Recognition}},
url = {http://link.springer.com/10.1007/s12559-017-9505-1},
year = {2017}
}
@article{Frank2012,
abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
author = {Frank, Michael J. and Badre, David},
doi = {10.1093/cercor/bhr114},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cerebral cortex (New York, N.Y. 1991)/Frank, Badre/Frank, Badre - 2012 - Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1 Computational analysis.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Computer Simulation,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Humans,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reinforcement (Psychology)},
number = {3},
pages = {509--26},
pmid = {21693490},
title = {{Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3278315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {22},
year = {2012}
}
@article{Ivanitsky1996,
author = {Иваницкий, А. М.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Журнал высшей нервной деятельности/Иваницкий/Иваницкий - 1996 - Мозговая основа субъективных переживаний гипотеза информационного синтеза.pdf:pdf},
journal = {Журнал высшей нервной деятельности},
language = {russian},
number = {2},
pages = {241--282},
title = {{Мозговая основа субъективных переживаний: гипотеза информационного синтеза}},
volume = {46},
year = {1996}
}
@article{Fernando2013,
abstract = {How do human infants learn the causal dependencies between events? Evidence suggests that this remarkable feat can be achieved by observation of only a handful of examples. Many computational models have been produced to explain how infants perform causal inference without explicit teaching about statistics or the scientific method. Here, we propose a spiking neuronal network implementation that can be entrained to form a dynamical model of the temporal and causal relationships between events that it observes. The network uses spike-time dependent plasticity, long-term depression, and heterosynaptic competition rules to implement Rescorla-Wagner-like learning. Transmission delays between neurons allow the network to learn a forward model of the temporal relationships between events. Within this framework, biologically realistic synaptic plasticity rules account for well-known behavioral data regarding cognitive causal assumptions such as backwards blocking and screening-off. These models can then be run as emulators for state inference. Furthermore, this mechanism is capable of copying synaptic connectivity patterns between neuronal networks by observing the spontaneous spike activity from the neuronal circuit that is to be copied, and it thereby provides a powerful method for transmission of circuit functionality between brain regions.},
author = {Fernando, Chrisantha},
doi = {10.1111/cogs.12073},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive science/Fernando/Fernando - 2013 - From blickets to synapses inferring temporal causal networks by observation.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {backwards blocking,causal inference,groups,neuronal replicator hypothesis,polychronous,rational process model,screening-off},
number = {8},
pages = {1426--70},
pmid = {23957457},
title = {{From blickets to synapses: inferring temporal causal networks by observation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23957457},
volume = {37},
year = {2013}
}
@article{Ring2011,
abstract = {This paper addresses the problem of continual learning [1] in a new way, combining multi-modular reinforcement learning with inspiration from the motor cortex to produce a unique perspective on hierarchical behavior. Most reinforcement-learning agents represent policies monolithically using a single table or function approximator. In those cases where the policies are split among a few different modules, these modules are related to each other only in that they work together to produce the agent's overall policy. In contrast, the brain appears to organize motor behavior in a two-dimensional map, where nearby locations represent similar behaviors. This representation allows the brain to build hierarchies of motor behavior that correspond not to hierarchies of subroutines but to regions of the map such that larger regions correspond to more general behaviors. Inspired by the benefits of the brain's representation, the system presented here is a first step and the first attempt toward the two-dimensional organization of learned policies according to behavioral similarity. We demonstrate a fully autonomous multi-modular system designed for the constant accumulation of ever more sophisticated skills (the continual-learning problem). The system can split up a complex task among a large number of simple modules such that nearby modules correspond to similar policies. The eventual goal is to develop and use the resulting organization hierarchically, accessing behaviors by their location and extent in the map.},
author = {Ring, Mark and Schaul, Tom and Schmidhuber, Juergen},
doi = {10.1109/DEVLRN.2011.6037326},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/2011 IEEE International Conference on Development and Learning, ICDL 2011/Ring, Schaul, Schmidhuber/Ring, Schaul, Schmidhuber - 2011 - The two-dimensional organization of behavior.pdf:pdf},
isbn = {9781612849904},
issn = {2161-9476},
journal = {2011 IEEE International Conference on Development and Learning, ICDL 2011},
pages = {1--8},
title = {{The two-dimensional organization of behavior}},
volume = {2},
year = {2011}
}
@article{Babichev2018,
abstract = {Hippocampal cognitive map---a neuronal representation of the spatial environment---is broadly discussed in the computational neuroscience literature for decades. More recent studies point out that hippocampus plays a major role in producing yet another cognitive framework that incorporates not only spatial, but also nonspatial memories---the memory space. However, unlike cognitive maps, memory spaces have been barely studied from a theoretical perspective. Here we propose an approach for modeling hippocampal memory spaces as an epiphenomenon of neuronal spiking activity. First, we suggest that the memory space may be viewed as a finite topological space---a hypothesis that allows treating both spatial and nonspatial aspects of hippocampal function on equal footing. We then model the topological properties of the memory space to demonstrate that this concept naturally incorporates the notion of a cognitive map. Lastly, we suggest a formal description of the memory consolidation process and point out a connection between the proposed model of the memory spaces to the so-called Morris' schemas, which emerge as the most compact representation of the memory structure.},
author = {Babichev, Andrey and Dabaghian, Yuri A.},
doi = {10.3389/fncom.2018.00027},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Frontiers in Computational Neuroscience/Babichev, Dabaghian/Babichev, Dabaghian - 2018 - Topological Schemas of Memory Spaces.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {cell assemblies,cognitive map,hippocampus,memory space,place cells,topology},
month = {apr},
pages = {1--16},
title = {{Topological Schemas of Memory Spaces}},
url = {http://arxiv.org/abs/1710.05967 http://journal.frontiersin.org/article/10.3389/fncom.2018.00027/full},
volume = {12},
year = {2018}
}
@article{Simoes2015,
abstract = {Understanding consciousness is one of the most fasci- nating challenges of our time. Fromancient civilizations to modern philosophers, questions have been asked on howone is conscious of his/her own existence and about theworld that surrounds him/her. Although there is no precise definition for consciousness, there is an agreement that it is strongly related to human cognitive pro- cesses such as attention, a process capable of promoting a selection of a few stimuli from a huge amount of information that reaches us constantly. In order to bring the consciousness discussion to a com- putational scenario, this paper presents conscious attention-based integrated model (CONAIM), a formal model for machine con- sciousness based on an attentional schema for human-like agent cognition that integrates: short- and long-term memories, rea- soning, planning, emotion, decision-making, learning, motivation, and volition. Experimental results in a mobile robotics domain show that the agent can attentively use motivation, volition, and memories to set its goals and learn new concepts and procedures based on exogenous and endogenous stimuli. By performing com- putation over an attentional space, the model also allowed the agent to learn over a much reduced state space. Further imple- mentation under this model could potentially allow the agent to express sentience, self-awareness, self-consciousness, autonoetic consciousness, mineness, and perspectivalness.},
author = {Simoes, Alexandre and Colmbini, Esther and Ribeiro, Carlos},
doi = {10.1109/JSYST.2015.2498542},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Systems Journal/Simoes, Colmbini, Ribeiro/Simoes, Colmbini, Ribeiro - 2016 - CONAIM A Conscious Attention-Based Integrated Model for Human-Like Robots.pdf:pdf},
issn = {19379234},
journal = {IEEE Systems Journal},
number = {99},
pages = {1--12},
title = {{CONAIM : A Conscious Attention-Based Integrated Model for Human-Like Robots}},
year = {2016}
}
@book{Kober2014,
address = {Cham},
author = {Kober, Jens and Peters, Jan},
doi = {10.1007/978-3-319-03194-1},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Kober, Peters/Kober, Peters - 2014 - Learning Motor Skills.pdf:pdf},
isbn = {978-3-319-03193-4},
publisher = {Springer International Publishing},
series = {Springer Tracts in Advanced Robotics},
title = {{Learning Motor Skills}},
url = {http://link.springer.com/10.1007/978-3-319-03194-1},
volume = {97},
year = {2014}
}
@inproceedings{Process,
abstract = {This paper shows a formal model of cognitive function of decision-making. The decision-making is only one of several cognitive functions of high level of natural intelligence. Our model has been inspired by human decision-making process. In order to show a comprehensive and coherent model of human decision-making process based on a rigorous formalism, we have adopted a multidisciplinary approach encompassing knowledge in cognitive informatics, neuroscience, and psychology. The model has been divided into conceptual, formal, and computational model. However, in this paper we show the conceptual and part of the formal model. In order to develop a comprehensive and coherent conceptual model of the decision- making process and its relationship with others cognitive processes, we have adopted the layered reference model postulated by Wang. Our conceptual model shows the main brain areas involved in the decision-making process and describes their functions. While our formal model tries to show a rigorous explanation for the cognitive decision-making process.},
author = {Process, Decision-making and Wang, Yingxu},
booktitle = {Proceedings IEEE International Conference on Cognitive Inlormatics {\&} Cognitive Computing},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings IEEE International Conference on Cognitive Inlormatics {\&} Cognitive Computing/Process, Wang/Process, Wang - 2015 - A Formal Model Inspired on Human Decision-Making Process.pdf:pdf},
isbn = {9181461312909},
keywords = {cognitive informatics,decision-making,fuzzy logic,natural intelligence},
pages = {375--383},
title = {{A Formal Model Inspired on Human Decision-Making Process}},
year = {2015}
}
@article{Yamada2015,
author = {Yamada, Tatsuro and Murata, Shingo and Arie, Hiroaki and Ogata, Tetsuya},
doi = {10.3389/fnbot.2016.00005},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Frontiers in Neurorobotics/Yamada et al/Yamada et al. - 2016 - Dynamical Integration of Language and Behavior in a Recurrent Neural Network for Human–Robot Interaction.pdf:pdf},
isbn = {978-1-4799-9994-1},
issn = {1662-5218},
journal = {Frontiers in Neurorobotics},
keywords = {dynamical system approach,human,language learning,recurrent neural networks,robot interaction,sequence to sequence learning,symbol grounding problem},
month = {jul},
pages = {4179--4184},
publisher = {IEEE},
title = {{Dynamical Integration of Language and Behavior in a Recurrent Neural Network for Human–Robot Interaction}},
url = {http://ieeexplore.ieee.org/document/7353968/ http://journal.frontiersin.org/Article/10.3389/fnbot.2016.00005/abstract},
volume = {10},
year = {2016}
}
@article{Chernavsky2012b,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Сложные системы/Чернавская et al/Чернавская et al. - 2012 - Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {2},
pages = {25--41},
title = {{Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления}},
volume = {1},
year = {2012}
}
@article{Chernavsky2012a,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Сложные системы/Чернавская et al/Чернавская et al. - 2012 - Процесс мышления в контексте динамической теории информации. Часть II понятие «образ» и «символ» как инструме.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {3},
pages = {46--65},
title = {{Процесс мышления в контексте динамической теории информации. Часть II: понятие «образ» и «символ» как инструменты моделирования процесса мышления средствами нейрокомпьютинга}},
volume = {2},
year = {2012}
}
@article{Rasmussen2011,
abstract = {Abstract Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method ... $\backslash$n},
author = {Rasmussen, Daniel and Eliasmith, Chris},
doi = {10.1111/j.1756-8765.2010.01127.x},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Topics in Cognitive Science/Rasmussen, Eliasmith/Rasmussen, Eliasmith - 2011 - A neural model of rule generation in inductive reasoning.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Cognitive modeling,Fluid intelligence,Inductive reasoning,Neural engineering framework,Raven's progressive matrices,Realistic neural modeling,Rule generation,Vector symbolic architectures},
number = {1},
pages = {140--153},
title = {{A neural model of rule generation in inductive reasoning}},
volume = {3},
year = {2011}
}
@unpublished{Velichkovsky2017,
author = {Velichkovsky, B. M. and Krotkova, O. A. and Sharaev, M. G. and Ushakov, V. L.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Velichkovsky et al/Velichkovsky et al. - 2017 - In search of the I Neuropsychology of lateralized thinking meets Dynamic Causal Modeling.pdf:pdf},
title = {{In search of the "I": Neuropsychology of lateralized thinking meets Dynamic Causal Modeling}},
year = {2017}
}
@article{Franklin1999,
author = {Franklin, S. and Graesser, A.},
journal = {Conscious Cognition},
number = {8},
pages = {285--301},
title = {{A software agent model of consciousness}},
year = {1999}
}
@article{Minami2001,
author = {Minami, T. and Inui, T.},
doi = {10.1007/s12559-015-9330-3},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Connectionist Models of Neurons, Learning Processes, and Artificial Intelligence/Minami, Inui/Minami, Inui - 2001 - A Neural Network Model of Working Memory.pdf:pdf},
issn = {18669964},
journal = {Connectionist Models of Neurons, Learning Processes, and Artificial Intelligence},
keywords = {Action preparation,Language processing,Neural network modelling,Sequence learning,Working memory,modelling {\'{a}} sequence learning,network,working memory {\'{a}} neural,{\'{a}} action preparation {\'{a}}},
pages = {126--133},
publisher = {Springer US},
title = {{A Neural Network Model of Working Memory}},
url = {http://www.springerlink.com/index/NW4NLH1ME9PJ8JQY.pdf},
year = {2001}
}
@article{Bruce2009,
abstract = {A proposal for saliency computation within the visual cortex is put forth based on the premise that localized saliency computation serves to maximize information sampled from one's environment. The model is built entirely on computational constraints but nevertheless results in an architecture with cells and connectivity reminiscent of that appearing in the visual cortex. It is demonstrated that a variety of visual search behaviors appear as emergent properties of the model and therefore basic principles of coding and information transmission. Experimental results demonstrate greater efficacy in predicting fixation patterns across two different data sets as compared with competing models.},
author = {Bruce, Neil D. B. and Tsotsos, John K.},
doi = {10.1167/9.3.5},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Journal of Vision/Bruce, Tsotsos/Bruce, Tsotsos - 2009 - Saliency, attention, and visual search An information theoretic approach.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
number = {9},
pages = {1--24},
pmid = {19757944},
title = {{Saliency, attention, and visual search: An information theoretic approach}},
url = {http://journalofvision.org/9/3/5/article.aspx},
volume = {3},
year = {2009}
}
@article{Glenberg2012,
abstract = {Evolution and the brain have done a marvelous job solving many tricky problems in action control, including problems of learning, hierarchical control over serial behavior, continuous recalibration, and fluency in the face of slow feedback. Given that evolution tends to be conservative, it should not be surprising that these solutions are exploited to solve other tricky problems, such as the design of a communication system. We propose that a mechanism of motor control, paired controller/predictor models, has been exploited for language learning, comprehension, and production. Our account addresses the development of grammatical regularities and perspective, as well as how linguistic symbols become meaningful through grounding in perception, action, and emotional systems. ?? 2011 Elsevier Srl.},
author = {Glenberg, Arthur M. and Gallese, Vittorio},
doi = {10.1016/j.cortex.2011.04.010},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cortex/Glenberg, Gallese/Glenberg, Gallese - 2012 - Action-based language A theory of language acquisition, comprehension, and production.pdf:pdf},
isbn = {1973-8102 (Electronic)$\backslash$r0010-9452 (Linking)},
issn = {00109452},
journal = {Cortex},
keywords = {Embodiment,HMOSAIC model of action control,Language,Mirror neurons},
number = {7},
pages = {905--922},
pmid = {21601842},
publisher = {Elsevier Srl},
title = {{Action-based language: A theory of language acquisition, comprehension, and production}},
url = {http://dx.doi.org/10.1016/j.cortex.2011.04.010},
volume = {48},
year = {2012}
}
@article{Battaglia2011,
abstract = {After acquisition, memories underlie a process of consolidation, making them more resistant to interference and brain injury. Memory consolidation involves systems-level interactions, most importantly between the hippocampus and associated structures, which takes part in the initial encoding of memory, and the neocortex, which supports long-term storage. This dichotomy parallels the contrast between episodic memory (tied to the hippocampal formation), collecting an autobiographical stream of experiences, and semantic memory, a repertoire of facts and statistical regularities about the world, involving the neocortex at large. Experimental evidence points to a gradual transformation of memories, following encoding, from an episodic to a semantic character. This may require an exchange of information between different memory modules during inactive periods. We propose a theory for such interactions and for the formation of semantic memory, in which episodic memory is encoded as relational data. Semantic memory is modeled as a modified stochastic grammar, which learns to parse episodic configurations expressed as an association matrix. The grammar produces tree-like representations of episodes, describing the relationships between its main constituents at multiple levels of categorization, based on its current knowledge of world regularities. These regularities are learned by the grammar from episodic memory information, through an expectation-maximization procedure, analogous to the inside-outside algorithm for stochastic context-free grammars. We propose that a Monte-Carlo sampling version of this algorithm can be mapped on the dynamics of "sleep replay" of previously acquired information in the hippocampus and neocortex. We propose that the model can reproduce several properties of semantic memory such as decontextualization, top-down processing, and creation of schemata.},
author = {Battaglia, Francesco P. and Pennartz, Cyriel M. A.},
doi = {10.3389/fncom.2011.00036},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Frontiers in computational neuroscience/Battaglia, Pennartz/Battaglia, Pennartz - 2011 - The construction of semantic memory grammar-based representations learned from relational episodic informat.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {episodic memory,memory consolidation,sleep r,sleep replay,stochastic grammars},
number = {August},
pages = {36},
pmid = {21887143},
title = {{The construction of semantic memory: grammar-based representations learned from relational episodic information}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3157741{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Paraense2016,
abstract = {In this work, we present a distributed cognitive architecture used to control the traffic in an urban network. This architecture relies on a machine consciousness approach – Global Work- space Theory – in order to use competition and broadcast, allowing a group of local traffic con- trollers to interact, resulting in a better group performance. The main idea is that the local controllers usually perform a purely reactive behavior, defining the times of red and green lights, according just to local information. These local controllers compete in order to define which of them is experiencing the most critical traffic situation. The controller in the worst condition gains access to the global workspace, further broadcasting its condition (and its loca- tion) to all other controllers, asking for their help in dealing with its situation. This call from the controller accessing the global workspace will cause an interference in the reactive local behavior, for those local controllers with some chance in helping the controller in a critical con- dition, by containing traffic in its direction. This group behavior, coordinated by the global workspace strategy, turns the once reactive behavior into a kind of deliberative one. We show that this strategy is capable of improving the overall mean travel time of vehicles flowing through the urban network. A consistent gain in performance with the ‘‘Artificial Consciousness” traffic signal controller during all simulation time, throughout different simulated scenarios, could be observed, ranging from around 13.8{\%} to more than 21{\%}.},
author = {Paraense, Andr{\'{e}} Luis O. and Raizer, Klaus and Gudwin, Ricardo R.},
doi = {10.1016/j.bica.2015.10.001},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Paraense, Raizer, Gudwin/Paraense, Raizer, Gudwin - 2016 - A machine consciousness approach to urban traffic control.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {global workspace theory,machine consciousness,traffic lights control},
pages = {61--73},
title = {{A machine consciousness approach to urban traffic control}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000614},
volume = {15},
year = {2016}
}
@article{Schrodt2017a,
author = {Schrodt, Fabian and Kneissler, Jan and Ehrenfeld, Stephan and Butz, Martin V.},
doi = {10.1111/tops.12252},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Topics in Cognitive Science/Schrodt et al/Schrodt et al. - 2017 - Mario Becomes Cognitive.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {artificial intelligence,cognitive architecture,cognitive science and games,self-},
pages = {1--31},
title = {{Mario Becomes Cognitive}},
url = {http://doi.wiley.com/10.1111/tops.12252},
year = {2017}
}
@article{Itti2001,
abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
author = {Itti, L and Koch, C},
doi = {10.1038/35058500},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Nature reviews. Neuroscience/Itti, Koch/Itti, Koch - 2001 - Computational modelling of visual attention.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: metabolism,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {3},
pages = {194--203},
pmid = {11256080},
title = {{Computational modelling of visual attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11256080},
volume = {2},
year = {2001}
}
@article{Baars2005a,
abstract = {Global workspace (GW) theory emerged from the cognitive architecture tradition in cognitive science. Newell and co-workers were the first to show the utility of a GW or "blackboard" architecture in a distributed set of knowledge sources, which could cooperatively solve problems that no single constituent could solve alone. The empirical connection with conscious cognition was made by Baars (1988, 2002). GW theory generates explicit predictions for conscious aspects of perception, emotion, motivation, learning, working memory, voluntary control, and self systems in the brain. It has similarities to biological theories such as Neural Darwinism and dynamical theories of brain functioning. Functional brain imaging now shows that conscious cognition is distinctively associated with wide spread of cortical activity, notably toward frontoparietal and medial temporal regions. Unconscious comparison conditions tend to activate only local regions, such as visual projection areas. Frontoparietal hypometabolism is also implicated in unconscious states, including deep sleep, coma, vegetative states, epileptic loss of consciousness, and general anesthesia. These findings are consistent with the GW hypothesis, which is now favored by a number of scientists and philosophers.},
author = {Baars, Bernard J.},
doi = {10.1016/S0079-6123(05)50004-9},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Progress in Brain Research/Baars/Baars - 2005 - Global workspace theory of consciousness toward a cognitive neuroscience of human experience.pdf:pdf},
isbn = {1925283267},
issn = {0079-6123},
journal = {Progress in Brain Research},
keywords = {Cognition,Cognition: physiology,Consciousness,Consciousness: physiology,Humans,Models,Neurosciences,Psychological},
pages = {45--53},
pmid = {16186014},
title = {{Global workspace theory of consciousness: toward a cognitive neuroscience of human experience}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16186014},
volume = {150},
year = {2005}
}
@article{Fitch2014,
abstract = {Progress in understanding cognition requires a quantitative, theoretical framework, grounded in the other natural sciences and able to bridge between implementational, algorithmic and computational levels of explanation. I review recent results in neuroscience and cognitive biology that, when combined, provide key components of such an improved conceptual framework for contemporary cognitive science. Starting at the neuronal level, I first discuss the contemporary realization that single neurons are powerful tree-shaped computers, which implies a reorientation of computational models of learning and plasticity to a lower, cellular, level. I then turn to predictive systems theory (predictive coding and prediction-based learning) which provides a powerful formal framework for understanding brain function at a more global level. Although most formal models concerning predictive coding are framed in associationist terms, I argue that modern data necessitate a reinterpretation of such models in cognitive terms: as model-based predictive systems. Finally, I review the role of the theory of computation and formal language theory in the recent explosion of comparative biological research attempting to isolate and explore how different species differ in their cognitive capacities. Experiments to date strongly suggest that there is an important difference between humans and most other species, best characterized cognitively as a propensity by our species to infer tree structures from sequential data. Computationally, this capacity entails generative capacities above the regular (finite-state) level; implementationally, it requires some neural equivalent of a push-down stack. I dub this unusual human propensity "dendrophilia", and make a number of concrete suggestions about how such a system may be implemented in the human brain, about how and why it evolved, and what this implies for models of language acquisition. I conclude that, although much remains to be done, a neurally-grounded framework for theoretical cognitive science is within reach that can move beyond polarized debates and provide a more adequate theoretical future for cognitive biology. {\textcopyright} 2014.},
author = {Fitch, W. Tecumseh},
doi = {10.1016/j.plrev.2014.04.005},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Physics of Life Reviews/Fitch/Fitch - 2014 - Toward a computational framework for cognitive biology Unifying approaches from cognitive neuroscience and comparative co.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {Cognitive science,Comparative cognition,Computational neuroscience,Formal language theory,Mathematical psychology,Neurolinguistics},
number = {3},
pages = {329--364},
pmid = {24969660},
publisher = {Elsevier B.V.},
title = {{Toward a computational framework for cognitive biology: Unifying approaches from cognitive neuroscience and comparative cognition}},
url = {http://dx.doi.org/10.1016/j.plrev.2014.04.005},
volume = {11},
year = {2014}
}
@article{Griffiths2010,
abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.},
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in cognitive sciences/Griffiths et al/Griffiths et al. - 2010 - Probabilistic models of cognition exploring representations and inductive biases.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Bias (Epidemiology),Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Models,Predictive Value of Tests,Probability,Psychological},
number = {8},
pages = {357--64},
pmid = {20576465},
publisher = {Elsevier Ltd},
title = {{Probabilistic models of cognition: exploring representations and inductive biases}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20576465},
volume = {14},
year = {2010}
}
@inproceedings{Rasmussen1998,
author = {Rasmussen, Daniel and Eliasmith, Chris},
booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 36th Annual Conference of the Cognitive Science Society/Rasmussen, Eliasmith/Rasmussen, Eliasmith - 2014 - A neural model of hierarchical reinforcement learning.pdf:pdf},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
number = {1},
pages = {1252--1257},
title = {{A neural model of hierarchical reinforcement learning}},
year = {2014}
}
