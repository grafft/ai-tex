Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Smolensky2014,
abstract = {Mental representations have continuous as well as discrete, combinatorial aspects. For example, while predominantly discrete, phonological representations also vary continuously, as evidenced by instrumental studies of both grammatically-­‐‑induced sound alternations and speech errors. Can an integrated theoretical framework address both aspects of structure? The framework we introduce here, Gradient Symbol Processing, characterizes the emergence of grammatical macrostructure from the Parallel Distributed Processing microstructure (McClelland {\&} Rumelhart, 1986) of language processing. The mental representations that emerge, Distributed Symbol Systems, have both combinatorial and gradient structure. They are processed through Subsymbolic Optimization-­‐‑Quantization, in which an optimization process favoring representations that satisfy well-­‐‑formedness constraints operates in parallel with a distributed quantization process favoring discrete symbolic structures. We apply a particular instantiation of this framework, $\lambda$-­‐‑ Diffusion Theory, to phonological production. Simulations of the resulting model suggest that Gradient Symbol Processing offers a way to unify accounts of discrete grammatical competence with both discrete and continuous patterns in language performance.},
author = {Smolensky, Paul and Goldrick, Matthew and Mathis, Donald},
doi = {10.1111/cogs.12047},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Smolensky, Goldrick, Mathis/Smolensky, Goldrick, Mathis - 2014 - Optimization and quantization in gradient symbol systems A framework for integrating the continuous.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Combinatorial structure,Distributed representation,Harmonic grammar,Optimization,Selection,Speech errors},
number = {6},
pages = {1102--1138},
pmid = {23802807},
title = {{Optimization and quantization in gradient symbol systems: A framework for integrating the continuous and the discrete in cognition}},
volume = {38},
year = {2014}
}
@article{Donadello2017,
abstract = {Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that the use of background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.},
archivePrefix = {arXiv},
arxivId = {1705.08968},
author = {Donadello, Ivan and Serafini, Luciano and d'Avila Garcez, Artur},
eprint = {1705.08968},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)/Donadello, Serafini, Garcez/Donadello, Serafini, Garcez - 2017 - Logic Tensor Networks for Semantic Image Interpret.pdf:pdf},
journal = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)},
keywords = {Machine Learning: Knowledge-based Learning,Robotics and Vision: Vision and Perception,Uncertainty in AI: Uncertainty in AI},
pages = {1596--1602},
title = {{Logic Tensor Networks for Semantic Image Interpretation}},
url = {http://arxiv.org/abs/1705.08968},
year = {2017}
}
@article{Garcez2015,
abstract = {The goal of neural-symbolic computation is to integrate ro- bust connectionist learning and sound symbolic reasoning. With the recent advances in connectionist learning, in par- ticular deep neural networks, forms of representation learn- ing have emerged. However, such representations have not become useful for reasoning. Results from neural-symbolic computation have shown to offer powerful alternatives for knowledge representation, learning and reasoning in neural computation. This paper recalls the main contributions and discusses key challenges for neural-symbolic integration which have been identified at a recent Dagstuhl seminar.},
author = {Garcez, Avila and Besold, Tarek R and Raedt, Luc De and F{\"{o}}ldiak, Peter and Hitzler, Pascal and Icard, Thomas and K{\"{u}}hnberger, Kai-uwe and Lamb, Luis C and Miikkulainen, Risto and Silver, Daniel L},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Knowledge Representation and Reasoning Integrating Symbolic and Neural Approaches Papers from the 2015 AAAI Spring Symposium/Garcez et al/Garcez et al. - 2015 - Neural-Symbolic Learning and Reasoning Contrib.pdf:pdf},
journal = {Knowledge Representation and Reasoning: Integrating Symbolic and Neural Approaches: Papers from the 2015 AAAI Spring Symposium},
pages = {18--21},
title = {{Neural-Symbolic Learning and Reasoning : Contributions and Challenges}},
year = {2015}
}
@article{Besold2017,
abstract = {The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.},
archivePrefix = {arXiv},
arxivId = {1711.03902},
author = {Besold, Tarek R. and d'Avila Garcez, Artur and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and Kuehnberger, Kai-Uwe and Lamb, Luis C. and Lowd, Daniel and Lima, Priscila Machado Vieira and de Penning, Leo and Pinkas, Gadi and Poon, Hoifung and Zaverucha, Gerson},
eprint = {1711.03902},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Besold et al/Besold et al. - 2017 - Neural-Symbolic Learning and Reasoning A Survey and Interpretation.pdf:pdf},
pages = {1--58},
title = {{Neural-Symbolic Learning and Reasoning: A Survey and Interpretation}},
url = {http://arxiv.org/abs/1711.03902},
year = {2017}
}
@book{Sun1994,
abstract = {Concerned with understanding and modeling commonsense reasoning with a combination of rules and similarities under a connectionist rubric. Examines the areas of reasoning, connectionist models, inheritance, causality, rule-based systems and similarity-based reasoning. Introduces a new structure, a novel connectionist architecture and a set of fresh ideas leading to new applications.},
author = {Sun, Ron},
pages = {273},
publisher = {Wiley-Interscience},
title = {{Integrating Rules and Connectionism for Robust Commonsense Reasoning}},
year = {1994}
}
@article{Vogt2003,
author = {Vogt, Paul},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Robotics and Autonomous Systems/Vogt/Vogt - 2003 - Anchoring of semiotic symbols.pdf:pdf},
journal = {Robotics and Autonomous Systems},
number = {2-3},
pages = {109--120},
title = {{Anchoring of semiotic symbols}},
volume = {43},
year = {2003}
}
@article{Touretzky1985,
abstract = {Pattern matching and variable binding are easily implemented in conventional computer architectures, but not necessarily in all architectures. In a distributed neural network architecture each symbol is represented by activity in many units and each unit contributes to the representation of many symbols. Manipulating symbols using this type of distributed representation is not as easy as with a local representation whore each unit denotes one symbol, but there is evidence that the distributed approach is the one chosen by nature. We describe a working implementation of a production system interpreter in a neural network using distributed representations for both symbols and rules. The research provides a detailed account of two important symbolic reasoning operations, pattern matching and variable binding, as emergent properties of collections of neuron-like elements. The success of our production system implementation goes some way towards answering a common criticism of connectionist theories: that they aren't powerful enough to do symbolic reasoning.},
author = {Touretzky, D S and Hinton, G E},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Ninth International Joint Conference on Artificial Intelligence/Touretzky, Hinton/Touretzky, Hinton - 1985 - Symbols among the neurons details of a connectionist inference architecture.pdf:pdf},
isbn = {CMU-CS-A},
journal = {Proceedings of the Ninth International Joint Conference on Artificial Intelligence},
pages = {238--243},
title = {{Symbols among the neurons: details of a connectionist inference architecture}},
volume = {1},
year = {1985}
}
@book{DAvilaGarcez2009,
author = {d'Avila Garcez, Artur S. and Lamb, Luis C. and Gabbay, Dov M.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/d'Avila Garcez, Lamb, Gabbay/d'Avila Garcez, Lamb, Gabbay - 2009 - Neural-Symbolic Cognitive Reasoning.pdf:pdf},
isbn = {9783540732457},
publisher = {Springer},
title = {{Neural-Symbolic Cognitive Reasoning}},
year = {2009}
}
