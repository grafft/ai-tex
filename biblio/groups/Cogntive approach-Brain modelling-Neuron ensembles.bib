Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Rao2004,
abstract = {A large number of human psychophysical results have been successfully explained in recent years using Bayesian models. However, the neural implementation of such models remains largely unclear. In this article, we show that a network architecture commonly used to model the cerebral cortex can implement Bayesian inference for an arbitrary hidden Markov model. We illustrate the approach using an orientation discrimination task and a visual motion detection task. In the case of orientation discrimination, we show that the model network can infer the posterior distribution over orientations and correctly estimate stimulus orientation in the presence of significant noise. In the case of motion detection, we show that the resulting model network exhibits direction selectivity and correctly computes the posterior probabilities over motion direction and position. When used to solve the well-known random dots motion discrimination task, the model generates responses that mimic the activities of evidence-accumulating neurons in cortical areas LIP and FEF. The framework we introduce posits a new interpretation of cortical activities in terms of log posterior probabilities of stimuli occurring in the natural world.},
author = {Rao, Rajesh P N},
doi = {10.1162/08997660460733976},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2004/Rao - 2004.pdf:pdf},
isbn = {08997660460733976},
issn = {0899-7667},
journal = {Neural computation},
number = {1},
pages = {1--38},
pmid = {15006021},
title = {{Bayesian computation in recurrent neural circuits}},
volume = {16},
year = {2004}
}
@inproceedings{Vityaev2012b,
address = {Ростов-на-Дону},
author = {Витяев, Е. Е.},
booktitle = {Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)/2012/Витяев - 2012.pdf:pdf},
language = {russian},
pages = {81--84},
title = {{Формальная модель нейрона, обеспечивающая непротиворечивость предсказаний}},
volume = {2},
year = {2012}
}
@article{Prinz2006,
author = {Prinz, Nwsaa and Butera, Rj},
doi = {10.1007/978-1-4614-0739-3},
editor = {Schultheiss, Nathan W. and Prinz, Astrid A. and Butera, Robert J.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Springer/2006/Prinz, Butera - 2006.pdf:pdf},
isbn = {9781461407386},
issn = {9781461407386},
journal = {Springer},
pages = {33--52},
title = {{Phase Response Curves in Neuroscience}},
url = {http://scholarpedia.org/article/Phase{\_}resetting{\_}curve{\%}5Cnhttp://link.springer.com/content/pdf/10.1007/978-1-4614-0739-3.pdf},
year = {2006}
}
@article{Ivanitsky1994,
author = {Иваницкий, Г. Р. and Медвинский, А. Б. and Цыганов, М. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1994/Иваницкий, Медвинский, Цыганов - 1994.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1041--1072},
title = {{От динамики популяционных автоволн, формируемых живыми клетками, к нейроинформатике}},
volume = {164},
year = {1994}
}
@article{Nekorkon2008,
author = {Некоркин, В. И.},
doi = {10.3367/UFNr.0178.200803f.0313},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2008/Некоркин - 2008.pdf:pdf},
issn = {0042-1294},
journal = {Успехи физических наук},
language = {russian},
number = {3},
pages = {313--323},
title = {{Нейронные колебания и волны в нейродинамике}},
url = {http://ufn.ru/ru/articles/2008/3/f/},
volume = {178},
year = {2008}
}
@article{Solovyeva2015,
abstract = {In this work we reveal and explore a new class of attractor neural networks, based on inborn connections provided by model molecular markers, the molecular marker based attractor neural networks (MMBANN). We have explored conditions for the existence of attractor states, critical relations between their parameters and the spectrum of single neuron models, which can implement the MMBANN. Besides, we describe functional models (perceptron and SOM) which obtain significant advantages, while using MMBANN. In particular, the perceptron based on MMBANN, gets specificity gain in orders of error probabilities values, MMBANN SOM obtains real neurophysiological meaning, the number of possible grandma cells increases 1000- fold with MMBANN. Each set of markers has a metric, which is used to make connections between neurons containing the markers. The resulting neural networks have sets of attractor states, which can serve as finite grids for representation of variables in computations. These grids may show dimensions of d = 0, 1, 2,... We work with static and dynamic attractor neural networks of dimensions d = 0 and d = 1. We also argue that the number of dimensions which can be represented by attractors of activities of neural networks with the number of elements N=104 does not exceed 8.},
archivePrefix = {arXiv},
arxivId = {1508.01060},
author = {Solovyeva, Ksenia P and Karandashev, Iakov M and Zhavoronkov, Alex and Dunin-Barkowski, Witali L.},
doi = {10.3389},
eprint = {1508.01060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Front. Syst. Neurosci/2015/Solovyeva et al. - 2015.pdf:pdf},
issn = {1662-5137},
journal = {Front. Syst. Neurosci.},
keywords = {Hopfield networks,bump attractor,cortical column,dynamic attractor,hopfield networks,innate connections,neural networks,self-organizing mapping},
pmid = {26778977},
title = {{Models of Innate Neural Attractors and Their Applications for Neural Information Processing}},
volume = {9},
year = {2015}
}
@article{Abarbanel1996,
author = {Абарбанель, Г. Д. И. and Рабинович, М. И. and Селверстон, А. and Баженов, М. В. and Хуэрта, Р. and Сущик, М. М. and Рубчинский, Л. Л.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1996/Абарбанель et al. - 1996.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {4},
pages = {363--390},
title = {{Синхрониазция в нейронных ансамблях}},
volume = {166},
year = {1996}
}
@article{Borisuk2002,
author = {Борисюк, Г. Н. and Борисюк, Р. М. and Казанович, Я. Б. and Иваницкий, Г. Р.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2002/Борисюк et al. - 2002.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1189--1214},
title = {{Модели динамики нейронной активности при обработке информации мозгом - итоги ``десятилетия''}},
volume = {170},
year = {2002}
}
@unpublished{Smith2015,
author = {Smith, J E},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Smith - 2015.pdf:pdf},
pages = {1--82},
title = {{Biologically Plausible Spiking Neural Networks}},
year = {2015}
}
@article{Tetzlaff2013,
abstract = {Memory storage in the brain relies on mechanisms acting on time scales from minutes, for long-term synaptic potentiation, to days, for memory consolidation. During such processes, neural circuits distinguish synapses relevant for forming a long-term storage, which are consolidated, from synapses of short-term storage, which fade. How time scale integration and synaptic differentiation is simultaneously achieved remains unclear. Here we show that synaptic scaling - a slow process usually associated with the maintenance of activity homeostasis - combined with synaptic plasticity may simultaneously achieve both, thereby providing a natural separation of short- from long-term storage. The interaction between plasticity and scaling provides also an explanation for an established paradox where memory consolidation critically depends on the exact order of learning and recall. These results indicate that scaling may be fundamental for stabilizing memories, providing a dynamic link between early and late memory formation processes.},
author = {Tetzlaff, Christian and Kolodziejski, Christoph and Timme, Marc and Tsodyks, Misha and W{\"{o}}rg{\"{o}}tter, Florentin},
doi = {10.1371/journal.pcbi.1003307},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2013/Tetzlaff et al. - 2013.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,Long-Term,Long-Term: physiology,Memory,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Short-Term,Short-Term: physiology,Synapses,Synapses: physiology},
number = {10},
pages = {e1003307},
pmid = {24204240},
title = {{Synaptic scaling enables dynamically distinct short- and long-term memory formation}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3814677{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2013}
}
