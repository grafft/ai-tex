Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Langley2009a,
abstract = {In this paper, we review Icarus, a cognitive architecture that utilizes hierarchical skills and concepts for reactive execution in physical environments. In addition, we present two extensions to the framework. The first involves the incorporation of means-ends analysis, which lets the system compose known skills to solve novel problems. The second involves the storage of new skills that are based on successful means-ends traces. We report experimental studies of these mechanisms on three distinct domains. Our results suggest that the two methods interact to acquire useful skill hierarchies that generalize well and that reduce the effort required to handle new tasks. We conclude with a discussion of related work on learning and prospects for additional research, including extending the framework to cover developmental phenomena. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Langley, Pat and Choi, Dongkyu and Rogers, Seth},
doi = {10.1016/j.cogsys.2008.07.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Langley, Choi, Rogers/2009/Acquisition of hierarchical reactive skills in a unified cognitive architecture.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive architecture,Hierarchical skills,Incremental learning,Problem solving,Reactive control},
number = {4},
pages = {316--332},
title = {{Acquisition of hierarchical reactive skills in a unified cognitive architecture}},
volume = {10},
year = {2009}
}
@article{Chersi2014,
abstract = {A growing body of evidence in cognitive psychology and neuroscience suggests a deep interconnection between sensory-motor and language systems in the brain. Based on recent neurophysiological findings on the anatomo-functional organization of the fronto-parietal network, we present a computational model showing that language processing may have reused or co-developed organizing principles, functionality, and learning mechanisms typical of premotor circuit. The proposed model combines principles of Hebbian topological self-organization and prediction learning. Trained on sequences of either motor or linguistic units, the network develops independent neuronal chains, formed by dedicated nodes encoding only context-specific stimuli. Moreover, neurons responding to the same stimulus or class of stimuli tend to cluster together to form topologically connected areas similar to those observed in the brain cortex. Simulations support a unitary explanatory framework reconciling neurophysiological motor data with established behavioral evidence on lexical acquisition, access, and recall.},
author = {Chersi, Fabian and Ferro, Marcello and Pezzulo, Giovanni and Pirrelli, Vito},
doi = {10.1111/tops.12094},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Chersi et al/2014/Topological self-organization and prediction learning support both action and lexical chains in the brain.pdf:pdf},
issn = {1756-8765},
journal = {Topics in cognitive science},
keywords = {computational modeling,lexical chains,motor chains,prediction,self-organizing maps,serial working memory,somatotopic organization},
number = {3},
pages = {476--91},
pmid = {24935737},
title = {{Topological self-organization and prediction learning support both action and lexical chains in the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24935737},
volume = {6},
year = {2014}
}
@book{Kober2014,
address = {Cham},
author = {Kober, Jens and Peters, Jan},
doi = {10.1007/978-3-319-03194-1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kober, Peters/2014/Learning Motor Skills.pdf:pdf},
isbn = {978-3-319-03193-4},
publisher = {Springer International Publishing},
series = {Springer Tracts in Advanced Robotics},
title = {{Learning Motor Skills}},
url = {http://link.springer.com/10.1007/978-3-319-03194-1},
volume = {97},
year = {2014}
}
@article{Subagdja2015,
author = {Subagdja, Budhitama and Tan, Ah-Hwee},
doi = {10.1016/j.neucom.2015.02.038},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Subagdja, Tan/2015/Neural modeling of sequential inferences and learning over episodic memory.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Adaptive resonance theory,Episodic memory,Transitive inference},
pages = {1--14},
publisher = {Elsevier},
title = {{Neural modeling of sequential inferences and learning over episodic memory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231215001873},
year = {2015}
}
@article{Dong2011a,
abstract = {We present a new model of sensorimotor learning in a systems-level cognitive model, LIDA. Sensorimotor learning helps an agent properly interact with its environment using past experi- ences. This new model stores and updates the rewards of pairs of data, motor commands and their contexts, using the concept of reinforcement learning; thus the agent is able to generate (output) effective commands in certain contexts based on its reward history. Following Global Workspace Theory, the primary basis of LIDA, the process of updating rewards in sensorimotor learning is cued by the agent's conscious content, the most salient portion of the agent's under- standing of the current situation, issued by the Global Workspace module of LIDA. Furthermore, we add a dynamic learning rate to control the extent to which a newly arriving reward may affect the reward update. This learning rate control mechanism is inspired by a hypothesis from neuroscience regarding memory of errors. Our experimental results show that sensorimotor learning using a dynamic learning rate improves performance in a simulated movement of push- ing a box.},
author = {Dong, Daqi and Franklin, Stan},
doi = {10.1016/j.bica.2015.09.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dong, Franklin/2015/Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {a learning rate control,action,cognitive modeling,execution,in lida and add,in this paper,learning rate,lida 1,lida model,mechanism,sensorimotor learning,this is,we implement sensorimotor learning},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate}},
volume = {14},
year = {2015}
}
@article{Taatgen2005,
abstract = {Emerging parallel processing and increased flexibility during the acquisition of cognitive skills form a combination that is hard to reconcile with rule-based models that often produce brittle behavior. Rule-based models can exhibit these properties by adhering to 2 principles: that the model gradually learns task-specific rules from instructions and experience, and that bottom-up processing is used whenever possible. In a model of learning perfect time-sharing in dual tasks (Schumacher et al., 2001), speedup learning and bottom-up activation of instructions can explain parallel behavior. In a model of a complex dynamic task (Carnegie Mellon University Aegis Simulation Program [CMU-ASP], Anderson et al., 2004), parallel behavior is explained by the transition from serially organized instructions to rules that are activated by both top-down (goal-driven) and bottom-up (perceptually driven) factors. Parallelism lets the model opportunistically reorder instructions, leading to the gradual emergence of new task strategies.},
author = {Taatgen, Niels},
doi = {10.1207/s15516709cog0000_23},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Taatgen/2005/Modeling parallelization and flexibility improvements in skill acquisition from dual tasks to complex dynamic skills.pdf:pdf},
isbn = {0364-0213},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {cognitive architecture,complex systems,computer,dual tasking,human,instruction,interaction,knowledge,learning,psychology,representation,situated cognition,skill acquisition and learning,symbolic computational modeling},
number = {3},
pages = {421--455},
pmid = {21702780},
title = {{Modeling parallelization and flexibility improvements in skill acquisition: from dual tasks to complex dynamic skills}},
volume = {29},
year = {2005}
}
@incollection{Hexmoor1996,
abstract = {Routine interactions in the world of an autonomous agent are a major source of learning for the agent. In my approach an agent interacts in the world in several different ways, from cognitive to automatic. I show that an agent can learn and also improve its routine interactions in its different modes of interaction in the world. I present a formalism and use for a goal structure known as goal sketch [11]. Rewards and punishments generated from a goal sketch which indicate progress in goal satisfaction are used to improve automatic interactions and enhance agent's strategies and concepts about action. I will discuss my experiments with a physical robot that uses a goal sketch in order to generate rewards and punishments which are then used in improving robot skills and discovering new actions.},
author = {Hexmoor, Henry},
booktitle = {Intelligent Agents II Agent Theories, Architectures, and Languages},
doi = {10.1007/3540608052_61},
editor = {Wooldridge, Michael and Muller, J{\"{o}}rg P. and Tambe, Milind},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hexmoor/1996/Learning Routines.pdf:pdf},
pages = {97--110},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Learning Routines}},
year = {1996}
}
@book{Steyvers2003,
abstract = {Information about the structure of a causal system can come in the form of observational data-random samples of the system's autonomous behavior-or interventional data-samples conditioned on the particular values of one or more variables that have been experimentally manipulated. Here we study people's ability to infer causal structure from both observation and intervention, and to choose informative interventions on the basis of observational data. In three causal inference tasks, participants were to some degree capable of distinguishing between competing causal hypotheses on the basis of purely observational data. Performance improved substantially when participants were allowed to observe the effects of interventions that they performed on the systems. We develop computational models of how people infer causal structure from data and how they plan intervention experiments, based on the representational framework of causal graphical models and the inferential principles of optimal Bayesian decision-making and maximizing expected information gain. These analyses suggest that people can make rational causal inferences, subject to psychologically reasonable representational assumptions and computationally reasonable processing constraints. {\textcopyright} 2003 Cognitive Science Society, Inc. All rights reserved.},
author = {Steyvers, Mark and Tenenbaum, Joshua B. and Wagenmakers, Eric Jan and Blum, Ben},
booktitle = {Cognitive Science},
doi = {10.1016/S0364-0213(03)00010-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Steyvers et al/2003/Inferring causal networks from observations and interventions.pdf:pdf},
isbn = {1949824764},
issn = {03640213},
keywords = {Active learning,Bayesian models,Bayesian networks,Causal reasoning,Computer simulation,Decision making,Human experimentation,Hypothesis testing,Interventions,Observational learning,Rational inference,Structure learning,Web experiments},
number = {3},
pages = {453--489},
title = {{Inferring causal networks from observations and interventions}},
volume = {27},
year = {2003}
}
@article{Hampshire2016,
abstract = {The ability to learn new tasks rapidly is a prominent characteristic of human behaviour. This ability relies on flexible cognitive systems that adapt in order to encode temporary programs for processing non-automated tasks. Previous functional imaging studies have revealed distinct roles for the lateral frontal cortices (LFCs) and the ventral striatum in intentional learning processes. However, the human LFCs are complex; they house multiple distinct sub-regions, each of which co-activates with a different functional network. It remains unclear how these LFC networks differ in their functions and how they coordinate with each other, and the ventral striatum, to support intentional learning. Here, we apply a suite of fMRI connectivity methods to determine how LFC networks activate and interact at different stages of two novel tasks, in which arbitrary stimulus-response rules are learnt either from explicit instruction or by trial-and-error. We report that the networks activate en masse and in synchrony when novel rules are being learnt from instruction. However, these networks are not homogeneous in their functions; instead, the directed connectivities between them vary asymmetrically across the learning timecourse and they disengage from the task sequentially along a rostro-caudal axis. Furthermore, when negative feedback indicates the need to switch to alternative stimulus-response rules, there is additional input to the LFC networks from the ventral striatum. These results support the hypotheses that LFC networks interact as a hierarchical system during intentional learning and that signals from the ventral striatum have a driving influence on this system when the internal program for processing the task is updated.},
author = {Hampshire, Adam and Hellyer, Peter J. and Parkin, Beth and Hiebert, Nole and MacDonald, Penny and Owen, Adrian M. and Leech, Robert and Rowe, James},
doi = {10.1016/j.neuroimage.2015.11.060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hampshire et al/2016/Network mechanisms of intentional learning.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Caudate,Dynamic causal modelling,Frontal cortex,Functional connectivity,Learning},
pages = {123--134},
publisher = {The Authors},
title = {{Network mechanisms of intentional learning}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.11.060},
volume = {127},
year = {2016}
}
@inproceedings{Cubek2015,
author = {Cubek, Richard and Ertel, Wolfgang},
booktitle = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cubek, Ertel/2015/High-Level Learning from Demonstration with Conceptual Spaces and Subspace Clustering.pdf:pdf},
isbn = {9781479969234},
pages = {2592--2597},
publisher = {IEEE},
title = {{High-Level Learning from Demonstration with Conceptual Spaces and Subspace Clustering}},
year = {2015}
}
@article{Rasmussen2011,
abstract = {Abstract Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method ... $\backslash$n},
author = {Rasmussen, Daniel and Eliasmith, Chris},
doi = {10.1111/j.1756-8765.2010.01127.x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen, Eliasmith/2011/A neural model of rule generation in inductive reasoning.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Cognitive modeling,Fluid intelligence,Inductive reasoning,Neural engineering framework,Raven's progressive matrices,Realistic neural modeling,Rule generation,Vector symbolic architectures},
number = {1},
pages = {140--153},
title = {{A neural model of rule generation in inductive reasoning}},
volume = {3},
year = {2011}
}
@article{Rafferty2015a,
author = {Rafferty, Anna N. and Brunskill, Emma and Griffiths, Thomas L. and Shafto, Patrick},
doi = {10.1111/cogs.12290},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rafferty et al/2016/Faster Teaching via POMDP Planning.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {automated teaching,concept learning,partially observable markov decision,process},
month = {aug},
number = {6},
pages = {1290--1332},
title = {{Faster Teaching via POMDP Planning}},
url = {http://doi.wiley.com/10.1111/cogs.12290},
volume = {40},
year = {2016}
}
@article{Zendehrouh2015,
author = {Zendehrouh, Sareh},
doi = {10.1016/j.neunet.2015.08.006},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Zendehrouh/2015/A new computational account of cognitive control over reinforcement-based decision-making Modeling of a probabilistic learning task.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {112--123},
publisher = {Elsevier Ltd},
title = {{A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608015001604},
volume = {71},
year = {2015}
}
@article{Sun2004,
abstract = {This paper explores the interaction between implicit and explicit processes during skill learning, in terms of top-down learning (that is, learning that goes from explicit to implicit knowledge) versus bottom-up learning (that is, learning that goes from implicit to explicit knowledge). Instead of studying each type of knowledge (implicit or explicit) in isolation, we stress the interaction between the two types, especially in terms of one type giving rise to the other, and its effects on learning. The work presents an integrated model of skill learning that takes into account both implicit and explicit processes and both top-down and bottom-up learning. We examine and simulate human data in the Tower of Hanoi task. The paper shows how the quantitative data in this task may be captured using either top-down or bottom-up approaches, although top-down learning is a more apt explanation of the human data currently available. These results illustrate the two different directions of learning (top-down versus bottom-up), and thereby provide a new perspective on skill learning. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi},
doi = {10.1016/j.cogsys.2003.07.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Sun, Zhang/2004/Top-down versus bottom-up learning in cognitive skill acquisition.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
pages = {63--89},
title = {{Top-down versus bottom-up learning in cognitive skill acquisition}},
volume = {5},
year = {2004}
}
@phdthesis{Rasmussen2014,
author = {Rasmussen, Daniel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen/2014/Hierarchical reinforcement learning in a biologically plausible neural architecture.pdf:pdf},
pages = {175},
school = {Unversetu of Waterloo},
title = {{Hierarchical reinforcement learning in a biologically plausible neural architecture}},
year = {2014}
}
@article{Frank2012,
abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
author = {Frank, Michael J. and Badre, David},
doi = {10.1093/cercor/bhr114},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frank, Badre/2012/Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1 Computational analysis.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Computer Simulation,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Humans,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reinforcement (Psychology)},
number = {3},
pages = {509--26},
pmid = {21693490},
title = {{Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3278315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {22},
year = {2012}
}
@article{Miconi2017,
abstract = {{\textless}p{\textgreater}Neural activity during cognitive tasks exhibits complex dynamics that flexibly encode task-relevant variables. Chaotic recurrent networks, which spontaneously generate rich dynamics, have been proposed as a model of cortical computation during cognitive tasks. However, existing methods for training these networks are either biologically implausible, and/or require a continuous, real-time error signal to guide learning. Here we show that a biologically plausible learning rule can train such recurrent networks, guided solely by delayed, phasic rewards at the end of each trial. Networks endowed with this learning rule can successfully learn nontrivial tasks requiring flexible (context-dependent) associations, memory maintenance, nonlinear mixed selectivities, and coordination among multiple outputs. The resulting networks replicate complex dynamics previously observed in animal cortex, such as dynamic encoding of task features and selective integration of sensory inputs. We conclude that recurrent neural networks offer a plausible model of cortical dynamics during both learning and performance of flexible behavior.{\textless}/p{\textgreater}},
archivePrefix = {arXiv},
arxivId = {1507.08973},
author = {Miconi, Thomas},
doi = {10.7554/eLife.20899},
eprint = {1507.08973},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Miconi/2017/Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks.pdf:pdf},
isbn = {0894-0282},
issn = {2050084X},
journal = {eLife},
pages = {1--24},
pmid = {22352717},
title = {{Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks}},
volume = {6},
year = {2017}
}
@inproceedings{Rasmussen1998,
author = {Rasmussen, Daniel and Eliasmith, Chris},
booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen, Eliasmith/2014/A neural model of hierarchical reinforcement learning.pdf:pdf},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
number = {1},
pages = {1252--1257},
title = {{A neural model of hierarchical reinforcement learning}},
year = {2014}
}
@inproceedings{Licato2015,
abstract = {The ability to generate explanations of perceived events and of one's own actions is of central importance to how we make sense of the world. When modeling explanation generation, one common tactic used by cognitive systems is to construct a linkage of previously created cause- effect pairs. But where do such cause-effect pairs come from in the first place, and how can they be created automatically by cognitive systems? In this paper, we discuss the development of causal representations in children, by analyzing the literature surrounding a Piagetian experiment, and show how the conditions making cause-effect pair creation possi- ble can start to be modeled using a combination of feature-extraction techniques and the structured knowledge representation in the hybrid cognitive architecture CLARION. We create a task in PAGI World for learning causality, and make this task available for download.},
author = {Licato, John and Marton, Nick and Dong, Boning and Sun, Ron and Bringsjord, Selmer},
booktitle = {Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition},
editor = {Lieto, Antonio and Battaglino, Cristina and Radicioni, Daniele P. and Sanguinetti, Manuela},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Licato et al/2015/Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generation in a Cognitive Architecture.pdf:pdf},
keywords = {analogy,clarion,cognitive architecture,explanation},
pages = {29--39},
series = {CEUR Workshop Proceedings},
title = {{Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generation in a Cognitive Architecture}},
year = {2015}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ma, Wei Ji and Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/nn1790},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Ma et al/2006/Bayesian inference with probabilistic population codes.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {11},
pages = {1432--1438},
pmid = {17057707},
title = {{Bayesian inference with probabilistic population codes}},
volume = {9},
year = {2006}
}
@article{Tabor2013,
abstract = {Human participants and recurrent ("connectionist") neural networks were both trained on a categorization system abstractly similar to natural language systems involving irregular ("strong") classes and a default class. Both the humans and the networks exhibited staged learning and a generalization pattern reminiscent of the Elsewhere Condition (Kiparsky, 1973). Previous connectionist accounts of related phenomena have often been vague about the nature of the networks' encoding systems. We analyzed our network using dynamical systems theory, revealing topological and geometric properties that can be directly compared with the mechanisms of non-connectionist, rule-based accounts. The results reveal that the networks "contain" structures related to mechanisms posited by rule-based models, partly vindicating the insights of these models. On the other hand, they support the one mechanism (OM), as opposed to the more than one mechanism (MOM), view of symbolic abstraction by showing how the appearance of MOM behavior can arise emergently from one underlying set of principles. The key new contribution of this study is to show that dynamical systems theory can allow us to explicitly characterize the relationship between the two perspectives in implemented models.},
author = {Tabor, Whitney and Cho, Pyeong W and Dankowicz, Harry},
doi = {10.1111/cogs.12072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Tabor, Cho, Dankowicz/2013/Birth of an abstraction a dynamical systems account of the discovery of an elsewhere principle in a category learning task.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {Adult,Computer Simulation,Concept Formation,Concept Formation: physiology,Female,Generalization (Psychology),Generalization (Psychology): physiology,Humans,Learning,Learning: physiology,Male,Models,Problem Solving,Problem Solving: physiology,Psychological},
number = {7},
pages = {1193--227},
pmid = {23931713},
title = {{Birth of an abstraction: a dynamical systems account of the discovery of an elsewhere principle in a category learning task}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23931713},
volume = {37},
year = {2013}
}
@article{Hasselmo2006,
author = {Howard, Marc W. and Fotedar, Mrigankka S. and Datey, Aditya V. and Hasselmo, Michael E.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Howard et al/2005/The Temporal Context Model in spatial navigation and relational learning Toward a common explanation of medial temporal lobe function ac.pdf:pdf},
journal = {Psychology Review},
number = {1},
pages = {75--116},
title = {{The Temporal Context Model in spatial navigation and relational learning: Toward a common explanation of medial temporal lobe function across domains}},
volume = {112},
year = {2005}
}
@article{Gopnik2004,
abstract = {The authors outline a cognitive and computational account of causal learning in children. They propose that children use specialized cognitive systems that allow them to recover an accurate “causal map” of the world: an abstract, coherent, learned representation of the causal relations among events. This kind of knowledge can be perspicuously understood in terms of the formalism of directed graphical causal models, or Bayes nets. Children's causal learning and inference may involve computations similar to those for learning causal Bayes nets and for predicting with them. Experimental results suggest that 2to 4-year-old children construct new causal maps and that their learning is consistent with the Bayes net formalism.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gopnik, A and Glymour, C and Sobel, D M and Schulz, L E and Kushnir, T and Danks, D},
doi = {10.1037/0033-295X.111.1.3},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gopnik et al/2004/A theory of causal learning in children.pdf:pdf},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {SLC, complex systems},
pages = {3--32},
pmid = {14756583},
title = {{A theory of causal learning in children}},
year = {2004}
}
@article{Aoun2014,
author = {Aoun, Mario Antoine and Boukadoum, Mounir},
doi = {10.1109/ICCI-CC.2014.6921451},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Aoun, Boukadoum/2014/Learning algorithm and neurocomputing architecture for NDS Neurons.pdf:pdf},
isbn = {978-1-4799-6081-1},
journal = {2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing},
keywords = {chaos control,chaotic spiking neural network,inputs to a pool,liquid,nds neuron,nonlinear transient computation,of,online signature verification,property,sp mentions that different,state machines,stdp},
pages = {126--132},
publisher = {Ieee},
title = {{Learning algorithm and neurocomputing architecture for NDS Neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6921451},
year = {2014}
}
@article{Yan2014,
abstract = {The accessibility verification of the assembly/disassembly plays an important role in the process of product design. In the last decade, the sampling based motion planners have been successfully applied to solve the accessibility verification. However, the narrow passage which is a common problem in the assembly tasks is still a bottleneck. Meanwhile, the requirement of perception and emotion assessment drives the interaction between users and automatic path planners in the virtual assembly process. In this paper, a curve matching method is used to explore the implicit relationship between the topological information of scenarios and the motion of objects, based on which an interactive motion planning framework that can learn from experience is constructed. Our framework consists of two main processes: a learning process and a motion generation process. In the former process, the motion segment (a part of motion path) and its related scenario segment (a part of workspace passed through by the object) are gathered, after an interactive motion planning process finds a collision-free motion path or reaches the conclusion of inaccessibility. According to the similarity between the skeletons of scenario segments, the gathered scenario segments and motion segments are organized by a hierarchical structure in the motion library. The latter process permits users to control only one point in the workspace for the selection of a new scenario, and then the similar scenarios are retrieved from the motion library, to help quickly detect the connectivity of the new scenario and generate a repaired motion path to guide users with feasible manipulations. We highlight the performance of our framework on a challenging problem in 2D, in which a non-convex object passes through a cluttered environment filled with randomly shaped and located non-convex obstacles.},
author = {Yan, Yu and Poirson, Emilie and Bennis, Fouad},
doi = {10.1016/j.cad.2014.07.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Yan, Poirson, Bennis/2014/An interactive motion planning framework that can learn from experience.pdf:pdf},
issn = {00104485},
journal = {Computer-Aided Design},
keywords = {accessibility verification,assembly path planning},
pages = {23--38},
publisher = {Elsevier Ltd},
title = {{An interactive motion planning framework that can learn from experience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010448514001584},
volume = {59},
year = {2014}
}
@inproceedings{Kachergis2016,
address = {Austin},
author = {Kachergis, George and Berends, Floris and de Kleijn, Roy and Hommel, Bernhard},
booktitle = {Proceedings of the 38th Annual Conference of the Cognitive Science Society},
editor = {Papafragou, A. and Grodner, D. and Mirman, D. and Trueswell, J.C.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kachergis et al/2016/Human Reinforcement Learning of Sequential Action.pdf:pdf},
keywords = {movement trajectory,quential action,reinforcement learning,se-,sequence learning,serial reaction time task},
pages = {193--198},
publisher = {Cognitive Science Society},
title = {{Human Reinforcement Learning of Sequential Action}},
year = {2016}
}
@inproceedings{Drix2014,
author = {Drix, Damien and Hafner, Verena V},
booktitle = {Joint IEEE International Conference on Development and Learning},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Drix, Hafner/2014/Learning proprioceptive and motor features.pdf:pdf},
isbn = {9781479975402},
pages = {374--378},
title = {{Learning proprioceptive and motor features}},
year = {2014}
}
@article{Fernando2013,
abstract = {How do human infants learn the causal dependencies between events? Evidence suggests that this remarkable feat can be achieved by observation of only a handful of examples. Many computational models have been produced to explain how infants perform causal inference without explicit teaching about statistics or the scientific method. Here, we propose a spiking neuronal network implementation that can be entrained to form a dynamical model of the temporal and causal relationships between events that it observes. The network uses spike-time dependent plasticity, long-term depression, and heterosynaptic competition rules to implement Rescorla-Wagner-like learning. Transmission delays between neurons allow the network to learn a forward model of the temporal relationships between events. Within this framework, biologically realistic synaptic plasticity rules account for well-known behavioral data regarding cognitive causal assumptions such as backwards blocking and screening-off. These models can then be run as emulators for state inference. Furthermore, this mechanism is capable of copying synaptic connectivity patterns between neuronal networks by observing the spontaneous spike activity from the neuronal circuit that is to be copied, and it thereby provides a powerful method for transmission of circuit functionality between brain regions.},
author = {Fernando, Chrisantha},
doi = {10.1111/cogs.12073},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fernando/2013/From blickets to synapses inferring temporal causal networks by observation.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {backwards blocking,causal inference,groups,neuronal replicator hypothesis,polychronous,rational process model,screening-off},
number = {8},
pages = {1426--70},
pmid = {23957457},
title = {{From blickets to synapses: inferring temporal causal networks by observation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23957457},
volume = {37},
year = {2013}
}
@article{Keramati2011a,
abstract = {Reinforcement learning models address animal's behavioral adaptation to its changing “external” environment, and are based on the assumption that Pavlo- vian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are con- cerned with behavioral adaptation in response to the “internal” state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that in- tegrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identi- cal. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.},
author = {Keramati, Mehdi and Gutkin, Boris},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Keramati, Gutkin/2011/A Reinforcement Learning theory for homeostatic regulation.pdf:pdf},
isbn = {9781618395993},
journal = {Nips},
pages = {82--90},
title = {{A Reinforcement Learning theory for homeostatic regulation}},
year = {2011}
}
@article{Sergin2008,
author = {Sergin, A. V. and Sergin, V. Ya.},
journal = {Neural Network World},
number = {3},
pages = {227--244},
title = {{Model of perception: The hierarchy of inclusive sensory characteristics and top-down cascade transfer of excitation}},
volume = {18},
year = {2008}
}
@article{Sommerville2005,
abstract = {Adults and children readily construct action representations organized with respect to an ultimate goal. These representations allow one to predict the consequences of action, interpret and describe actions, and categorize action sequences. In this paper, we explore the ontogeny of hierarchically organized action representations, and its relation to infants' ability to produce similar sequences. To do so, we examine infants' perception and performance of a means-end sequence: pulling a cloth to retrieve a toy. Using a visual habituation paradigm, we demonstrate that 12-month-old infants understand that the initial step of the cloth-pulling sequence is directed toward the ultimate goal of attaining the toy, and use their knowledge of the causal constraints of the sequence to make this goal attribution. Ten-month-olds, however, appear transitional with respect to this understanding: their ability to identify the goal of the cloth-pulling sequence is related to their own ability to planfully solve a similar sequence. These findings are consistent with a burgeoning body of literature suggesting an intimate link between action production and perception, and suggest that this link is in place by at least 10 months of age. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sommerville, Jessica A. and Woodward, Amanda L.},
doi = {10.1016/j.cognition.2003.12.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Sommerville, Woodward/2005/Pulling out the intentional structure of action The relation between action processing and action production in infancy.pdf:pdf},
isbn = {0010-0277},
issn = {00100277},
journal = {Cognition},
keywords = {Action processing,Action production,Intentional structure},
number = {1},
pages = {1--30},
pmid = {15629472},
title = {{Pulling out the intentional structure of action: The relation between action processing and action production in infancy}},
volume = {95},
year = {2005}
}
@article{Damerow2016,
abstract = {Most current approaches to scene understanding lack the capability to adapt object and situation models to behavioral needs not anticipated by the human system designer. Here, we give a detailed description of a system architecture for self-referential autonomous learning which enables the refinement of object and situation models during operation in order to optimize behavior. This includes structural learning of hierarchical models for situations and behaviors that is triggered by a mismatch between expected and actual action outcome. Besides proposing architectural concepts, we also describe a first implementation of our system within a simulated traffic scenario to demonstrate the feasibility of our approach.},
author = {Damerow, Florian and Knoblauch, Andreas and K{\"{o}}rner, Ursula and Eggert, Julian and K{\"{o}}rner, Edgar},
doi = {10.1007/s12559-016-9407-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Damerow et al/2016/Toward Self-Referential Autonomous Learning of Object and Situation Models.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {autonomous learning {\'{a}} hierarchical,self-referential control {\'{a}} scene,situation model,understanding {\'{a}}},
pages = {1--17},
title = {{Toward Self-Referential Autonomous Learning of Object and Situation Models}},
url = {http://link.springer.com/10.1007/s12559-016-9407-7},
year = {2016}
}
