Automatically generated by Mendeley Desktop 1.16.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Taatgen2005,
abstract = {Emerging parallel processing and increased flexibility during the acquisition of cognitive skills form a combination that is hard to reconcile with rule-based models that often produce brittle behavior. Rule-based models can exhibit these properties by adhering to 2 principles: that the model gradually learns task-specific rules from instructions and experience, and that bottom-up processing is used whenever possible. In a model of learning perfect time-sharing in dual tasks (Schumacher et al., 2001), speedup learning and bottom-up activation of instructions can explain parallel behavior. In a model of a complex dynamic task (Carnegie Mellon University Aegis Simulation Program [CMU-ASP], Anderson et al., 2004), parallel behavior is explained by the transition from serially organized instructions to rules that are activated by both top-down (goal-driven) and bottom-up (perceptually driven) factors. Parallelism lets the model opportunistically reorder instructions, leading to the gradual emergence of new task strategies.},
author = {Taatgen, Niels},
doi = {10.1207/s15516709cog0000_23},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2005/Taatgen - 2005.pdf:pdf},
isbn = {0364-0213},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {cog{\_}arch,cognitive architecture,complex systems,computer,dual tasking,human,instruction,interaction,knowledge,learning,psychology,representation,situated cognition,skill acquisition and learning,symbolic computational modeling},
mendeley-tags = {cog{\_}arch},
number = {3},
pages = {421--455},
pmid = {21702780},
title = {{Modeling parallelization and flexibility improvements in skill acquisition: from dual tasks to complex dynamic skills}},
volume = {29},
year = {2005}
}
@article{Aoun2014,
author = {Aoun, Mario Antoine and Boukadoum, Mounir},
doi = {10.1109/ICCI-CC.2014.6921451},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing/2014/Aoun, Boukadoum - 2014.pdf:pdf},
isbn = {978-1-4799-6081-1},
journal = {2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing},
keywords = {chaos control,chaotic spiking neural network,inputs to a pool,liquid,nds neuron,nonlinear transient computation,of,online signature verification,property,sp mentions that different,state machines,stdp},
pages = {126--132},
publisher = {Ieee},
title = {{Learning algorithm and neurocomputing architecture for NDS Neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6921451},
year = {2014}
}
@book{Steyvers2003,
abstract = {Information about the structure of a causal system can come in the form of observational data-random samples of the system's autonomous behavior-or interventional data-samples conditioned on the particular values of one or more variables that have been experimentally manipulated. Here we study people's ability to infer causal structure from both observation and intervention, and to choose informative interventions on the basis of observational data. In three causal inference tasks, participants were to some degree capable of distinguishing between competing causal hypotheses on the basis of purely observational data. Performance improved substantially when participants were allowed to observe the effects of interventions that they performed on the systems. We develop computational models of how people infer causal structure from data and how they plan intervention experiments, based on the representational framework of causal graphical models and the inferential principles of optimal Bayesian decision-making and maximizing expected information gain. These analyses suggest that people can make rational causal inferences, subject to psychologically reasonable representational assumptions and computationally reasonable processing constraints. {\textcopyright} 2003 Cognitive Science Society, Inc. All rights reserved.},
author = {Steyvers, Mark and Tenenbaum, Joshua B. and Wagenmakers, Eric Jan and Blum, Ben},
booktitle = {Cognitive Science},
doi = {10.1016/S0364-0213(03)00010-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Science/2003/Steyvers et al. - 2003.pdf:pdf},
isbn = {1949824764},
issn = {03640213},
keywords = {Active learning,Bayesian models,Bayesian networks,Causal reasoning,Computer simulation,Decision making,Human experimentation,Hypothesis testing,Interventions,Observational learning,Rational inference,Structure learning,Web experiments},
number = {3},
pages = {453--489},
title = {{Inferring causal networks from observations and interventions}},
volume = {27},
year = {2003}
}
@inproceedings{Cubek2015,
author = {Cubek, Richard and Ertel, Wolfgang},
booktitle = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015/2015/Cubek, Ertel - 2015.pdf:pdf},
isbn = {9781479969234},
pages = {2592--2597},
publisher = {IEEE},
title = {{High-Level Learning from Demonstration with Conceptual Spaces and Subspace Clustering}},
year = {2015}
}
@article{Tabor2013,
abstract = {Human participants and recurrent ("connectionist") neural networks were both trained on a categorization system abstractly similar to natural language systems involving irregular ("strong") classes and a default class. Both the humans and the networks exhibited staged learning and a generalization pattern reminiscent of the Elsewhere Condition (Kiparsky, 1973). Previous connectionist accounts of related phenomena have often been vague about the nature of the networks' encoding systems. We analyzed our network using dynamical systems theory, revealing topological and geometric properties that can be directly compared with the mechanisms of non-connectionist, rule-based accounts. The results reveal that the networks "contain" structures related to mechanisms posited by rule-based models, partly vindicating the insights of these models. On the other hand, they support the one mechanism (OM), as opposed to the more than one mechanism (MOM), view of symbolic abstraction by showing how the appearance of MOM behavior can arise emergently from one underlying set of principles. The key new contribution of this study is to show that dynamical systems theory can allow us to explicitly characterize the relationship between the two perspectives in implemented models.},
author = {Tabor, Whitney and Cho, Pyeong W and Dankowicz, Harry},
doi = {10.1111/cogs.12072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2013/Tabor, Cho, Dankowicz - 2013.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {Adult,Computer Simulation,Concept Formation,Concept Formation: physiology,Female,Generalization (Psychology),Generalization (Psychology): physiology,Humans,Learning,Learning: physiology,Male,Models,Problem Solving,Problem Solving: physiology,Psychological},
number = {7},
pages = {1193--227},
pmid = {23931713},
title = {{Birth of an abstraction: a dynamical systems account of the discovery of an elsewhere principle in a category learning task}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23931713},
volume = {37},
year = {2013}
}
@article{Fernando2013,
abstract = {How do human infants learn the causal dependencies between events? Evidence suggests that this remarkable feat can be achieved by observation of only a handful of examples. Many computational models have been produced to explain how infants perform causal inference without explicit teaching about statistics or the scientific method. Here, we propose a spiking neuronal network implementation that can be entrained to form a dynamical model of the temporal and causal relationships between events that it observes. The network uses spike-time dependent plasticity, long-term depression, and heterosynaptic competition rules to implement Rescorla-Wagner-like learning. Transmission delays between neurons allow the network to learn a forward model of the temporal relationships between events. Within this framework, biologically realistic synaptic plasticity rules account for well-known behavioral data regarding cognitive causal assumptions such as backwards blocking and screening-off. These models can then be run as emulators for state inference. Furthermore, this mechanism is capable of copying synaptic connectivity patterns between neuronal networks by observing the spontaneous spike activity from the neuronal circuit that is to be copied, and it thereby provides a powerful method for transmission of circuit functionality between brain regions.},
author = {Fernando, Chrisantha},
doi = {10.1111/cogs.12073},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2013/Fernando - 2013.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {backwards blocking,causal inference,groups,neuronal replicator hypothesis,polychronous,rational process model,screening-off},
number = {8},
pages = {1426--70},
pmid = {23957457},
title = {{From blickets to synapses: inferring temporal causal networks by observation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23957457},
volume = {37},
year = {2013}
}
@article{Langley2009a,
abstract = {In this paper, we review Icarus, a cognitive architecture that utilizes hierarchical skills and concepts for reactive execution in physical environments. In addition, we present two extensions to the framework. The first involves the incorporation of means-ends analysis, which lets the system compose known skills to solve novel problems. The second involves the storage of new skills that are based on successful means-ends traces. We report experimental studies of these mechanisms on three distinct domains. Our results suggest that the two methods interact to acquire useful skill hierarchies that generalize well and that reduce the effort required to handle new tasks. We conclude with a discussion of related work on learning and prospects for additional research, including extending the framework to cover developmental phenomena. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Langley, Pat and Choi, Dongkyu and Rogers, Seth},
doi = {10.1016/j.cogsys.2008.07.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2009/Langley, Choi, Rogers - 2009.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive architecture,Hierarchical skills,Incremental learning,Problem solving,Reactive control,cog{\_}arch,icarus},
mendeley-tags = {cog{\_}arch,icarus},
number = {4},
pages = {316--332},
title = {{Acquisition of hierarchical reactive skills in a unified cognitive architecture}},
volume = {10},
year = {2009}
}
@article{Subagdja2015,
author = {Subagdja, Budhitama and Tan, Ah-Hwee},
doi = {10.1016/j.neucom.2015.02.038},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neurocomputing/2015/Subagdja, Tan - 2015.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Adaptive resonance theory,Episodic memory,Transitive inference},
pages = {1--14},
publisher = {Elsevier},
title = {{Neural modeling of sequential inferences and learning over episodic memory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231215001873},
year = {2015}
}
@article{Yan2014,
abstract = {The accessibility verification of the assembly/disassembly plays an important role in the process of product design. In the last decade, the sampling based motion planners have been successfully applied to solve the accessibility verification. However, the narrow passage which is a common problem in the assembly tasks is still a bottleneck. Meanwhile, the requirement of perception and emotion assessment drives the interaction between users and automatic path planners in the virtual assembly process. In this paper, a curve matching method is used to explore the implicit relationship between the topological information of scenarios and the motion of objects, based on which an interactive motion planning framework that can learn from experience is constructed. Our framework consists of two main processes: a learning process and a motion generation process. In the former process, the motion segment (a part of motion path) and its related scenario segment (a part of workspace passed through by the object) are gathered, after an interactive motion planning process finds a collision-free motion path or reaches the conclusion of inaccessibility. According to the similarity between the skeletons of scenario segments, the gathered scenario segments and motion segments are organized by a hierarchical structure in the motion library. The latter process permits users to control only one point in the workspace for the selection of a new scenario, and then the similar scenarios are retrieved from the motion library, to help quickly detect the connectivity of the new scenario and generate a repaired motion path to guide users with feasible manipulations. We highlight the performance of our framework on a challenging problem in 2D, in which a non-convex object passes through a cluttered environment filled with randomly shaped and located non-convex obstacles.},
author = {Yan, Yu and Poirson, Emilie and Bennis, Fouad},
doi = {10.1016/j.cad.2014.07.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Computer-Aided Design/2014/Yan, Poirson, Bennis - 2014.pdf:pdf},
issn = {00104485},
journal = {Computer-Aided Design},
keywords = {accessibility verification,assembly path planning},
pages = {23--38},
publisher = {Elsevier Ltd},
title = {{An interactive motion planning framework that can learn from experience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010448514001584},
volume = {59},
year = {2014}
}
@inproceedings{Drix2014,
author = {Drix, Damien and Hafner, Verena V},
booktitle = {Joint IEEE International Conference on Development and Learning},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Joint IEEE International Conference on Development and Learning/2014/Drix, Hafner - 2014.pdf:pdf},
isbn = {9781479975402},
pages = {374--378},
title = {{Learning proprioceptive and motor features}},
year = {2014}
}
@article{Damerow2016,
abstract = {Most current approaches to scene understanding lack the capability to adapt object and situation models to behavioral needs not anticipated by the human system designer. Here, we give a detailed description of a system architecture for self-referential autonomous learning which enables the refinement of object and situation models during operation in order to optimize behavior. This includes structural learning of hierarchical models for situations and behaviors that is triggered by a mismatch between expected and actual action outcome. Besides proposing architectural concepts, we also describe a first implementation of our system within a simulated traffic scenario to demonstrate the feasibility of our approach.},
author = {Damerow, Florian and Knoblauch, Andreas and K{\"{o}}rner, Ursula and Eggert, Julian and K{\"{o}}rner, Edgar},
doi = {10.1007/s12559-016-9407-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Computation/2016/Damerow et al. - 2016.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {autonomous learning {\'{a}} hierarchical,self-referential control {\'{a}} scene,situation model,understanding {\'{a}}},
pages = {1--17},
title = {{Toward Self-Referential Autonomous Learning of Object and Situation Models}},
url = {http://link.springer.com/10.1007/s12559-016-9407-7},
year = {2016}
}
@inproceedings{Licato2015,
abstract = {The ability to generate explanations of perceived events and of one's own actions is of central importance to how we make sense of the world. When modeling explanation generation, one common tactic used by cognitive systems is to construct a linkage of previously created cause- effect pairs. But where do such cause-effect pairs come from in the first place, and how can they be created automatically by cognitive systems? In this paper, we discuss the development of causal representations in children, by analyzing the literature surrounding a Piagetian experiment, and show how the conditions making cause-effect pair creation possi- ble can start to be modeled using a combination of feature-extraction techniques and the structured knowledge representation in the hybrid cognitive architecture CLARION. We create a task in PAGI World for learning causality, and make this task available for download.},
author = {Licato, John and Marton, Nick and Dong, Boning and Sun, Ron and Bringsjord, Selmer},
booktitle = {Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition},
editor = {Lieto, Antonio and Battaglino, Cristina and Radicioni, Daniele P. and Sanguinetti, Manuela},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition/2015/Licato et al. - 2015.pdf:pdf},
keywords = {analogy,clarion,cognitive architecture,explanation},
pages = {29--39},
series = {CEUR Workshop Proceedings},
title = {{Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generation in a Cognitive Architecture}},
year = {2015}
}
@article{Keramati2011a,
abstract = {Reinforcement learning models address animal's behavioral adaptation to its changing “external” environment, and are based on the assumption that Pavlo- vian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are con- cerned with behavioral adaptation in response to the “internal” state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that in- tegrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identi- cal. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.},
author = {Keramati, Mehdi and Gutkin, Boris},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nips/2011/Keramati, Gutkin - 2011.pdf:pdf},
isbn = {9781618395993},
journal = {Nips},
pages = {82--90},
title = {{A Reinforcement Learning theory for homeostatic regulation}},
year = {2011}
}
@article{Frank2012,
abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
author = {Frank, Michael J. and Badre, David},
doi = {10.1093/cercor/bhr114},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cerebral cortex (New York, N.Y. 1991)/2012/Frank, Badre - 2012.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Computer Simulation,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Humans,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reinforcement (Psychology)},
number = {3},
pages = {509--26},
pmid = {21693490},
title = {{Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3278315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {22},
year = {2012}
}
@article{Hampshire2016,
abstract = {The ability to learn new tasks rapidly is a prominent characteristic of human behaviour. This ability relies on flexible cognitive systems that adapt in order to encode temporary programs for processing non-automated tasks. Previous functional imaging studies have revealed distinct roles for the lateral frontal cortices (LFCs) and the ventral striatum in intentional learning processes. However, the human LFCs are complex; they house multiple distinct sub-regions, each of which co-activates with a different functional network. It remains unclear how these LFC networks differ in their functions and how they coordinate with each other, and the ventral striatum, to support intentional learning. Here, we apply a suite of fMRI connectivity methods to determine how LFC networks activate and interact at different stages of two novel tasks, in which arbitrary stimulus-response rules are learnt either from explicit instruction or by trial-and-error. We report that the networks activate en masse and in synchrony when novel rules are being learnt from instruction. However, these networks are not homogeneous in their functions; instead, the directed connectivities between them vary asymmetrically across the learning timecourse and they disengage from the task sequentially along a rostro-caudal axis. Furthermore, when negative feedback indicates the need to switch to alternative stimulus-response rules, there is additional input to the LFC networks from the ventral striatum. These results support the hypotheses that LFC networks interact as a hierarchical system during intentional learning and that signals from the ventral striatum have a driving influence on this system when the internal program for processing the task is updated.},
author = {Hampshire, Adam and Hellyer, Peter J. and Parkin, Beth and Hiebert, Nole and MacDonald, Penny and Owen, Adrian M. and Leech, Robert and Rowe, James},
doi = {10.1016/j.neuroimage.2015.11.060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/NeuroImage/2016/Hampshire et al. - 2016.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Caudate,Dynamic causal modelling,Frontal cortex,Functional connectivity,Learning},
pages = {123--134},
publisher = {The Authors},
title = {{Network mechanisms of intentional learning}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.11.060},
volume = {127},
year = {2016}
}
@article{Zendehrouh2015,
author = {Zendehrouh, Sareh},
doi = {10.1016/j.neunet.2015.08.006},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural Networks/2015/Zendehrouh - 2015.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {112--123},
publisher = {Elsevier Ltd},
title = {{A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608015001604},
volume = {71},
year = {2015}
}
@article{Chersi2014,
abstract = {A growing body of evidence in cognitive psychology and neuroscience suggests a deep interconnection between sensory-motor and language systems in the brain. Based on recent neurophysiological findings on the anatomo-functional organization of the fronto-parietal network, we present a computational model showing that language processing may have reused or co-developed organizing principles, functionality, and learning mechanisms typical of premotor circuit. The proposed model combines principles of Hebbian topological self-organization and prediction learning. Trained on sequences of either motor or linguistic units, the network develops independent neuronal chains, formed by dedicated nodes encoding only context-specific stimuli. Moreover, neurons responding to the same stimulus or class of stimuli tend to cluster together to form topologically connected areas similar to those observed in the brain cortex. Simulations support a unitary explanatory framework reconciling neurophysiological motor data with established behavioral evidence on lexical acquisition, access, and recall.},
author = {Chersi, Fabian and Ferro, Marcello and Pezzulo, Giovanni and Pirrelli, Vito},
doi = {10.1111/tops.12094},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in cognitive science/2014/Chersi et al. - 2014.pdf:pdf},
issn = {1756-8765},
journal = {Topics in cognitive science},
keywords = {computational modeling,lexical chains,motor chains,prediction,self-organizing maps,serial working memory,somatotopic organization},
number = {3},
pages = {476--91},
pmid = {24935737},
title = {{Topological self-organization and prediction learning support both action and lexical chains in the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24935737},
volume = {6},
year = {2014}
}
@article{Hasselmo2006,
author = {Howard, Marc W. and Fotedar, Mrigankka S. and Datey, Aditya V. and Hasselmo, Michael E.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychology Review/2005/Howard et al. - 2005.pdf:pdf},
journal = {Psychology Review},
number = {1},
pages = {75--116},
title = {{The Temporal Context Model in spatial navigation and relational learning: Toward a common explanation of medial temporal lobe function across domains}},
volume = {112},
year = {2005}
}
@article{Rasmussen2011,
abstract = {Abstract Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method ... $\backslash$n},
author = {Rasmussen, Daniel and Eliasmith, Chris},
doi = {10.1111/j.1756-8765.2010.01127.x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in Cognitive Science/2011/Rasmussen, Eliasmith - 2011.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Cognitive modeling,Fluid intelligence,Inductive reasoning,Neural engineering framework,Raven's progressive matrices,Realistic neural modeling,Rule generation,Vector symbolic architectures},
number = {1},
pages = {140--153},
title = {{A neural model of rule generation in inductive reasoning}},
volume = {3},
year = {2011}
}
@article{Dong2011a,
abstract = {We present a new model of sensorimotor learning in a systems-level cognitive model, LIDA. Sensorimotor learning helps an agent properly interact with its environment using past experi- ences. This new model stores and updates the rewards of pairs of data, motor commands and their contexts, using the concept of reinforcement learning; thus the agent is able to generate (output) effective commands in certain contexts based on its reward history. Following Global Workspace Theory, the primary basis of LIDA, the process of updating rewards in sensorimotor learning is cued by the agent's conscious content, the most salient portion of the agent's under- standing of the current situation, issued by the Global Workspace module of LIDA. Furthermore, we add a dynamic learning rate to control the extent to which a newly arriving reward may affect the reward update. This learning rate control mechanism is inspired by a hypothesis from neuroscience regarding memory of errors. Our experimental results show that sensorimotor learning using a dynamic learning rate improves performance in a simulated movement of push- ing a box.},
author = {Dong, Daqi and Franklin, Stan},
doi = {10.1016/j.bica.2015.09.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Dong, Franklin - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {a learning rate control,action,cognitive modeling,execution,in lida and add,in this paper,learning rate,lida 1,lida model,mechanism,sensorimotor learning,this is,we implement sensorimotor learning},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate}},
volume = {14},
year = {2015}
}
@article{Sun2004,
abstract = {This paper explores the interaction between implicit and explicit processes during skill learning, in terms of top-down learning (that is, learning that goes from explicit to implicit knowledge) versus bottom-up learning (that is, learning that goes from implicit to explicit knowledge). Instead of studying each type of knowledge (implicit or explicit) in isolation, we stress the interaction between the two types, especially in terms of one type giving rise to the other, and its effects on learning. The work presents an integrated model of skill learning that takes into account both implicit and explicit processes and both top-down and bottom-up learning. We examine and simulate human data in the Tower of Hanoi task. The paper shows how the quantitative data in this task may be captured using either top-down or bottom-up approaches, although top-down learning is a more apt explanation of the human data currently available. These results illustrate the two different directions of learning (top-down versus bottom-up), and thereby provide a new perspective on skill learning. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi},
doi = {10.1016/j.cogsys.2003.07.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2004/Sun, Zhang - 2004.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
pages = {63--89},
title = {{Top-down versus bottom-up learning in cognitive skill acquisition}},
volume = {5},
year = {2004}
}
@inproceedings{Rasmussen1998,
author = {Rasmussen, Daniel and Eliasmith, Chris},
booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 36th Annual Conference of the Cognitive Science Society/2014/Rasmussen, Eliasmith - 2014.pdf:pdf},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
number = {1},
pages = {1252--1257},
title = {{A neural model of hierarchical reinforcement learning}},
year = {2014}
}
@incollection{Hexmoor1996,
abstract = {Routine interactions in the world of an autonomous agent are a major source of learning for the agent. In my approach an agent interacts in the world in several different ways, from cognitive to automatic. I show that an agent can learn and also improve its routine interactions in its different modes of interaction in the world. I present a formalism and use for a goal structure known as goal sketch [11]. Rewards and punishments generated from a goal sketch which indicate progress in goal satisfaction are used to improve automatic interactions and enhance agent's strategies and concepts about action. I will discuss my experiments with a physical robot that uses a goal sketch in order to generate rewards and punishments which are then used in improving robot skills and discovering new actions.},
author = {Hexmoor, Henry},
booktitle = {Intelligent Agents II Agent Theories, Architectures, and Languages},
doi = {10.1007/3540608052_61},
editor = {Wooldridge, Michael and Muller, J{\"{o}}rg P. and Tambe, Milind},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Intelligent Agents II Agent Theories, Architectures, and Languages/1996/Hexmoor - 1996.pdf:pdf},
pages = {97--110},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Learning Routines}},
year = {1996}
}
@phdthesis{Rasmussen2014,
author = {Rasmussen, Daniel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Rasmussen - 2014.pdf:pdf},
pages = {175},
school = {Unversetu of Waterloo},
title = {{Hierarchical reinforcement learning in a biologically plausible neural architecture}},
year = {2014}
}
