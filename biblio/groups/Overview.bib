Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Waters2015,
abstract = {In a recent study of trends in language teaching pedagogy, I identified a major professional dichotomy regarding preferred approaches to the teaching of 'language knowledge'. In general, it was shown that the theoretical discourse of language teaching favoured a 'communicating-to-learn' approach in the matter (e.g., task-based learning), whereas the practitioner 'world' leaned more towards a 'learning-to-communicate' approach (e.g., Presentation-Practice-Production). The purpose of this paper is to build on these findings by attempting to determine to what extent either of these pedagogic stances can be justified. In doing so, recent research and theorising on the workings of memory in relation to the learning of factual information is reviewed. On the basis of the characteristics of cognitive architecture that this literature describes, it is taken to indicate that i), long-term memorisation of knowledge is the key to skilled performance, and ii), guided or 'direct' instruction is superior to problem-solving or discovery-oriented forms of pedagogy in facilitating the long-term learning of factual information. Following this, the implications of these findings for language teaching pedagogy are discussed. In particular, they are seen to provide a rationale for current professional perspectives concerning the teaching of language knowledge to be re-conceptualised.},
author = {Waters, Alan},
doi = {10.1016/j.system.2015.07.004},
isbn = {0346-251X},
issn = {0346251X},
journal = {System},
keywords = {Cognitive architecture,Communicating-to-learn,Learning-to-communicate,Memory,Teaching language knowledge},
pages = {141--147},
title = {{Cognitive architecture and the learning of language knowledge}},
volume = {53},
year = {2015}
}
@article{Kuhnberger2008,
abstract = {Whereas symbol-based systems, like deductive reasoning devices, knowledge bases, planning systems, or tools for solving constraint satisfaction problems, presuppose (more or less) the consistency of data and the consistency of results of internal computations, this is far from being plausible in real-world applications, in particular, if we take natural agents into account. Furthermore in complex cognitive systems, that often contain a large number of different modules, inconsistencies can jeopardize the integrity of the whole system. This paper addresses the problem of resolving inconsistencies in hybrid cognitively inspired systems on both levels, in single processing modules and in the overall system. We propose the hybrid architecture I-Cog as a flexible tool, that is explicitly designed to reorganize knowledge constantly and use occurring inconsistencies as a non-classical learning mechanism. {\textcopyright} 2008 The authors and IOS Press. All rights reserved.},
author = {K{\"{u}}hnberger, Kai Uwe and Geibel, Peter and Gust, Helmar and Krumnack, Ulf and Ovchinnikova, Ekaterina and Schwering, Angela and Wandmacher, Tonio},
isbn = {9781586038335},
issn = {09226389},
journal = {Frontiers in Artificial Intelligence and Applications},
keywords = {hybrid systems,inconsistencies,integrated cognition,learning},
number = {1},
pages = {212--223},
title = {{Learning from inconsistencies in an integrated cognitive architecture}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84875918017{\&}partnerID=tZOtx3y1},
volume = {171},
year = {2008}
}
@article{Gemignani2016,
abstract = {Robots, in order to properly interact with people and effectively perform the requested tasks, should have a deep and specific knowledge of the environment they live in. Current capabilities of robotic platforms in understanding the surrounding environment and the assigned tasks are limited, despite the recent progress in robotic perception. Moreover, novel improvements in human-robot interaction support the view that robots should be regarded as intelligent agents that can request the help of the user to improve their knowledge and performance. In this paper, we present a novel approach to semantic mapping. Instead of requiring our robots to autonomously learn every possible aspect of the environment, we propose a shift in perspective, allowing non-expert users to shape robot knowledge through human-robot interaction. Thus, we present a fully operational prototype system that is able to incrementally and on-line build a rich and specific representation of the environment. Such a novel representation combines the metric information needed for navigation tasks with the symbolic information that conveys meaning to the elements of the environment and the objects therein. Thanks to such a representation, we are able to exploit multiple AI techniques to solve spatial referring expressions and support task execution. The proposed approach has been experimentally validated on different kinds of environments, by several users, and on multiple robotic platforms.},
author = {Gemignani, Guglielmo and Capobianco, Roberto and Bastianelli, Emanuele and Bloisi, Domenico Daniele and Iocchi, Luca and Nardi, Daniele},
doi = {10.1016/j.robot.2015.11.001},
isbn = {0921-8890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Human-robot interaction,Knowledge representation,Semantic mapping},
pages = {1--16},
publisher = {Elsevier B.V.},
title = {{Living with robots: Interactive environmental knowledge acquisition}},
url = {http://dx.doi.org/10.1016/j.robot.2015.11.001},
volume = {78},
year = {2016}
}
@article{Collins2017,
abstract = {Learning from surprises is a cornerstone for building bio-inspired cognitive architectures that can autonomously learn from interactions with their environments. However, distinguishing true surprises - from which useful information can be extracted to improve an agent's world model - from environmental noise is a fundamental challenge. This paper proposes a new and robust approach for actively learning a predictive model of discrete, stochastic, partially-observable environments based on a concept called the Stochastic Distinguishing Experiment (SDE). SDEs are conditional probability distributions over the next observation given a variable-length sequence of ordered actions and expected observations up to the present that partition the space of possible agent histories, thus forming an approximate predictive representation of state. We derive this SDE-based learning algorithm and present theoretical proofs of its convergence and computational complexity. Theoretical and experimental results in small environments with important theoretical properties demonstrate the algorithm's ability to build an accurate predictive model from one continuous interaction with its environment without requiring any prior knowledge of the underlying state space, the number of SDEs to use, or even a bound on SDE length.},
author = {Collins, Thomas Joseph and Shen, Wei Min},
doi = {10.1016/j.bica.2017.07.005},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Active learning,Prediction,Surprise-based learning},
pages = {1--12},
publisher = {Elsevier B.V.},
title = {{A robust cognitive architecture for learning from surprises}},
url = {http://dx.doi.org/10.1016/j.bica.2017.07.005},
volume = {21},
year = {2017}
}
