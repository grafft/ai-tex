Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Gorodetsky2007,
abstract = {Данная работа представляет реализованную авторами P2P агентскую плат- форму, экземпляры которой, установленные в узлах сети поверх стандартного P2P серви- са, образуют распределенную базу знаний, предназначенную для организации семантическо- го P2P взаимодействия агентов. Прикладные агенты, в свою очередь, устанавливаются в узлах сети поверх экземпляров агентской платформы. В основу разработки положены функциональная архитектура, разработанная рабочей группой FIPA в качестве предложе- ния для последующей программной реализации и стандартизации. Разработанная про- граммная реализация платформы поддерживается также механизмом парных взаимодейст- вий агентов на основе сообщений разработанных форматов, а также парных коммуникаций узлов сети. Такой механизмом парных взаимодействий агентов также разработан автора- ми. Роль, функции и существо процессов функционирования этой платформы поясняется на примерах двух приложений, которые сами по себе являются достаточно важными с практи- ческой точки зрения. Эти же приложения использованы для верификации основных решений, предложенных в работе.},
author = {Городецкий, В. И. and Карсаев, О. В. and Самойлов, В. В. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Городецкий et al/2007/Открытые сети агентов.pdf:pdf},
journal = {Труды СПИИРАН},
language = {russian},
number = {4},
pages = {11--35},
title = {{Открытые сети агентов}},
year = {2007}
}
@article{Panov2016d,
abstract = {В работе исследуется задача автоматического планирования в контексте более общей проблемы создания интеллектуальных систем управления сложными техническими объектами (мобильными роботами, беспилотными транспортными средствами и др.). Основное внимание уделяется задачам, которые не могут быть решены без взаимодействия методов стратегического (символьного) и тактического (субсимвольного) планирования. В работе предлагаются оригинальные методы планирования на символьном (психологически правдоподобное планирование поведения агента) и субсимвольном (планирование траектории) уровнях. Описываются способы их взаимной увязки и возникающие прямые и обратные связи. Приводится описание применения указанных алгоритмов на модельном примере задачи коллективного перемещения в динамической среде с разрушаемыми препятствиями.},
author = {Панов, А. И. and Яковлев, К. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов, Яковлев/2016/Взаимодействие стратегического и тактического планирования поведения коалиций агентов в динамической среде.doc:doc;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов, Яковлев/2016/Взаимодействие стратегического и тактического планирования поведения коалиций агентов в динамической среде.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {15-37-20893,16-37-60055,A*,JPS,LIAN,elibrary,mypub,vak,автоматическое планирование,знаковая картина мира,значение,интеллектуальное планирование,личностный смысл,образ,планирование,планирование поведения,планирование траектории,эвристический поиск},
language = {russian},
mendeley-tags = {15-37-20893,16-37-60055,elibrary,mypub,vak},
number = {4},
pages = {68--78},
title = {{Взаимодействие стратегического и тактического планирования поведения коалиций агентов в динамической среде}},
url = {http://aidt.ru/index.php?option=com{\_}content{\&}view=article{\&}id=740:a-i-panov-k-s-yakovlev-vzaimodejstvie-strategicheskogo-i-takticheskogo-planirovaniya-povedeniya-koalitsii-agentov-v-dinamicheskoj-srede{\&}catid=291:modelirovanie-povedeniya-i-upravlenie{\&}Itemid=},
year = {2016}
}
@misc{Presentation2016c,
author = {Panov, Aleksandr I.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov/2016/Biologically and psychologically inspired modelling in BICA.pdf:pdf},
pages = {53},
title = {{Biologically and psychologically inspired modelling in BICA}},
year = {2016}
}
@article{Osipov2014c,
abstract = {Рассматриваются функции, которые в психологии принято относить к функциям сознания. К числу таких функций относятся рефлексия, осознание мотива деятельности, целеполагание, синтез целенаправленного поведения и некоторые иные. Описание опирается на понятие знака, достаточно широко используемое в психологии, в частности, в культурно-исторической теории Л.С.Выготского, где знак понимается неформальным образом. В настоящей работе уточняется понятие знака, рассматриваются механизмы формирования знаков и некоторые процедуры самоорганизации на множестве знаков. Благодаря работе механизмов самоорганизации возникает новый способ представления картины мира субъекта деятельности. Вводится понятие семиотической сети, которое используется для исследования картин мира субъектов. Строятся модели некоторых из указанных выше функций. Вторая часть статьи посвящена функциям самосознания и применению построенных моделей для задачи синтеза плана и построения новых архитектур интеллектуальных агентов, обладающих, в частности, способностями к распределению ролей в коалициях.},
author = {Осипов, Г. С. and Панов, А. И. and Чудова, Н. В.},
doi = {10.7868/S000233881404012X},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2014/Управление поведением как функция сознания. I. Картина мира и целеполагание.doc:doc;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2014/Управление поведением как функция сознания. I. Картина мира и целеполагание.pdf:pdf},
issn = {0002-3388},
journal = {Известия Российской академии наук. Теория и системы управления},
keywords = {12-07-00611,elibrary,mypub,vak},
language = {russian},
mendeley-tags = {12-07-00611,elibrary,mypub,vak},
number = {4},
pages = {49--62},
title = {{Управление поведением как функция сознания. I. Картина мира и целеполагание}},
url = {http://elibrary.ru/item.asp?doi=10.7868/S000233881404012X},
year = {2014}
}
@article{Kiselev2018a,
abstract = {В настоящей работе рассмотрена задача распределения ролей при составлении общего плана действий в коалиции когнитивных агентов. Когнитивные агенты реализуют основные функции интеллектуального агента с использованием моделей когнитивных функций человека. В качестве психологических оснований построения моделей когнитивных функций использованы теория деятельности и формальная модель знаковой картины мира. В работе представлен оригинальный метод распределения ролей – алгоритм MultiMAP, основанный на знаковом способе планирования поведения агента. Представлены основные особенности описываемого подхода, включающие способы представления знаний агента о себе и о других агентах, способы знаковой коммуникации и сохранения опыта кооперации с другими агентами. Описаны модельные эксперименты, демонстрирующие основные преимущества представленного подхода и некоторые недостатки, на устранение которых направлена будущая работа в данном направлении.},
author = {Киселев, Г. А. and Панов, А. И.},
doi = {10.15622/sp.57.7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Киселев, Панов/2018/Знаковый подход к задаче распределения ролей в коалиции когнитивных агентов.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Киселев, Панов/2018/Знаковый подход к задаче распределения ролей в коалиции когнитивных агентов(2).pdf:pdf},
issn = {2078-9181},
journal = {Труды СПИИРАН},
keywords = {16-37-60055,frccsc,hse,mypub,vak},
language = {russian},
mendeley-tags = {16-37-60055,frccsc,hse,mypub,vak},
number = {2},
pages = {161--187},
title = {{Знаковый подход к задаче распределения ролей в коалиции когнитивных агентов}},
url = {http://proceedings.spiiras.nw.ru/ojs/index.php/sp/article/view/3665},
year = {2018}
}
@article{Gorodetsky2012,
author = {Городецкий, В И},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Городецкий/2012/Самоорганизация и многоагентные системы. I. Модели многоагентной самоорганизации.pdf:pdf},
journal = {Известия РАН. Теория и системы управления},
language = {russian},
number = {2},
pages = {92--120},
title = {{Самоорганизация и многоагентные системы. I. Модели многоагентной самоорганизации}},
year = {2012}
}
@inproceedings{Kumar2017,
abstract = {We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.},
archivePrefix = {arXiv},
arxivId = {1712.08266},
author = {Kumar, Saurabh and Shah, Pararth and Hakkani-Tur, Dilek and Heck, Larry},
booktitle = {Hierarchical RL Workshop, NIPS 2017},
eprint = {1712.08266},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kumar et al/2017/Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning.pdf:pdf},
title = {{Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1712.08266},
year = {2017}
}
@article{Dietterich1998,
abstract = {This paper presents a new approach to hier- archical reinforcement learning based on the MAXQ decomposition of the value function. The MAXQ decomposition has both a procedu- ral semantics—as a subroutine hierarchy—and a declarative semantics—as a representation of the value function of a hierarchical policy. MAXQ unifies and extends previouswork on hierarchical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. Conditions under which the MAXQ decomposition can represent the optimal value function are derived. The paper defines a hierarchicalQlearning algorithm, proves its con- vergence, and shows experimentally that it can learn much faster than ordinary “flat” Q learn- ing. Finally, the paper discusses some interest- ing issues that arise in hierarchical reinforcement learning including the hierarchical credit assign- ment problem and non-hierarchical execution of theMAXQ hierarchy.},
author = {Dietterich, Thomas G},
file = {::},
isbn = {1-55860-556-8},
journal = {Proc. of the fifteenth international conference on machine learning},
number = {c},
pages = {118--126},
title = {{The MAXQ Method for Hierarchical Reinforcement Learning}},
year = {1998}
}
@article{Milford2014,
abstract = {Mobile robots and animals alike must effectively navigate their environments in order to achieve their goals. For animals goal-directed navigation facilitates finding food, seeking shelter or migration; similarly robots perform goal-directed navigation to find a charging station, get out of the rain or guide a person to a destination. This similarity in tasks extends to the environment as well; increasingly, mobile robots are operating in the same underwater, ground and aerial environments that animals do. Yet despite these similarities, goal-directed navigation research in robotics and biology has proceeded largely in parallel, linked only by a small amount of interdisciplinary research spanning both areas. Most state-of-the-art robotic navigation systems employ a range of sensors, world representations and navigation algorithms that seem far removed from what we know of how animals navigate; their navigation systems are shaped by key principles of navigation in 'real-world' environments including dealing with uncertainty in sensing, landmark observation and world modelling. By contrast, biomimetic animal navigation models produce plausible animal navigation behaviour in a range of laboratory experimental navigation paradigms, typically without addressing many of these robotic navigation principles. In this paper, we attempt to link robotics and biology by reviewing the current state of the art in conventional and biomimetic goal-directed navigation models, focusing on the key principles of goal-oriented robotic navigation and the extent to which these principles have been adapted by biomimetic navigation models and why.},
author = {Milford, M. and Schulz, R.},
doi = {10.1098/rstb.2013.0484},
file = {::},
isbn = {1471-2970},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
number = {1655},
pages = {20130484--20130484},
pmid = {25267826},
title = {{Principles of goal-directed spatial robot navigation in biomimetic models}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2013.0484},
volume = {369},
year = {2014}
}
@misc{Presentation2016d,
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2016/Теория сознания Тонони.pdf:pdf},
pages = {30},
title = {{Теория сознания Тонони}},
year = {2016}
}
@article{Yang2007,
author = {Yang, Jingan and Luo, Zhenghu},
doi = {10.1016/j.asoc.2006.04.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Yang, Luo/2007/Coalition formation mechanism in multi-agent systems based on genetic algorithms.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {agent coalition formation,chromosome encoding,crossover and mutation,genetic algorithm,multiagent system},
number = {2},
pages = {561--568},
title = {{Coalition formation mechanism in multi-agent systems based on genetic algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494606000421},
volume = {7},
year = {2007}
}
@inproceedings{Davoodabadi2011,
abstract = {In this paper the problem of automatically discovering subtasks and hierarchies in reinforcement learning is considered. We present a novel method that allows an agent to autonomously discover subgoals and create a hierarchy from actions. Our method identifies subgoals by partitioning local state transition graphs. Options constructed for reaching these subgoals are added to action choices and used for accelerating the Q-Learning algorithm. Experimental results show significant performance improvements, especially in the initial learning phase.},
author = {Davoodabadi, M and Beigy, H},
booktitle = {Proceedings of the 5th Indian International Conference on Artificial Intelligence, IICAI 2011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Davoodabadi, Beigy/2011/A new method for discovering subgoals and constructing options in reinforcement learning.pdf:pdf},
isbn = {9780972741286},
keywords = {Artificial intelligence,Autonomously discovering subgoals,Community detection,Hierarchical reinforcement learning,Learning algorithms,Learning phase,Local state,Option,Performance improvements,Q-learning algorithms,Reinforcement learning,Subgoals,Subtasks},
pages = {441--450},
title = {{A new method for discovering subgoals and constructing options in reinforcement learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872195092{\&}partnerID=40{\&}md5=9bf17b3f8f09d77ec8cd05285124028d},
year = {2011}
}
@article{Daniel2016,
abstract = {Tasks that require many sequential decisions are hard to solve using conventional rein- forcement learning algorithms. Based on the option framework, we propose a model which aims to alleviate these concerns. Instead of learning a single monolithic policy, the agent learns a set of simpler sub-policies as well as the initiation and termination probabili- ties for each of those sub-policies. While ex- isting option learning algorithms frequently require manual specification of components such as the sub-policies, we present an algo- rithm which infers all relevant components of the option framework from data. We present results on SMDPs with discrete as well as continuous state-action spaces. The results show that the presented algorithm can combine simple sub-policies to solve complex tasks and can improve learning performance on simpler tasks.},
author = {Daniel, Christian and van Hoof, Herke and Peters, Jan and Neumann, Gerhard},
doi = {10.1007/s10994-016-5580-x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Daniel et al/2016/Probabilistic inference for determining options in reinforcement learning.pdf:pdf},
issn = {15730565},
journal = {Machine Learning},
keywords = {Options,Reinforcement learning,Robot learning,Semi Markov decision process},
number = {2-3},
pages = {337--357},
publisher = {Springer US},
title = {{Probabilistic inference for determining options in reinforcement learning}},
volume = {104},
year = {2016}
}
@article{Wang2012a,
abstract = {Reinforcement learning has been an important category of machine learning approaches exhibiting self-learning and online learning characteristics. Using reinforcement learning, an agent can learn its behaviors through trial-and-error interactions with a dynamic environment and finally come up with an optimal strategy. Reinforcement learning suffers the curse of dimensionality, though there has been significant progress to overcome this issue in recent years. MAXQ is one of the most common approaches for reinforcement learning. To function properly, MAXQ requires a decomposition of the agent's task into a task hierarchy. Previously, the decomposition can only be done manually. In this paper, we propose a mechanism for automatic subtask discovery. The mechanism applies clustering to automatically construct task hierarchy required by MAXQ, such that MAXQ can be fully automated. We present the design of our mechanism, and demonstrate its effectiveness through theoretical analysis and an extensive experimental evaluation. {\textcopyright} 2012 IEEE.},
author = {Wang, Hongbing and Li, Wenya and Zhou, Xuan},
doi = {10.1109/ICTAI.2012.165},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Wang, Li, Zhou/2012/Automatic discovery and transfer of MAXQ hierarchies in a complex system.pdf:pdf},
isbn = {9780769549156},
issn = {10823409},
journal = {Proceedings of International Conference on Tools with Artificial Intelligence, ICTAI},
keywords = {Clustering,MAXQ,Reinforcement Learning,System of Systems},
pages = {1157--1162},
title = {{Automatic discovery and transfer of MAXQ hierarchies in a complex system}},
volume = {1},
year = {2012}
}
@article{Fang2014,
author = {Fang, Rui and Doering, Malcolm and Chai, Jy},
isbn = {9781577356783},
journal = {Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence},
keywords = {NLP and Machine Learning},
number = {Dale 1995},
pages = {1544--1550},
title = {{Collaborative Models for Referring Expression Generation in Situated Dialogue}},
url = {http://cse.msu.edu/{\%}7B{~}{\%}7Dfangrui/Papers/aaai2014-REG.pdf},
year = {2014}
}
@article{Duffy2008,
author = {Duffy, Brian},
journal = {Processing},
pages = {1--12},
title = {{Conversational Agents}},
year = {2008}
}
@inproceedings{Barto2004,
abstract = {Humans and other animals often engage in activities for their own sakes rather than as steps toward solving practical problems. Psychologists call these intrinsically motivated behaviors. What we learn during intrinsically motivated behavior is essential for our development as competent autonomous entities able to efficiently solve a wide range of practical problems as they arise. In this paper we present initial results from a computational study of intrinsically motivated learning aimed at allowing artificial agents to construct and extend hierarchies of reusable skills that are needed for competent autonomy. At the core of the model are recent theoretical and algorithmic advances in computational reinforcement learning, specifically, new concepts related to skills and new learning algorithms for learning with skill hierarchies. 1},
author = {Barto, Andrew G. and Singh, Satinder},
booktitle = {Proceedings of the 3rd International Conference on Development and Learning (ICDL 2004)},
doi = {10.1.1.123.395},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Barto, Singh/2004/Intrinsically motivated learning of hierarchical collections of skills.pdf:pdf},
pages = {112--119},
title = {{Intrinsically motivated learning of hierarchical collections of skills}},
url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.117.6436{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A083E47D2FE080D11716EC249E464BE2?doi=10.1.1.117.6436{\&}rep=rep1{\&}type=pdf},
year = {2004}
}
@article{Uv,
author = {Uv, R T S},
file = {::},
title = {{¢¤{\pounds}¦¥¨{\S} ¸ ¹ {\textcopyright} »3¸ {\textcopyright} {\S}}}
}
@article{Panov2015g,
abstract = {Рассматриваются особенности представления пространственных и временных знаний для планирования согласованного перемещения коалиции интеллектуальных агентов. В качестве примера подобной задачи рассмотрен перелет группы беспилотных летательных аппаратов в заданную область на местности с препятствиями. Рассматривается знаковый подход к описанию знаний агента, основанный на психологической теории деятельности и биологически правдоподобной иерархической модели распознавания. Особое внимание уделено описанию действий и процессам обучения на основе поступающей первичной информации.},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.pdf:pdf},
journal = {Робототехника и техническая кибернетика},
keywords = {14-07-31194,elibrary,mypub,группа БПЛА,знак,иерархия автоматов,когнитивные процессы,представление знаний},
language = {russian},
mendeley-tags = {14-07-31194,elibrary,mypub},
number = {4(9)},
pages = {34--40},
title = {{Представление знаний автономных агентов, планирующих согласованные перемещения}},
url = {https://elibrary.ru/item.asp?id=25085187},
year = {2015}
}
@article{Frank2012,
abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
author = {Frank, Michael J. and Badre, David},
doi = {10.1093/cercor/bhr114},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frank, Badre/2012/Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1 Computational analysis.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Computer Simulation,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Humans,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reinforcement (Psychology)},
number = {3},
pages = {509--26},
pmid = {21693490},
title = {{Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3278315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {22},
year = {2012}
}
@article{Pechoucek2002,
author = {Pechoucek, Michal and Marik, Vladimir and Barta, Jaroslav},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Pechoucek, Marik, Barta/2002/A Knowledge-Based Approach to Coalition Formation.pdf:pdf},
journal = {IEEE Intelligent Systems},
number = {3},
pages = {17--25},
title = {{A Knowledge-Based Approach to Coalition Formation}},
volume = {17},
year = {2002}
}
@inproceedings{Hayes2015,
abstract = {In this work, we present an algorithm for improv- ing collaborator performance on sequential manipulation tasks. Our agent-decoupled, optimization-based, task and motion planning approach merges considerations derived from both symbolic and geometric planning domains. This results in the generation of supportive behaviors enabling a teammate to reduce cognitive and kinematic burdens during task completion. We describe our algorithm alongside representative use cases, with an evaluation based on solving complex circuit building problems. We conclude with a discussion of applications and extensions to human-robot teaming scenarios.},
author = {Hayes, Bradley and Scassellati, Brian},
booktitle = {International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7354288},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hayes, Scassellati/2015/Effective Robot Teammate Behaviors for Supporting Sequential Manipulation Tasks.pdf:pdf},
isbn = {9781479999934},
issn = {21530866},
pages = {6374--6380},
title = {{Effective Robot Teammate Behaviors for Supporting Sequential Manipulation Tasks}},
url = {http://www.bradhayes.info/papers/iros15.pdf},
year = {2015}
}
@article{Nikolaidis2014,
abstract = {We present a framework for learning human user models from joint-action demonstrations that enables the robot to compute a robust policy for a collaborative task with a human. The learning takes place completely automatically, without any human intervention. First, we describe the clustering of demonstrated action sequences into different human types using an unsupervised learning algorithm. These demonstrated sequences are also used by the robot to learn a reward function that is representative for each type, through the employment of an inverse reinforcement learning algorithm. The learned model is then used as part of a Mixed Observability Markov Decision Process formulation, wherein the human type is a partially observable variable. With this framework, we can infer, either offline or online, the human type of a new user that was not included in the training set, and can compute a policy for the robot that will be aligned to the preference of this new user and will be robust to deviations of the human actions from prior demonstrations. Finally we validate the approach using data collected in human subject experiments, and conduct proof-of-concept demonstrations in which a person performs a collaborative task with a small industrial robot.},
archivePrefix = {arXiv},
arxivId = {1405.6341},
author = {Nikolaidis, Stefanos and Gu, Keren and Ramakrishnan, Ramya and Shah, Julie},
doi = {10.1145/2696454.2696455},
eprint = {1405.6341},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nikolaidis et al/2014/Efficient Model Learning for Human-Robot Collaborative Tasks.pdf:pdf},
isbn = {9781450328838},
issn = {21672148},
journal = {arXiv},
pages = {1--9},
title = {{Efficient Model Learning for Human-Robot Collaborative Tasks}},
url = {http://arxiv.org/abs/1405.6341},
year = {2014}
}
@phdthesis{George2008,
author = {George, Dileep},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George/2008/How the Brain Might Work a Hierarchical and Temporal Model for Learning and Recognition.pdf:pdf},
number = {June},
pages = {191},
school = {Stanford University},
title = {{How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition}},
year = {2008}
}
@article{Emelyanov2016,
abstract = {Extensive use of unmanned aerial vehicles (UAVs) in recent years has induced the rapid growth of research areas related to UAV production. Among these, the design of control systems capable of automating a wide range of UAV activities is one of the most actively explored and evolving. Currently, researchers and developers are interested in designing control systems that can be referred to as intelligent, e.g. the systems which are suited to solve such tasks as planning, goal prioritization, coalition formation etc. and thus guarantee high levels of UAV autonomy. One of the principal problems in intelligent control system design is tying together various methods and models traditionally used in robotics and aimed at solving such tasks as dynamics modelling, control signal genera- tion, location and mapping, path planning etc. with the methods of behaviour modelling and planning which are thoroughly studied in cognitive science. Our work is aimed at solving this problem. We propose layered architecture — STRL (strategic, tactical, reactive, layered) — of the control system that au- tomates the behaviour generation using a cognitive approach while taking into account complex dynamics and kinematics of the control object (UAV).We use a special type of knowledge representation — sign world model — that is based on the psychological activity theory to describe individual behaviour planning and coalition formation processes. We also propose path planning methodology which serves as the mediator between the high-level cognitive activities and the reactive control signals generation. To generate these signals we use a state-dependent Riccati equation and specific method for solving it. We believe that utilization of the proposed architecture will broaden the spectrum of tasks which can be solved by the UAV's coalition automatically, as well as raise the autonomy level of each individual member of that coalition.},
author = {Emel'yanov, Stanislav and Makarov, Dmitry and Panov, Aleksandr I. and Yakovlev, Konstantin},
doi = {10.1016/j.cogsys.2015.12.008},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Emel'yanov et al/2016/Multilayer cognitive architecture for UAV control.pdf:pdf},
issn = {1389-0417},
journal = {Cognitive Systems Research},
keywords = {14-11-00692,cognitive architecture,elibrary,intelligent control system,mypub,nonlinear control,path planning,scopus,sign world model,state-dependent Riccati equation,unmanned aerial vehicle,wos{\_}core},
mendeley-tags = {14-11-00692,elibrary,mypub,scopus,wos{\_}core},
pages = {58--72},
title = {{Multilayer cognitive architecture for UAV control}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041716000048},
volume = {39},
year = {2016}
}
@article{Zubarev2013,
abstract = {В статье рассматриваются и анализируются различные подходы к построению архитектуры системы управления беспилотным летательным аппаратом типа «вертолет». На основании проведенного анализа делается вывод о целесообразности применения иерархической, трехуровневой схемы – стратегический уровень, тактический уровень, уровень управления. Описываются решаемые на каждом уровне задачи и дается краткая характеристика методов, подходов и алгоритмов, потенциально применимых для их решения, выделяются наиболее перспективные на взгляд авторов методы и подходы.},
author = {Зубарев, Д. В. and Макаров, Д. А. and Панов, А. И. and Яковлев, К. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Зубарев et al/2013/Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Зубарев et al/2013/Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами.docx:docx},
journal = {Авиакосмическое приборостроение},
keywords = {12-07-00611,12-07-31057,12-07-31058,elibrary,mypub,алгоритмы управления,архитектура системы управления,беспилотные летательные аппараты,вертолеты,когнитивное компьютерное моделирование,методы планирования траекторий,регуляторы},
language = {russian},
mendeley-tags = {12-07-00611,12-07-31057,12-07-31058,elibrary,mypub},
number = {4},
pages = {10--28},
title = {{Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами}},
year = {2013}
}
@article{Levine2016,
abstract = {Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.},
archivePrefix = {arXiv},
arxivId = {1504.00702},
author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1504.00702},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Levine et al/2016/End-to-End Training of Deep Visuomotor Policies.pdf:pdf},
isbn = {9781479969227},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Neural Networks,Optimal Control,Reinforcement Learning,Vision},
pages = {1--40},
pmid = {15003161},
title = {{End-to-End Training of Deep Visuomotor Policies}},
volume = {17},
year = {2016}
}
@article{Potamianos2005a,
author = {Potamianos, Alexandros and Narayanan, Shrikanth and Member, Senior and Riccardi, Giuseppe},
doi = {10.1007/978-3-540-49127-9_35},
isbn = {9781598295993},
issn = {1947-4040},
journal = {Audio},
number = {3},
pages = {321--329},
title = {{Spoken Dialogue Systems}},
volume = {13},
year = {2005}
}
@inproceedings{Hengst2002,
abstract = {An open problem in reinforcement learning is discovering hierarchical structure. HEXQ, an algorithm which automatically attempts to decompose and solve a model-free fac- tored MDP hierarchically is described. By searching for aliased Markov sub-space re- gions based on the state variables the algo- rithm uses temporal and state abstraction to construct a hierarchy of interlinked smaller MDPs.},
author = {Hengst, Bernhard},
booktitle = {Proceedings of the International Conference on Machine Learning ICML 2002},
doi = {10.1.1.9.5839},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hengst/2002/Discovering hierarchy in reinforcement learning with HEXQ.pdf:pdf},
isbn = {1-55860-873-7},
pages = {243--250},
title = {{Discovering hierarchy in reinforcement learning with HEXQ}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.5839},
year = {2002}
}
@inproceedings{Makarov2016,
abstract = {Работа посвящена архитектуре системы управления сложными техническими объектами, рассматриваемыми как интеллектуальные агенты. В качестве таких объектов взяты малые беспилотные летательные аппараты (БПЛА) мультикоптерного типа. Архитектура состоит из трех уровней: стратегического, тактического и реактивного. Её применение позволит автоматизировать управление как отдельными БПЛА, так и их коалициями БПЛА при решении широкого круга задач.},
address = {Смоленск},
author = {Макаров, Д. А. and Панов, А. И. and Яковлев, К. С.},
booktitle = {Пятнадцатая национальная конференция по искусственному интеллекту с международным участием КИИ-2016 (3-7 октября 2016г., г.Смоленск, Россия): Труды конференции},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2016/STRL многоуровневая система управления интеллектуальными агентами.doc:doc;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2016/STRL многоуровневая система управления интеллектуальными агентами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2016/STRL многоуровневая система управления интеллектуальными агентами.pdf:pdf},
isbn = {978-5-91412-316-8},
keywords = {14-11-00692,elibrary,myconf,беспилотные летательные аппараты,знаковая картина мира,интеллектуальная система управления,многоуровневая архитектура,нелинейное управление,планирование поведения,планирование траектории,уравнение Риккати},
language = {russian},
mendeley-tags = {14-11-00692,elibrary,myconf},
pages = {179--188},
publisher = {Универсум},
title = {{STRL: многоуровневая система управления интеллектуальными агентами}},
volume = {1},
year = {2016}
}
@article{Traum,
abstract = {SLIDES!},
author = {Traum, David},
title = {{Approaches to dialogue systems and dialogue management}}
}
@article{Bai2017a,
abstract = {In the context of hierarchical reinforcement learn-ing, the idea of hierarchies of abstract machines (HAMs) is to write a partial policy as a set of hierar-chical finite state machines with unspecified choice states, and use reinforcement learning to learn an optimal completion of this partial policy. Given a HAM with deep hierarchical structure, there of-ten exist many internal transitions where a machine calls another machine with the environment state unchanged. In this paper, we propose a new hier-archical reinforcement learning algorithm that au-tomatically discovers such internal transitions, and shortcircuits them recursively in the computation of Q values. The resulting HAMQ-INT algorithm outperforms the state of the art significantly on the benchmark Taxi domain and a much more complex RoboCup Keepaway domain.},
author = {Bai, Aijun and Russell, Stuart},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bai, Russell/2017/Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging Internal Transitions.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {Proc. of the 26th International Joint Conference on Artificial Intelligence},
keywords = {2017,HAM,HRL,Machine Learning: Reinforcement Learning,Planning and Scheduling: Markov Decisions Processe,RL,Robotics and Vision: Multi-Robot Systems,Robotics and Vision: Robotics},
mendeley-tags = {2017,HAM,HRL,RL},
pages = {1418--1424},
title = {{Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging Internal Transitions}},
year = {2017}
}
@article{Epstein2013,
abstract = {This paper describes how a cognitive architecture builds a spatial model and navigates from it without a map. Each con- structed model is a collage of spatial affordances that de- scribes how the environment has been sensed and traversed. The system exploits the evolving model while it directs an agent to explore the environment. Effective models are learned quickly during travel. Moreover, when combined with simple heuristics, the learned spatial model supports effective navigation. In three simple environments, these learned mod- els describe space in ways familiar to people, and often pro- duce near-optimal travel times.},
author = {Epstein, Susan L. and Aroor, Anoop and Sklar, Elizabeth I. and Parsons, Simon},
file = {::},
keywords = {affordances,cognitive architecture,exploration,learning,spatial,spatial cognition},
pages = {1--6},
title = {{Navigation with Learned Spatial Affordances}},
url = {http://www.compsci.hunter.cuny.edu/{~}epstein/papers/CogSciFinal.Epstein.pdf},
year = {2013}
}
@article{Chudova2012b,
author = {Чудова, Н. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Чудова/2012/Концептуальное описание картины мира для задачи моделирования поведения, основанного на сознании.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {12-07-00611,psycho},
language = {russian},
mendeley-tags = {12-07-00611,psycho},
number = {2},
pages = {51--62},
title = {{Концептуальная модель картины мира для задачи моделирования поведения, основанного на сознании}},
year = {2012}
}
@article{Lester2004,
abstract = {Conversational agents integrate computational linguistics techniques with the communi- cation channel of theWeb to interpret and respond to statements made by users in ordinary natural language. Web-based conversational agents deliver high-volumes of interactive text-based dialogs. Recent years have seen significant activity in enterprise-class conversational agents. This chap- ter describes the principal applications of conversational agents in the enterprise and the technical challenges posed by their design and large-scale deployments. These technical challenges fall into two categories: accurate and efficient natural-language processing; and the scalability, performance, reliability, integration, and maintenance requirements posed by enterprise deployments},
author = {Lester, James and Mott, Bradford},
isbn = {978-1584883814},
journal = {The Practical Handbook of Internet Computing},
pages = {220--240},
title = {{Conversational Agents}},
year = {2004}
}
@inproceedings{Rasmussen1998,
author = {Rasmussen, Daniel and Eliasmith, Chris},
booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen, Eliasmith/2014/A neural model of hierarchical reinforcement learning.pdf:pdf},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
number = {1},
pages = {1252--1257},
title = {{A neural model of hierarchical reinforcement learning}},
year = {2014}
}
@article{Gorodotsky2015,
author = {Городецкий, В. И. and Самойлов, В. В. and Троцкий, Д. В.},
doi = {10.7868/S0002338815030087},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Городецкий, Самойлов, Троцкий/2015/Базовая онтология коллективного поведения автономных агентов и ее расширения.pdf:pdf},
isbn = {0002338815},
issn = {0002-3388},
journal = {Известия РАН. Теория и системы управления},
language = {russian},
number = {5},
pages = {102--121},
title = {{Базовая онтология коллективного поведения автономных агентов и ее расширения}},
url = {http://elibrary.ru/item.asp?doi=10.7868/S0002338815030087},
year = {2015}
}
@article{Kaplan2004,
abstract = {This chapter presents a generic internal reward system that drives an agent to increase the complexity of its behavior. This reward system does not reinforce a predefined task. Its purpose is to drive the agent to progress in learning given its embodiment and the environment in which it is placed. The dynamics created by such a system are studied first in a simple environment and then in the context of active vision.},
author = {Kaplan, Frederic and Oudeyer, Pierre-Yves},
doi = {10.1007/b99075},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kaplan, Oudeyer/2004/Maximizing learning progress An internal reward system for development.pdf:pdf},
isbn = {3-540-22484-X},
issn = {03029743},
journal = {Embodied artificial intelligence},
keywords = {Active vision,Artificial intelligence,Reward},
pages = {259--270},
title = {{Maximizing learning progress: An internal reward system for development}},
volume = {3139},
year = {2004}
}
@book{Berg2014,
abstract = {Current spoken dialogue systems are often criticised because they lack natural behaviour. In this thesis, a model to facilitate the development of user-friendly dialogues for information and control systems (e.g. travel-booking or smart room control systems) is created in order to address this problem. This also includes a study about the users' preferences, the classification of utterances according to intention and answer type and the development of a dialogue engine that can process dialogues based on this model.$\backslash$r$\backslash$nThe developed model describes the dialogue flow and the combination of questions, answers and the resulting actions. Features like mixed initiative, open-ended questions, subdialogues and adaptable phrasings of system utterances lead to more natural dialogues and increase the usability of dialogue systems while linguistic datatypes, abstract question descriptions in connection with answer types and language generation methods enormously facilitate the definition of such dialogues for the developer. The separation of dialogue model and dialogue engine makes possible the reuse of base functionalities und prevents the mixing of execution logic and dialogue knowledge. The engine contains dialogue acts to classify user utterances and to prevent ambiguities as well as language understanding modules to identify the user's goal. In addition, it infers the next dialogue step under consideration of the specified dialogue behaviour.$\backslash$r$\backslash$nBy implementing the Natural Dialogue System (NADIA), that runs the XML-based model, the functionality is proven.},
author = {Berg, Markus M.},
isbn = {9783898385084},
keywords = {Dialogmodellierung,Sprachdialogsystem,Sprachverarbeitung,dialogue modelling,natural language processing,spoken dialogue system},
title = {{Modelling of Natural Dialogues in the Context of Speech-based Information and Control Systems}},
url = {http://macau.uni-kiel.de/receive/dissertation{\_}diss{\_}00016739},
year = {2014}
}
@article{Mcgovern2001,
abstract = {An ability to adjust to changing environments and unforeseen circumstances is likely to be an important component of a successful autonomous space robot. This paper shows how to augment reinforcement learning algorithms with a method for automatically discovering certain types of subgoals online. By creating useful new subgoals while learning, the agent is able to accelerate learning on a current task and to transfer its expertise to related tasks through the reuse of its ability to attain subgoals. Subgoals are created based on commonalities across multiple paths to a solution. We cast the task of finding these commonalities as a multiple-instance learning problem and use the concept of diverse density to find solutions. We introduced this approach in [10] and here we present additional results for a simulated mobile robot task.},
author = {Mcgovern, Amy and Barto, Andrew},
file = {::},
journal = {6th International Symposium on Artificial Intelligence, Robotics, and Automation in Space},
keywords = {automatic discovering,reinforcement learning,subgoal discovering},
title = {{Accelerating reinforcement learning through the discovery of useful subgoals}},
url = {/home/obada/Desktop/MAS 1 - ISW/Robot Learning/Accelerating reinforcement learning through the discovery of useful subgoals.pdf},
year = {2001}
}
@article{Konidaris2012,
abstract = {We present a framework for transfer in reinforcement learning based on the idea that related tasks share some common features, and that transfer can be achieved via those shared features. The framework attempts to capture the notion of tasks that are related but distinct, and provides some insight into when transfer can be usefully applied to a problem sequence and when it cannot. We apply the framework to the knowledge transfer problem, and show that an agent can learn a portable shaping function from experience in a sequence of tasks to significantly improve performance in a later related task, even given a very brief training period. We also apply the framework to skill transfer, to show that agents can learn portable skills across a sequence of tasks that significantly improve performance on later related tasks, approaching the performance of agents given perfectly learned problem-specific skills.},
author = {Konidaris, George and Scheidwasser, Ilya and Barto, Andrew G.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Konidaris, Scheidwasser, Barto/2012/Transfer in reinforcement learning via shared features.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {reinforcement learning,shaping,skills,transfer},
number = {1},
pages = {1333--1371},
title = {{Transfer in reinforcement learning via shared features}},
url = {http://dl.acm.org/citation.cfm?id=2503308.2343689{\%}5Cnhttp://dl.acm.org/ft{\_}gateway.cfm?id=2343689{\&}type=pdf},
volume = {13},
year = {2012}
}
@inproceedings{Panov2012c,
abstract = {В работе представлена архитектура интеллектуального агента, поведение которого моделирует процесс принятия решения специалистом в некоторой предметной области. Знания агента хранятся в знаковой форме, коммуникации агентов между собой осуществляются с помощью знакового опосредования. Описывается система проведения экспериментов с такими интеллектуальными агентами, реализованная на основе мультиагентной системы Jadex. Также представлен анализ данных серии экспермиентов, проведенных в построенной системе для интеллектуальных агентов, моделирующих процесс интерпретации жалоб психологом-консультантом.},
address = {Рыбинск},
author = {Панов, А. И.},
booktitle = {Теория и практика системного анализа: Труды II Всероссийской научной конференции молодых учёных с международным участием},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2012/Моделирование процесса принятия решения агентом со знаковой картиной мира.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2012/Моделирование процесса принятия решения агентом со знаковой картиной мира.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2012/Моделирование процесса принятия решения агентом со знаковой картиной мира.doc:doc},
keywords = {myconf},
language = {russian},
mendeley-tags = {myconf},
pages = {126--137},
publisher = {РГАТУ имени П.А. Соловьева},
title = {{Моделирование процесса принятия решения агентом со знаковой картиной мира}},
volume = {I},
year = {2012}
}
@book{Osipov2018a,
abstract = {В монографии рассмотрено возникновение и формирование картин мира субъекта деятельности. Рассматривается понятие знака в качестве основного элемента картины мира. Приведены психологические и нейрофизиологические основания знаковой структуры картин мира. Строится модель знака, рассматриваются структура знака, семейства отношений и операций на множестве знаков. Показывается, что различные семейства отношений на множестве знаков позволяют моделировать различные типы картин мира. Продемонстрированы возможности знакового подхода в моделировании некоторых когнитивных функций, таких как целеполагание и динамическое распределение ролей в коалициях субъектов деятельности. Книга предназначена специалистам в области искусственного интеллекта, психологии, лингвистики и всем интересующимся проблемами моделирования человеческого сознания. Может быть использована аспирантами и студентами старших курсов университетов.},
address = {М.},
author = {Осипов, Г. С. and Панов, А. И. and Чудова, Н. В. and Кузнецова, Ю. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов et al/2018/Знаковая картина мира субъекта поведения(2).pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов et al/2018/Знаковая картина мира субъекта поведения(3).pdf:pdf},
isbn = {978-5-9221-1781-4},
keywords = {15-07-06214,17-17-00138,frccsc,mybook,osipov},
language = {russian},
mendeley-tags = {15-07-06214,17-17-00138,frccsc,mybook,osipov},
pages = {264},
publisher = {Физматлит},
title = {{Знаковая картина мира субъекта поведения}},
url = {http://www.rfbr.ru/rffi/ru/books/o{\_}2052004},
year = {2018}
}
@article{Rasmussen2017a,
abstract = {We present the first model capable of performing hierarchical reinforcement learning in a general, neurally detailed imple-mentation. We show that this model is able to learn a spatial pickup and delivery task more quickly than one without hier-archical abilities. In addition, we show that this model is able to leverage its hierarchical structure to transfer learned knowl-edge between related tasks. These results point towards the advantages to be gained by using a hierarchical RL framework to understand the brain's powerful learning ability.},
author = {Rasmussen, Daniel and Voelker, Aaron and Eliasmith, Chris},
doi = {10.1371/journal.pone.0180234},
editor = {Cymbalyuk, Gennady},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen, Voelker, Eliasmith/2017/A neural model of hierarchical reinforcement learning.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
month = {jul},
number = {7},
pages = {e0180234},
title = {{A neural model of hierarchical reinforcement learning}},
url = {http://dx.plos.org/10.1371/journal.pone.0180234},
volume = {12},
year = {2017}
}
@article{Osipov2014c,
abstract = {Рассматриваются функции, которые в психологии принято относить к функциям сознания. К числу таких функций относятся рефлексия, осознание мотива деятельности, целеполагание, синтез целенаправленного поведения и некоторые иные. Описание опирается на понятие знака, достаточно широко используемое в психологии, в частности, в культурно-исторической теории Л.С.Выготского, где знак понимается неформальным образом. В настоящей работе уточняется понятие знака, рассматриваются механизмы формирования знаков и некоторые процедуры самоорганизации на множестве знаков. Благодаря работе механизмов самоорганизации возникает новый способ представления картины мира субъекта деятельности. Вводится понятие семиотической сети, которое используется для исследования картин мира субъектов. Строятся модели некоторых из указанных выше функций. Вторая часть статьи посвящена функциям самосознания и применению построенных моделей для задачи синтеза плана и построения новых архитектур интеллектуальных агентов, обладающих, в частности, способностями к распределению ролей в коалициях.},
author = {Осипов, Г. С. and Панов, А. И. and Чудова, Н. В.},
doi = {10.7868/S000233881404012X},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2014/Управление поведением как функция сознания. I. Картина мира и целеполагание.doc:doc;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2014/Управление поведением как функция сознания. I. Картина мира и целеполагание.pdf:pdf},
issn = {0002-3388},
journal = {Известия Российской Академии Наук. Теория и системы управления},
keywords = {12-07-00611,elibrary,mypub,vak},
language = {russian},
mendeley-tags = {12-07-00611,elibrary,mypub,vak},
number = {4},
pages = {49--62},
title = {{Управление поведением как функция сознания. I. Картина мира и целеполагание}},
url = {http://elibrary.ru/item.asp?doi=10.7868/S000233881404012X},
year = {2014}
}
@inproceedings{Jakubuv2015,
abstract = {Multiagent planning is a coordination technique used for deliberative acting of a team of agents. One of vital planning techniques uses declarative description of agents' plans based on Finite State Machines and their later coordination by intersection of such machines with successive verification of the resulting joint plans. In this work, we firstly propose to use projections of agents' actions directly for multiagent planning based on iterative building of a coordinated multiagent plan. Secondly, we describe integration of the static analysis provided by process calculi type systems for approximate verification of exchanged local plans. Finally, we compare our approach with current state-of-the-art planner on an extensive benchmark set.},
author = {Jakubův, Jan and To{\v{z}}i{\v{c}}ka, Jan and Komenda, Anton{\'{i}}n},
booktitle = {Proceedings of the International Conference on Agents and Artificial Intelligence},
doi = {10.5220/0005222101730182},
file = {:C$\backslash$:/Users/sanek/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jakubův, To{\v{z}}i{\v{c}}ka, Komenda - 2015 - Multiagent Planning by Plan Set Intersection and Plan Verification.pdf:pdf},
isbn = {978-989-758-073-4},
pages = {173--182},
publisher = {SCITEPRESS - Science and and Technology Publications},
title = {{Multiagent Planning by Plan Set Intersection and Plan Verification}},
url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005222101730182},
year = {2015}
}
@article{Tamar2016,
abstract = {We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.},
archivePrefix = {arXiv},
arxivId = {1602.02867},
author = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
eprint = {1602.02867},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Tamar et al/2016/Value Iteration Networks.pdf:pdf},
journal = {arXiv},
month = {feb},
pages = {1--14},
title = {{Value Iteration Networks}},
url = {http://arxiv.org/abs/1602.02867},
year = {2016}
}
@article{Vezhnevets2017a,
abstract = {We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment.},
archivePrefix = {arXiv},
arxivId = {1703.01161},
author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
eprint = {1703.01161},
file = {::},
issn = {1938-7228},
title = {{FeUdal Networks for Hierarchical Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.01161},
year = {2017}
}
@article{Potamianos2005,
author = {Potamianos, Alexandros and Narayanan, Shrikanth and Member, Senior and Riccardi, Giuseppe},
doi = {10.1007/978-3-540-49127-9_35},
isbn = {9781598295993},
issn = {1947-4040},
journal = {Audio},
number = {3},
pages = {321--329},
title = {{Spoken Dialogue Systems}},
volume = {13},
year = {2005}
}
@article{Nichol2018,
abstract = {This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work.},
archivePrefix = {arXiv},
arxivId = {1803.02999},
author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
eprint = {1803.02999},
file = {::},
pages = {1--15},
title = {{On First-Order Meta-Learning Algorithms}},
url = {http://arxiv.org/abs/1803.02999},
year = {2018}
}
@incollection{Jones2006,
abstract = {As we progress towards a world where robots play an integral role in society, a critical problem that remains to be solved is the pickup team challenge; that is, dynamically formed heterogeneous robot teams executing coordinated tasks where little information is known a priori about the tasks, the robots, and the environments in which they would operate. Successful solutions to forming pickup teams would enable researchers to experiment with larger numbers of robots and enable industry to efficiently and cost-effectively integrate new robot technology with existing legacy teams. In this paper, we define the challenge of pickup teams and propose the treasure hunt domain for evaluating the performance of pickup teams. Additionally, we describe a basic implementation of a pickup team that can search and discover treasure in a previously unknown environment. We build on prior approaches in market-based task allocation and plays for synchronized task execution, to allocate roles amongst robots in the pickup team, and to execute synchronized team actions to accomplish the treasure hunt task},
author = {Jones, E. Gil and Browning, Brett and Dias, M. Bernardine and Argall, Brenna and Veloso, Manuela and Stentz, Anthony},
booktitle = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006},
doi = {10.1109/ROBOT.2006.1641771},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Jones et al/2006/Dynamically formed heterogeneous robot teams performing tightly-coordinated tasks.pdf:pdf},
isbn = {0780395069},
issn = {10504729},
pages = {570--575},
title = {{Dynamically formed heterogeneous robot teams performing tightly-coordinated tasks}},
year = {2006}
}
@article{Schrodt2017,
author = {Schrodt, Fabian and Kneissler, Jan and Ehrenfeld, Stephan and Butz, Martin V.},
doi = {10.1111/tops.12252},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Schrodt et al/2017/Mario Becomes Cognitive.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {artificial intelligence,cognitive architecture,cognitive science and games,self-},
pages = {1--31},
title = {{Mario Becomes Cognitive}},
url = {http://doi.wiley.com/10.1111/tops.12252},
year = {2017}
}
@article{Siagian2007,
abstract = {We present a robot localization system using biologically-inspired$\backslash$nvision. Our system models two extensively studied human visual capabilities:$\backslash$n(1) extracting the {\^{a}}gist{\^{a}} of a scene to produce a coarse localization$\backslash$nhypothesis, and (2) refining it by locating salient landmark regions$\backslash$nin the scene. Gist is computed here as a holistic statistical signature$\backslash$nof the image, yielding abstract scene classification and layout.$\backslash$nSaliency is computed as a measure of interest at every image location,$\backslash$nefficiently directing the time-consuming landmark identification$\backslash$nprocess towards the most likely candidate locations in the image.$\backslash$nThe gist and salient landmark features are then further processed$\backslash$nusing a Monte-Carlo localization algorithm to allow the robot to$\backslash$ngenerate its position. We test the system in three different outdoor$\backslash$nenvironments - building complex (126x180ft. area, 3794 testing images),$\backslash$nvegetation-filled park (270x360ft. area, 7196 testing images), and$\backslash$nopen-field park (450x585ft. area, 8287 testing images) - each with$\backslash$nits own challenges. The system is able to localize, on average, within$\backslash$n6.0, 10.73, and 32.24 ft., respectively, even with multiple kidnapped-robot$\backslash$ninstances.},
author = {Siagian, Christian and Itti, Laurent},
doi = {10.1109/IROS.2007.4399349},
file = {::},
isbn = {1424409128},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {1723--1730},
title = {{Biologically-inspired robotics vision Monte-Carlo localization in the outdoor environment}},
year = {2007}
}
@article{Epstein2015,
abstract = {Background: Optimal navigation for a simulated robot relies on a detailed map and explicit path planning. This is problematic for realworld robots, whose sensors and actuators are subject to noise and error, and whose environment may be dynamic. This paper reports on robots that rely on local spatial perception, learning, and commonsense rationales instead. Aims: Our thesis is that spatial abstractions learned from local sensing can support effective, autonomous robot navigation. Method: The simulated robot experiences real-world actuator error while it navigates autonomously. The robot's decision-making cognitive architecture relies on reactive and heuristic procedures based on simple rationales and spatial abstractions of where it has been. As the robot travels, it learns (and shares) affordances that facilitate movement, including perceived unobstructed areas and trail markers. Together they represent the environment but do not constitute a map. Robots navigate to five sets of targets in each of three environments. Results: This approach quickly produces efficient travel without planning or a map. Metrics include travel time, decision time, and distance. Experiments examine the impact of each kind of affordance. Comparison with a traditional A∗ planner shows that performance becomes only slightly suboptimal for one robot. Preliminary data with multiple robots suggest that, because our approach does need to replan when actuators err or robots threaten to collide, it will outperform the traditional approach. Conclusions: People have been shown not to navigate from detailed mental maps. Robots can also learn to navigate well without them, when they learn from local percepts.},
author = {Epstein, Susan L. and Aroor, Anoop and Evanusa, Matthew and Sklar, Elizabeth I. and Parsons, Simon},
doi = {10.1007/s10339-015-0713-x},
file = {::},
issn = {16124790},
journal = {Cognitive Processing},
keywords = {Qualitative reasoning,Robot navigation,Spatial abstractions,Spatial model},
pages = {215--219},
publisher = {Springer Berlin Heidelberg},
title = {{Spatial abstraction for autonomous robot navigation}},
volume = {16},
year = {2015}
}
@article{Singh2010,
abstract = {There is great interest in building intrinsic motivation into artificial systems using the reinforcement learning framework. Yet, what intrinsic motivation may mean computationally, and how it may differ from extrinsic motivation, remains a murky and controversial subject. In this paper, we adopt an evolutionary perspective and define a new optimal reward framework that captures the pressure to design good primary reward functions that lead to evolutionary success across environments. The results of two computational experiments show that optimal primary reward signals may yield both emergent intrinsic and extrinsic motivation. The evolutionary perspective and the associated optimal reward framework thus lead to the conclusion that there are no hard and fast features distinguishing intrinsic and extrinsic reward computationally. Rather, the directness of the relationship between rewarding behavior and evolutionary success varies along a continuum.},
author = {Singh, Satinder and Lewis, Richard L. and Barto, Andrew G. and Sorg, Jonathan},
doi = {10.1109/TAMD.2010.2051031},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Singh et al/2010/Intrinsically Motivated Reinforcement Learning An Evolutionary Perspective(2).pdf:pdf},
isbn = {0262195348, 9780262195348},
issn = {1943-0604},
journal = {IEEE Transactions on Autonomous Mental Development},
number = {2},
pages = {70--82},
title = {{Intrinsically Motivated Reinforcement Learning: An Evolutionary Perspective}},
url = {http://ieeexplore.ieee.org/document/5471106/},
volume = {2},
year = {2010}
}
@phdthesis{Panov2015g,
abstract = {Построена модель компонент знака—элемента картины мира субъекта деятельности в рамках сегодняшних представлений о функционировании мозга и психики человека. Построены четыре типа операторов распознавания (два статических оператора, динамический и иерархический операторы) в терминах алгебраической теории для образной компоненты знака. Доказаны теоремы корректности линейных замыканий множеств построенных в работе операторов распознавания (статических, динамического и иерархического).},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Исследование методов, разработка моделей и алгоритмов формирования элементов знаковой картины мира субъекта деятельности.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Исследование методов, разработка моделей и алгоритмов формирования элементов знаковой картины мира субъекта деятельности.pdf:pdf},
keywords = {14-07-31194,myth},
language = {russian},
mendeley-tags = {14-07-31194,myth},
pages = {118},
school = {Федеральное государственное бюджетное учреждение науки Институт системного анализа Российской академии наук},
title = {{Исследование методов, разработка моделей и алгоритмов формирования элементов знаковой картины мира субъекта деятельности}},
year = {2015}
}
@article{Kaelbling1993,
abstract = {This paper presents the HDG learning algorithm, which uses a hierarchical decomposition of the state space to make learning to achieve goals more efficient with a small penalty in path qual-ity. Special care must be taken when performing hierarchical planning and learning in stochastic domains, because macro-operators cannot be ex-ecuted ballistically. The HDG algorithm, which is a descendent of Watkins' Q-learning algorithm, is described here and preliminary empirical re-sults are presented.},
author = {Kaelbling, Leslie},
file = {::},
journal = {Proceedings of the Tenth International Conference on Machine Learning},
pages = {167--173},
title = {{Hierarchical Learning in Stochastic Domains: Preliminary Results}},
url = {http://people.csail.mit.edu/lpk/papers/ml93.ps},
year = {1993}
}
@article{Vig2006,
author = {Vig, Lovekesh and Adams, Julie A and Member, Senior},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vig, Adams, Member/2006/Multi-Robot Coalition Formation.pdf:pdf},
journal = {IEEE Transactions on Robotics},
number = {4},
pages = {637--649},
title = {{Multi-Robot Coalition Formation}},
volume = {22},
year = {2006}
}
@article{Dann2017a,
abstract = {In platform videogames, players are frequently tasked with solving medium-term navigation prob-lems in order to gather items or powerups. Arti-ficial agents must generally obtain some form of direct experience before they can solve such tasks. Experience is gained either through training runs, or by exploiting knowledge of the game's physics to generate detailed simulations. Human players, on the other hand, seem to look ahead in high-level, abstract steps. Motivated by human play, we intro-duce an approach that leverages not only abstract " skills " , but also knowledge of what those skills can and cannot achieve. We apply this approach to Infinite Mario, where despite facing randomly generated, maze-like levels, our agent is capable of deriving complex plans in real-time, without rely-ing on perfect knowledge of the game's physics.},
author = {Dann, Michael and Zambetta, Fabio and Thangarajah, John},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dann, Zambetta, Thangarajah/2017/Real-time navigation in classical platform games via skill reuse.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning: Reinforcement Learning,Multidisciplinary Topics and Applications: Compute},
pages = {1582--1588},
title = {{Real-time navigation in classical platform games via skill reuse}},
year = {2017}
}
@article{Garrett2015,
abstract = {In this paper we address planning problems in high-dimensional hybrid configuration spaces, with a particular focus on manipulation planning problems involving many objects. We present the hybrid backward-forward (HBF) planning algorithm that uses a backward identification of constraints to direct the sampling of the infinite action space in a forward search from the initial state towards a goal configuration. The resulting planner is probabilistically complete and can effectively construct long manipulation plans requiring both prehensile and nonprehensile actions in cluttered environments.},
author = {Garrett, Caelan Reed and Lozano-P{\'{e}}rez, Tom{\'{a}}s and Kaelbling, Leslie Pack},
doi = {10.1109/IROS.2015.7354287},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Garrett, Lozano-P{\'{e}}rez, Kaelbling/2015/Backward-forward search for manipulation planning.pdf:pdf},
isbn = {9781479999941},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Heuristic algorithms,Intelligent robots,Ovens,Planning,Probabilistic logic,Search problems},
number = {grant 1420927},
pages = {6366--6373},
title = {{Backward-forward search for manipulation planning}},
volume = {2015-Decem},
year = {2015}
}
@article{Mousavi2014,
abstract = {Reinforcement learning (RL) for solving large and complex problems faces the curse of dimensions problem. To overcome this problem, frameworks based on the temporal abstraction have been presented; each having their advantages and disadvantages. This paper proposes a new method like the strategies introduced in the hierarchical abstract machines (HAMs) to create a high-level controller layer of reinforcement learning which uses options. The proposed framework considers a non-deterministic automata as a controller to make a more effective use of temporally extended actions and state space clustering. This method can be viewed as a bridge between option and HAM frameworks, which tries to suggest a new framework to decrease the disadvantage of both by creating connection structures between them and at the same time takes advantages of them. Experimental results on different test environments show significant efficiency of the proposed method.},
author = {Mousavi, Seyed Sajad and Ghazanfari, Behzad and Mozayani, Nasser and Jahed-Motlagh, Mohammad Reza},
doi = {10.1016/j.asoc.2014.08.071},
file = {::},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Cluster,Hierarchical reinforcement learning,Multi-agent learning,Reinforcement learning},
pages = {118--128},
publisher = {Elsevier B.V.},
title = {{Automatic abstraction controller in reinforcement learning agent via automata}},
url = {http://dx.doi.org/10.1016/j.asoc.2014.08.071},
volume = {25},
year = {2014}
}
@article{Panov2017a,
abstract = {Behavior planning is an important function of any complex technical facility intelligent control system. Presently, a symbol paradigm of artificial intelligence offers a variety of planning algorithms, including those that use precedent information, i.e. algorithms based on acquired knowledge. A symbol grounding problem within the exiting approaches of knowledge representation does not allow effective use the developed algorithms together with learning mechanisms for the purpose of solving a wide variety of applied problems by actual intelligent agents (robotics systems). This article presents the original planning algorithm (MAP Planner), which uses a sign world model as the basis for acquisition and maintenance of knowledge for future use in behavior planning. the sign problem approach describes planning as a cognitive function actualized by the world model of a subject of activity. Apart from solving symbol grounding problems and ensuring psychological and biological plausibility, a sign planning process model allows interaction of an intelligent agent with other participants in solving a cooperative task. The article presents the description of the knowledge representation method used, a MAP planning algorithm, and a model experiment in a “block world”.},
annote = {NULL},
author = {Panov, Aleksandr I.},
doi = {10.1016/j.bica.2016.12.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov/2017/Behavior Planning of Intelligent Agent with Sign World Model.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov/2017/Behavior Planning of Intelligent Agent with Sign World Model(2).pdf:pdf},
issn = {2212-683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {16-37-60055,behavior planning,causal matrix,elibrary,frccsc,hse,map algorithm,mypub,scopus,semiotic network,sign image,sign personal meaning,sign significance,sign world model,wos{\_}core},
mendeley-tags = {16-37-60055,elibrary,frccsc,hse,mypub,scopus,wos{\_}core},
pages = {21--31},
title = {{Behavior Planning of Intelligent Agent with Sign World Model}},
url = {http://www.sciencedirect.com/science/article/pii/S2212683X16300913},
volume = {19},
year = {2017}
}
@inproceedings{Shu2017,
abstract = {Learning policies for complex tasks that require multiple different skills is a major challenge in reinforcement learning (RL). It is also a requirement for its deployment in real-world scenarios. This paper proposes a novel framework for efficient multi-task reinforcement learning. Our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to learn a new skill. This enables agents to continually acquire new skills during different stages of training. Each learned task corresponds to a human language description. Because agents can only access previously learned skills through these descriptions, the agent can always provide a human-interpretable description of its choices. In order to help the agent learn the complex temporal dependencies necessary for the hierarchical policy, we provide it with a stochastic temporal grammar that modulates when to rely on previously learned skills and when to execute new skills. We validate our approach on Minecraft games designed to explicitly test the ability to reuse previously learned skills while simultaneously learning new skills.},
archivePrefix = {arXiv},
arxivId = {1712.07294},
author = {Shu, Tianmin and Xiong, Caiming and Socher, Richard},
booktitle = {Hierarchical RL Workshop, NIPS 2017},
doi = {10.1051/0004-6361/201527329},
eprint = {1712.07294},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Shu, Xiong, Socher/2017/Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning.pdf:pdf},
isbn = {2004012439},
issn = {0004-6361},
pmid = {23459267},
title = {{Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning}},
url = {http://arxiv.org/abs/1712.07294},
year = {2017}
}
@incollection{Hoek2007,
author = {van der Hoek, Wiebe and Wooldridge, Michael},
booktitle = {Handbook of Knowledge Representation},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hoek, Wooldridge/2007/Multi-Agent Systems.pdf:pdf},
pages = {1--44},
title = {{Multi-Agent Systems}},
year = {2007}
}
@misc{Presentation2016b,
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2016/Теория когнитома Анохина.pdf:pdf},
pages = {23},
title = {{Теория когнитома Анохина}},
year = {2016}
}
@article{Dayan1993,
abstract = {One way to speed up reinforcement learning is to enable learning to happen simultaneously at multiple resolutions in space and time. This paper shows how to create a Q-learning managerial hierarchy in which high level managers learn how to set tasks to their sub-managers who, in turn, learn how to satisfy them. Sub-managers need not initially understand their managers' commands. They simply learn to maximise their reinforcement in the context of the current command. We illustrate the system using a simple maze task.. As the system learns how to get around, satisfying commands at the multiple levels, it explores more efficiently than standard, flat, Q-learning and builds a more comprehensive map.},
author = {Dayan, Peter and Hinton, Geoffrey},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dayan, Hinton/1993/Feudal Reinforcement Learning.pdf:pdf},
isbn = {1-55860-274-7},
issn = {1049-5258},
journal = {Advances in neural information processing systems},
keywords = {Reinforcement Learning},
pages = {271--278},
title = {{Feudal Reinforcement Learning}},
url = {http://www.cs.utoronto.ca/{~}hinton/absps/dh93.pdf},
year = {1993}
}
@article{Botvinick2009a,
abstract = {Research on human and animal behavior has long emphasized its hierarchical structure-the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
doi = {10.1016/j.cognition.2008.08.011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Botvinick, Niv, Barto/2009/Hierarchically organized behavior and its neural foundations a reinforcement learning perspective.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Animals,Humans,Models,Nerve Net,Nerve Net: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Problem Solving,Problem Solving: physiology,Psychological,Reinforcement (Psychology)},
number = {3},
pages = {262--80},
pmid = {18926527},
title = {{Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2783353{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {113},
year = {2009}
}
@incollection{Hengst2012,
abstract = {Hierarchical decomposition tackles complex problems by reducing them to a smaller set of interrelated problems. The smaller problems are solved separately and the results re-combined to find a solution to the original problem. It is well known that the na{\"{i}}ve application of reinforcement learning (RL) techniques fails to scale to more complex domains. This Chapter introduces hierarchical approaches to reinforcement learning that hold out the promise of reducing a reinforcement learning problems to a manageable size. Hierarchical Reinforcement Learning (HRL) rests on finding good re-usable temporally extended actions that may also provide opportunities for state abstraction. Methods for reinforcement learning can be extended to work with abstract states and actions over a hierarchy of subtasks that decompose the original problem, potentially reducing its computational complexity. We use a four-room task as a running example to illustrate the various concepts and approaches, including algorithms that can automatically learn the hierarchical structure from interactions with the domain.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.02971},
author = {Hengst, Bernhard},
booktitle = {Reinforcement Learning},
doi = {10.1007/978-3-642-27645-3_9},
eprint = {arXiv:1509.02971},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hengst/2012/Hierarchical Approaches.pdf:pdf},
isbn = {978-3-642-27644-6},
issn = {18726240},
pages = {293--323},
title = {{Hierarchical Approaches}},
url = {http://dx.doi.org/10.1007/978-3-642-27645-3{\_}9 http://link.springer.com/10.1007/978-3-642-27645-3{\_}9},
year = {2012}
}
@inproceedings{Alexander2016,
abstract = {We present a novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting. The network builds an internal plan, which is continuously updated upon observation of the next input from the environment. It can also partition this internal representation into contiguous sub- sequences by learning for how long the plan can be committed to - i.e. followed without re-planing. Combining these properties, the proposed model, dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally abstracted macro- actions of varying lengths that are solely learnt from data without any prior information. These macro-actions enable both structured exploration and economic computation. We experimentally demonstrate that STRAW delivers strong improvements on several ATARI games by employing temporally extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same time a general algorithm that can be applied on any sequence data. To that end, we also show that when trained on text prediction task, STRAW naturally predicts frequent n-grams (instead of macro-actions), demonstrating the generality of the approach.},
archivePrefix = {arXiv},
arxivId = {1606.04695},
author = {Vezhnevets, Alexander and Mnih, Volodymyr and Agapiou, John and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Kavukcuoglu, Koray},
booktitle = {Proceeding of NIPS 2016},
doi = {10.3847/0004-637X/832/1/56},
eprint = {1606.04695},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Alexander et al/2016/Strategic Attentive Writer for Learning Macro-Actions.pdf:pdf},
issn = {10495258},
title = {{Strategic Attentive Writer for Learning Macro-Actions}},
url = {http://arxiv.org/abs/1606.04695},
year = {2016}
}
@article{Erdem2014,
abstract = {We propose an extended version of our previous goal directed navigation model based on forward planning of trajectories in a network of head direction cells, persistent spiking cells, grid cells, and place cells. In our original work the animat incrementally creates a place cell map by random exploration of a novel environment. After the exploration phase, the animat decides on its next movement direction towards a goal by probing linear look-ahead trajectories in several candidate directions while stationary and picking the one activating place cells representing the goal location. In this work we present several improvements over our previous model. We improve the range of linear look-ahead probes significantly by imposing a hierarchical structure on the place cell map consistent with the experimental findings of differences in the firing field size and spacing of grid cells recorded at different positions along the dorsal to ventral axis of entorhinal cortex. The new model represents the environment at different scales by populations of simulated hippocampal place cells with different firing field sizes. Among other advantages this model allows simultaneous constant duration linear look-ahead probes at different scales while significantly extending each probe range. The extension of the linear look-ahead probe range while keeping its duration constant also limits the degrading effects of noise accumulation in the network. We show the extended model's performance using an animat in a large open field environment. {\textcopyright} 2013 Elsevier Ltd.},
author = {Erdem, Uǧur M. and Hasselmo, Michael E.},
doi = {10.1016/j.jphysparis.2013.07.002},
file = {::},
isbn = {1769-7115 (Electronic)$\backslash$r0928-4257 (Linking)},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Entorhinal cortex,Grid cell,Hippocampus,Navigation,Place cell},
number = {1},
pages = {28--37},
pmid = {23891644},
title = {{A biologically inspired hierarchical goal directed navigation model}},
volume = {108},
year = {2014}
}
@article{Fernandes2013,
author = {Fernandes, J F Ribas},
file = {::},
number = {November},
title = {{Hierarchical reinforcement learning in behavior and the brain}},
year = {2013}
}
@article{Pellom2001,
author = {Pellom, B. and Ward, W. and Hansen, J. and Cole, R. and Hacioglu, K. and Zhang, J. and Yu, X. and Pradhan, S.},
doi = {10.3115/1072133.1072225},
journal = {Proceedings of the first international conference on Human language technology research - HLT '01},
pages = {1--6},
title = {{University of Colorado dialog systems for travel and navigation}},
url = {http://portal.acm.org/citation.cfm?doid=1072133.1072225},
year = {2001}
}
@inproceedings{Mannor2004,
abstract = {We consider a graph theoretic approach for automatic construction of options in a dynamic environment. A map of the environment is generated on-line by the learning agent, representing the topological structure of the state transitions. A clustering algorithm is then used to partition the state space to different regions. Policies for reaching the different parts of the space are separately learned and added to the model in a form of options (macro-actions). The options are used for accelerating the Q-Learning algorithm. We extend the basic algorithm and consider building a map that includes preliminary indication of the location of "interesting" regions of the state space, where the value gradient is significant and additional exploration might be beneficial. Experiments indicate significant speedups, especially in the initial learning phase.},
address = {New York, New York, USA},
author = {Mannor, Shie and Menache, Ishai and Hoze, Amit and Klein, Uri},
booktitle = {Twenty-first international conference on Machine learning - ICML '04},
doi = {10.1145/1015330.1015355},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mannor et al/2004/Dynamic abstraction in reinforcement learning via clustering.pdf:pdf},
isbn = {1581138285},
keywords = {clustering,hierarchical reinforcement learning,options,q-learning,reinforcement learning},
pages = {71},
publisher = {ACM Press},
title = {{Dynamic abstraction in reinforcement learning via clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015355},
year = {2004}
}
@inproceedings{Panov2010b,
abstract = {В данной работе предлагается новая методика выявления причинно-следственных связей в психологических данных, получаемых при проведении тестирования. Используется сочетание методов статистической обработки и методов машинного обучения, в частности ДСМ-метода и метода AQ покрытий. Предлагаются способы дополнительного анализа и визуализации полученных гипотез о причинно-следственных связях.},
address = {Рыбинск},
author = {Панов, А. И.},
booktitle = {Теория и практика системного анализа: Труды I Всероссийской научной конференции молодых учёных},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2010/Методика интеллектуального анализа результатов психологического тестирования.pdf:pdf},
keywords = {myconf},
language = {russian},
mendeley-tags = {myconf},
pages = {39--45},
publisher = {РГАТА имени П.А. Соловьева},
title = {{Методика интеллектуального анализа результатов психологического тестирования}},
volume = {I},
year = {2010}
}
@article{Daniel2010,
abstract = {jetyak; path planning; theta*},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.3843},
author = {Daniel, Kenny and Nash, Alex and Koenig, Sven and Felner, Ariel},
doi = {10.1613/jair.2994},
eprint = {arXiv:1401.3843},
file = {::},
isbn = {1577353234},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {533--579},
title = {{Theta*: Any-angle path planning on grids}},
volume = {39},
year = {2010}
}
@article{Granatyr2015,
abstract = {Finding reliable partners to interact with in open environments is a challenging task for software agents, and trust and reputation mechanisms are used to handle this issue. From this viewpoint, we can observe the growing body of research on this subject, which indicates that these mechanisms can be considered key elements to design multiagent systems (MASs). Based on that, this article presents an extensive but not exhaustive review about the most significant trust and reputation models published over the past two decades, and hundreds of models were analyzed using two perspectives. The first one is a combination of trust dimensions and principles proposed by some relevant authors in the field, and the models are discussed using an MAS perspective. The second one is the discussion of these dimensions taking into account some types of interaction found in MASs, such as coalition, argumentation, negotiation, and recommendation. By these analyses, we aim to find significant relations between trust dimensions and types of interaction so it would be possible to construct MASs using the most relevant dimensions according to the types of interaction, which may help developers in the design of MASs. es, and Fabr{\'{i}}cio Enembreck. 2015. Trust and reputation models for multiagent systems. ACM Comput. Surv. 48, 2, Article 27 (October 2015), 42 pages.},
author = {Granatyr, Jones and Botelho, Vanderson and Lessing, Otto Robert and Scalabrin, Edson Em{\'{i}}lio and Barth{\`{e}}s, Jean-Paul and Enembreck, Fabr{\'{i}}cio},
doi = {10.1145/2816826},
file = {::},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {oct},
number = {2},
pages = {1--42},
title = {{Trust and Reputation Models for Multiagent Systems}},
url = {http://dl.acm.org/citation.cfm?doid=2830539.2816826},
volume = {48},
year = {2015}
}
@incollection{Panov2016c,
abstract = {In this paper we outline the approach of solving special type of navigation tasks for robotic systems, when a coalition of robots (agents) acts in the 2D environment, which can be modified by the actions, and share the same goal location. The latter is originally unreachable for some members of the coalition, but the common task still can be accomplished as the agents can assist each other (e.g. by modifying the environment). We call such tasks smart relocation tasks (as the can not be solved by pure path planning methods) and study spatial and behavior interaction of robots while solving them. We use cognitive approach and introduce semiotic knowledge representation — sign world model which underlines behavioral planning methodology. Planning is viewed as a recursive search process in the hierarchical state-space induced by sings with path planning signs reside on the lowest level. Reaching this level triggers path planning which is accomplished by state of the art grid-based planners focused on producing smooth paths (e.g. LIAN) and thus indirectly guarantying feasibility of that paths against agent's dynamic constraints.},
author = {Panov, Aleksandr I. and Yakovlev, Konstantin},
booktitle = {Robot Intelligence Technology and Applications 4},
doi = {10.1007/978-3-319-31293-4_1},
editor = {Kim, Jong-Hwan and Karray, Fakhri and Jo, Jun and Sincak, Peter and Myung, Hyun},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov, Yakovlev/2016/Behavior and Path Planning for the Coalition of Cognitive Robots in Smart Relocation Tasks.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov, Yakovlev/2016/Behavior and Path Planning for the Coalition of Cognitive Robots in Smart Relocation Tasks.pdf:pdf},
keywords = {14-07-31194,15-37-20893,behavior planning,coalition,elibrary,knowledge representation,lian,myconf,path planning,scopus,semiotic model,sign world model,task planning,wos{\_}core},
mendeley-tags = {14-07-31194,15-37-20893,elibrary,myconf,scopus,wos{\_}core},
pages = {3--20},
publisher = {Springer International Publishing},
series = {Advances in Intelligent Systems and Computing},
title = {{Behavior and Path Planning for the Coalition of Cognitive Robots in Smart Relocation Tasks}},
url = {http://link.springer.com/10.1007/978-3-319-31293-4{\_}1},
year = {2016}
}
@article{Osipov2017a,
abstract = {В соответствии с современными взглядами на возникновение психических функций и на роль в этом нейрофизиологических процессов, формирование психических функций связывается с существованием или синтезом в процессе коммуникации специальных информационных структур, содержащих три различных по происхождению вида информации: информации, поступающей из внешней среды, информации, извлекаемой из памяти, и информации, приходящей из центров мотивации. Связывание таких компонент в единое целое обеспечивается их именованием; оно же обеспечивает устойчивость возникающих структур. Такие информационные структуры были названы нами знаками ввиду их сходства с аналогичными структурами, изучаемыми в семиотике. Множество знаков, формируемых субъектом в процессе деятельности и коммуникации, образует его знаковую картину мира, отражающую его представления о внешней среде, о себе и о других субъектах.Знаковая картина мира позволяет поставить и решить ряд задач, возникающих при моделировании поведения интеллектуальных агентов и их коалиций, таких как задачи целеполагания, синтеза целенаправленного поведения, распределения ролей и взаимодействия агентов в коалиции. В работе рассматривается специальный объект - каузальная матрица, с помощью которой описывается строение компонент знака. На этой основе определяются операции и отношения в знаковой картине мира, моделирующие психологические особенности поведения человека.},
author = {Осипов, Г. С. and Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов/2017/Отношения и операции в знаковой картине мира субъекта поведения.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов/2017/Отношения и операции в знаковой картине мира субъекта поведения(2).pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {15-37-20893,16-37-60055,frccsc,mypub},
language = {russian},
mendeley-tags = {15-37-20893,16-37-60055,frccsc,mypub},
number = {4},
pages = {5--22},
title = {{Отношения и операции в знаковой картине мира субъекта поведения}},
url = {http://aidt.ru/index.php?option=com{\_}content{\&}view=article{\&}id=775:g-s-osipov-a-i-panov-otnosheniya-i-operatsii-v-znakovoj-kartine-mira-sub-ekta-povedeniya{\&}catid=321:kognitivnoe-modelirovanie{\&}Itemid=200{\&}lang=ru},
year = {2017}
}
@inproceedings{Roderick2017,
abstract = {We examine the problem of learning and planning on high-dimensional domains with long horizons and sparse rewards. Recent approaches have shown great successes in many Atari 2600 domains. However, domains with long horizons and sparse rewards, such as Montezuma's Revenge and Venture, remain challenging for existing methods. Methods using abstraction (Dietterich 2000; Sutton, Precup, and Singh 1999) have shown to be useful in tackling long-horizon problems. We combine recent techniques of deep reinforcement learning with existing model-based approaches using an expert-provided state abstraction. We construct toy domains that elucidate the problem of long horizons, sparse rewards and high-dimensional inputs, and show that our algorithm significantly outperforms previous methods on these domains. Our abstraction-based approach outperforms Deep Q-Networks (Mnih et al. 2015) on Montezuma's Revenge and Venture, and exhibits backtracking behavior that is absent from previous methods.},
archivePrefix = {arXiv},
arxivId = {1710.00459},
author = {Roderick, Melrose and Grimm, Christopher and Tellex, Stefanie},
booktitle = {Hierarchical RL Workshop, NIPS 2017},
eprint = {1710.00459},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Roderick, Grimm, Tellex/2017/Deep Abstract Q-Networks.pdf:pdf},
title = {{Deep Abstract Q-Networks}},
url = {http://arxiv.org/abs/1710.00459},
year = {2017}
}
@incollection{Menache2002,
abstract = {We present the Q-Cut algorithm, a graph theoretic approach for automatic detection of sub-goals in a dynamic environment, which is used for acceleration of the Q-Learning algorithm. The learning agent creates an on-line map of the process history, and uses an efficient Max-Flow/Min-Cut algorithm for identifying bottlenecks. The policies for reaching bottlenecks are separately learned and added to the model in a form of options (macro-actions). We then extend the basic Q-Cut algorithm to the Segmented Q-Cut algorithm, which uses previously identified bottlenecks for state space partitioning, necessary for finding additional bottlenecks in complex environments. Experiments show significant performance improvements, particulary in the initial learning phase.},
author = {Menache, Ishai and Mannor, Shie and Shimkin, Nahum},
booktitle = {ECML 2002: Machine Learning: ECML 2002},
doi = {10.1007/3-540-36755-1_25},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Menache, Mannor, Shimkin/2002/Q-Cut—Dynamic Discovery of Sub-goals in Reinforcement Learning.pdf:pdf},
isbn = {978-3-540-44036-9, 978-3-540-36755-0},
issn = {16113349},
pages = {295--306},
title = {{Q-Cut—Dynamic Discovery of Sub-goals in Reinforcement Learning}},
url = {http://link.springer.com/10.1007/3-540-36755-1{\_}25},
year = {2002}
}
@article{Madl2018,
abstract = {Computational cognitive models of spatial memory often neglect difficulties posed by the real world, such as sensory noise, uncertainty, and high spatial complexity. On the other hand, robotics is unconcerned with understanding biological cognition. Here, we describe a computational framework for robotic architectures aiming to function in realistic environments, as well as to be cognitively plausible. We motivate and describe several mechanisms towards achieving this despite the sensory noise and spatial complexity inherent in the physical world. We tackle error accumulation during path integration by means of Bayesian localization, and loop closing with sequential gradient descent. Finally, we outline a method for structuring spatial representations using metric learning and clustering. Crucially, unlike the algorithms of traditional robotics, we show that these mechanisms can be implemented in neuronal or cognitive models. We briefly outline a concrete implementation of the proposed framework as part of the LIDA cognitive architecture, and argue that this kind of probabilistic framework is well-suited for use in cognitive robotic architectures aiming to combine spatial functionality and psychological plausibility.},
author = {Madl, Tamas and Franklin, Stan and Chen, Ke and Trappl, Robert},
doi = {10.1016/j.cogsys.2017.08.002},
file = {::},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Bayesian brain,Cognitive architecture,Computational cognitive modeling,LIDA,Spatial memory},
pages = {147--172},
publisher = {Elsevier B.V.},
title = {{A computational cognitive framework of spatial memory in brains and robots}},
url = {https://doi.org/10.1016/j.cogsys.2017.08.002},
volume = {47},
year = {2018}
}
@article{DeCarolis2001,
abstract = {The aim of our research is to build a Reflexive Agent, that is able to either manifest an emotion it is feeling or to hide it. If the Agent decides to manifest its emotion, it can establish what verbal or nonverbal signals to employ communication in its and how to combine and synchronize them. In the decision of whether to express an emotion in a given context, a number of factors are considered, such as the Agent's own personality and goals, the Interlocutor's characteristics and the context. In planning how to communicate an emotion, various factors are considered as well: the available modalities (face, gaze, voice etc); the cognitive ease in producing and processing the various the expressiveness of every signal in communicating specific meanings; and, finally, the appropriateness of signals to social situations.},
author = {{De Carolis}, Berardina and Pelachaud, Catherine and Poggi, Isabella and {De Rosis}, Fiorella},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/De Carolis et al/2001/Behavior planning for a reflexive agent.pdf:pdf},
isbn = {1-55860-812-5, 978-1-558-60812-2},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1059--1064},
title = {{Behavior planning for a reflexive agent}},
year = {2001}
}
@article{Gupta2017,
abstract = {We introduce a neural architecture for navigation in novel environments. Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment. The Cognitive Mapper and Planner (CMP) is based on two key ideas: a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the planner, and b) a spatial memory with the ability to plan given an incomplete set of observations about the world. CMP constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step. The accumulated belief of the world enables the agent to track visited regions of the environment. Our experiments demonstrate that CMP outperforms both reactive strategies and standard memory-based architectures and performs well in novel environments. Furthermore, we show that CMP can also achieve semantically specified goals, such as "go to a chair".},
archivePrefix = {arXiv},
arxivId = {1702.03920},
author = {Gupta, Saurabh and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
eprint = {1702.03920},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gupta et al/2017/Cognitive Mapping and Planning for Visual Navigation.pdf:pdf},
journal = {ArXiv: 1702.03920},
month = {feb},
title = {{Cognitive Mapping and Planning for Visual Navigation}},
url = {http://arxiv.org/abs/1702.03920},
year = {2017}
}
@misc{Presentation2016b,
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2016/Биологически и психологически правдоподобные методы моделирования в искусственном интеллекте.pdf:pdf},
pages = {19},
title = {{Биологически и психологически правдоподобные методы моделирования в искусственном интеллекте}},
year = {2016}
}
@article{Panov2018a,
abstract = {В работе рассматривается знаковый подход к проблеме моделирования процесса целеполагания и его интеграции с методами синтеза плана поведения. На основе психологически правдоподобной модели знаковой картины мира когнитивного агента предложен алгоритм GoalMAP, который на основе формальной сетевой модели реализует итеративный процесс иерархического планирования с выделенным этапом постановки или выбора новой цели. Рассмотрена оценка сложности алгоритма планирования поведения, проведены модельные эксперименты с программной реализацией построенных алгоритмов, демонстрирующей ключевые особенности используемого подхода.},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2018/Целеполагание и синтез плана поведения когнитивным агентом.docx:docx},
journal = {Искусственный интеллект и принятие решений},
keywords = {16-37-60055,17-07-00281,GoalMAP,frccsc,mypub,vak,знак,знаковая картина мира,когнитивный агент,культурно-исторический подход,планирование,планирование поведения,теория деятельности,целеполагание},
language = {russian},
mendeley-tags = {16-37-60055,17-07-00281,frccsc,mypub,vak},
number = {2},
pages = {(В печати)},
title = {{Целеполагание и синтез плана поведения когнитивным агентом}},
year = {2018}
}
@book{Hadad2013,
author = {Hadad, Meirav and Kraus, Sarit and {Ben-Arroyo Hartman}, Irith and Rosenfeld, Avi},
booktitle = {Annals of Mathematics and Artificial Intelligence},
doi = {10.1007/s10472-013-9363-9},
file = {::},
isbn = {1047201393639},
issn = {10122443},
keywords = {Artificial intelligence,Cooperation,Coordination,Multiagent system,Planning,Time constraints},
number = {3},
pages = {243--291},
title = {{Group planning with time constraints}},
volume = {69},
year = {2013}
}
@article{Hexmoor2006,
abstract = {Agent teaming and autonomy are foundational themes in multi-agent systems. Agents may work as singletons or they may work in environments where other agents exist. In multi-agent systems, agents may form teams by sharing common goals with other agents. Cooperation is essential for any collaborative, group activity. Beyond coordination and judicious role assignment, cooperation enables members of a team to be aware and account for collection of their goals as well as the performance of agents on individual goals. This paper presents a general model of cooperation and illustrates how it may enhance group performance. In this paper, we present results of an application of the concept of cooperation in a simulated swarm of reconnaissance urban UAVs that are tracking vehicles in an urban environment.},
author = {Hexmoor, Henry and Eluru, Swetha and Sabaa, Hadi},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hexmoor, Eluru, Sabaa/2006/Plan sharing Showcasing coordinated UAV formation flight.pdf:pdf},
issn = {03505596},
journal = {Informatica (Ljubljana)},
keywords = {Agents,Benevolence,Collaboration,Help,UAV},
number = {2},
pages = {183--192},
title = {{Plan sharing: Showcasing coordinated UAV formation flight}},
volume = {30},
year = {2006}
}
@article{Branting2004,
abstract = {Two key objectives of conversational case-based reasoning (CCBR) systems are (1) eliciting case facts in a manner that minimizes the user's burden in terms of resources such as time, information cost, and cognitive load, and (2) integrating CBR with other problem solving modalities. This paper proposes an architecture that addresses both these goals by integrating CBR with a discourse-oriented dialogue engine. The dialogue engine determines when CBR or other problem-solving tech- niques are needed to achieve pending discourse goals. Conversely, the CBR component has the full resources of a dialogue engine to handle topic changes, interruptions, clarification questions by either the user or the system, and other speech acts that arise in problem-solving dialogues. 1},
author = {Branting, Karl and Lester, James and Mott, Bradford},
doi = {10.1007/978-3-540-28631-8_7},
isbn = {3-540-22882-9},
issn = {03029743},
journal = {Advances in Case-Based Reasoning},
title = {{Dialogue management for conversational case-based reasoning}},
url = {http://www.springerlink.com/index/e5369pe8c4yref2g.pdf},
year = {2004}
}
@article{Vig2007,
author = {Vig, Lovekesh and Adams, Julie a.},
doi = {10.1007/s10846-007-9150-0},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vig, Adams/2007/Coalition Formation From Software Agents to Robots.pdf:pdf},
issn = {0921-0296},
journal = {Journal of Intelligent and Robotic Systems},
number = {1},
pages = {85--118},
title = {{Coalition Formation: From Software Agents to Robots}},
url = {http://link.springer.com/10.1007/s10846-007-9150-0},
volume = {50},
year = {2007}
}
@article{Panov2015e,
abstract = {В работе рассмотрен ряд вопросов, возникающих в области автоматизации управления малыми беспилотными летательными аппаратами (БПЛА) мультироторного типа. Предложена совокупность методов планирования и управления, рассмотрена задача организации взаимодействия различных методов и алгоритмов (авторских и известных) в единую интеллектуальную систему управления БПЛА. Предлагается использование трех уровней управления – стратегического, тактического и реактивного, описывается соответствующая архитектура – STRL (от англ. strategic, tactical, reactive, layered). Использование этой архитектуры позволит автоматизировать управление коалициями БПЛА при решении широкого круга задач в различных средах.},
author = {Макаров, Д. А. and Панов, А. И. and Яковлев, К. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.doc:doc;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {14-11-00692,elibrary,mypub,vak,беспилотные летательные аппараты,знаковая картина мира,интеллектуальная система управления,многоуровневая архитектура,нелинейное управление,планирование траектории,уравнение Риккати},
language = {russian},
mendeley-tags = {14-11-00692,elibrary,mypub,vak},
number = {3},
pages = {18--33},
title = {{Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами}},
year = {2015}
}
@article{Botvinick2009a,
abstract = {Research on human and animal behavior has long emphasized its hierarchical structure-the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
doi = {10.1016/j.cognition.2008.08.011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Botvinick, Niv, Barto/2009/Hierarchically organized behavior and its neural foundations a reinforcement learning perspective.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Animals,Humans,Models,Nerve Net,Nerve Net: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Problem Solving,Problem Solving: physiology,Psychological,Reinforcement (Psychology)},
number = {3},
pages = {262--80},
pmid = {18926527},
title = {{Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2783353{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {113},
year = {2009}
}
@article{Chai2001,
abstract = {This paper describes a web-based dialog system – Natural Language Sales Assistant (NLSA) – that helps users find relevant information about products and services in e-commerce sites. The system leverages technologies in natural language processing and human computer interaction to create a faster and more intuitive way of interacting with websites. By combining traditional AI rule-based technology with taxonomy mapping, the system is able to accommodate both customer and business requirements. Our user studies have demonstrated that, in the context of e-commerce, users preferred the natural language enabled navigation over menu-driven navigation (79{\%} to 21{\%} users). In addition, compared to a menu driven system, the average number of clicks used in the natural language system was reduced by 63.2{\%} and the average time was reduced by 33.3{\%}. The NLSA system is currently deployed by IBM as a live pilot and we are collecting real user feedback. We believe that conversational interfaces like that of NLSA offer the ultimate personalization and can greatly enhance the user experience for websites.},
author = {Chai, Joyce Yue and Budzikowska, Malgorzata and Horvath, Veronika and Nicolov, Nicolas and Kambhatla, Nanda and Zadrozny, Wlodek and Stys, Margo and Kambhatla, Nanda and Zadrozny, Wlodek and Melville, Prem},
doi = {10.1145/345124.345164},
journal = {Iaai},
keywords = {engines usually require that,however,indexing,jargon so that the,keyword,keyword search,keywords could possibly match,product catalog or documents,search capabilities,terms used in the,users know domain specific},
number = {2},
pages = {19--26},
title = {{Natural Language Sales Assistant-A Web-Based Dialog System for Online Sales.}},
volume = {23},
year = {2001}
}
@article{Zubarev2013,
abstract = {В статье рассматриваются и анализируются различные подходы к построению архитектуры системы управления беспилотным летательным аппаратом типа «вертолет». На основании проведенного анализа делается вывод о целесообразности применения иерархической, трехуровневой схемы – стратегический уровень, тактический уровень, уровень управления. Описываются решаемые на каждом уровне задачи и дается краткая характеристика методов, подходов и алгоритмов, потенциально применимых для их решения, выделяются наиболее перспективные на взгляд авторов методы и подходы.},
author = {Зубарев, Д. В. and Макаров, Д. А. and Панов, А. И. and Яковлев, К. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Зубарев et al/2013/Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Зубарев et al/2013/Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами.docx:docx},
journal = {Авиакосмическое приборостроение},
keywords = {12-07-00611,12-07-31057,12-07-31058,elibrary,mypub,алгоритмы управления,архитектура системы управления,беспилотные летательные аппараты,вертолеты,когнитивное компьютерное моделирование,методы планирования траекторий,регуляторы},
language = {russian},
mendeley-tags = {12-07-00611,12-07-31057,12-07-31058,elibrary,mypub},
number = {4},
pages = {10--28},
title = {{Принципы построения многоуровневых архитектур систем управления беспилотными летательными аппаратами}},
year = {2013}
}
@article{2017,
abstract = {Системы комического наблюдения являются важным источником информации, необ- ходимой для оперативного решения широкого круга задач гражданского и военного назначе- ния. Эффективность функционирования таких систем зависит от многих факторов. Наряду с множеством технических, информационных, технологических, инфраструктурных, эконо- мических и других факторов, их эффективность в значительной степени зависит от качест- ва планирования миссий космических аппаратов и управления в реальном времени процессом исполнения миссии. В работе сформулирована проблема построения самоорганизующейся системы группового управления поведением кластера малых спутников, реализующего авто- номное исполнение заявок на сервис по добыванию информации о наземных объектах средст- вами космического наблюдения. В ней предлагается новая концепция группового управления в системе космического наблюдения. В основу этой концепции положен принцип самоорганиза- ции группового поведения кластера спутников. Такая система управления оказывается в со- стоянии реализовать автономное планирование и оперативное управления космической груп- пировкой, в которой все базовые функции процесса управления реализуются ее бортовыми средствами. Теоретический фундамент этой концепции строится на моделях коллективной робототехники, которые в настоящее время активно развиваются в области многоагент- ных систем. В работе приведен краткий обзор современного состояния исследований в об- ласти систем управления кластерами малых спутников, дана достаточно общая постановка задачи, в которой кластер малых спутников рассматривается как полностью автономная система, предназначенная для выполнения заказов на сбор и доставку космической информа- ции о наземных объектах. При этом полагается, что система управления самостоятельно в реальном времени распределяет задачи наблюдения на множестве спутников группировки, планирует и составляет расписание выполнения наблюдений в соответствии с пространст- венно-временными требованиями заказчика, выполняет оперативное управление распреде- ленным исполнением построенного расписания и выполняет коррекцию распределения задач и расписания их выполнения при возникновении нештатных ситуаций. В работе дано деталь- ное описание разработанной концепции самоорганизующейся системы группового управления кластером малых спутников, и архитектуры ее программной реализации.},
author = {Городецкий, В. И. and Карасев, О. В.},
doi = {10.18522/2311-3103-2017-1-234247},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Городецкий, Карасев/2017/Самоорганизация группового поведения кластера малых спутников распределенной системы наблюдения.pdf:pdf},
issn = {23113103},
journal = {Известия ЮФУ. Технические науки},
keywords = {Малый спутник,автономная миссия,блюдения,динамическая коммуникационная сеть.,задача наблюдения,коллективное поведение,парное взаимо- действие спутников,распределенная система на-,ресурсы спутника,самоорганизация},
language = {russian},
month = {jan},
number = {2},
pages = {234--247},
title = {{Самоорганизация группового поведения кластера малых спутников распределенной системы наблюдения}},
url = {http://izv-tn.tti.sfedu.ru/wp-content/uploads/2017/1/19.pdf},
volume = {187},
year = {2017}
}
@article{M.Garcia-Serrano2002,
author = {{M. Garc{\'{i}}a-Serrano}, Ana and Rodrigo-Aguado, Luis and Javier, Calle},
journal = {Proceedings of the Third International Conference on Language Resources and Evaluation (LREC'02)},
number = {January 2002},
title = {{Natural Language Dialogue in a Virtual Assistant Interface.}},
url = {http://aclweb.org/anthology/L02-1253},
year = {2002}
}
@inproceedings{Jonsson2001,
abstract = {Learning a complex task can be significantly facilitated by defining a hierarchy of subtasks. An agent can learn to choose between various temporally abstract actions, each solving an assigned subtask, to accomplish the overall task. In this paper, we study hierarchical learning using the framework of options. We argue that to take full advantage of hierarchical structure, one should perform option-specific state abstraction, and that if this is to scale to larger tasks, state abstraction ...},
author = {Jonsson, Anders and Barto, Andrew G.},
booktitle = {Proceedings of NIPS 2001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Jonsson, Barto/2001/Automated State Abstraction for Options using the U-Tree Algorithm.pdf:pdf},
isbn = {0262122413},
issn = {1049-5258},
pages = {1054--1060},
title = {{Automated State Abstraction for Options using the U-Tree Algorithm}},
year = {2001}
}
@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George, Hawkins/2009/Towards a mathematical theory of cortical micro-circuits.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Markov Chains,Memory,Memory: physiology,Models,Neurological,Pattern Recognition,Pyramidal Cells,Pyramidal Cells: physiology},
number = {10},
pages = {e1000532},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2749218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Milford2010,
abstract = {The challenge of persistent navigation and mapping is to develop an autonomous robot system that can simultaneously localize, map and navigate over the lifetime of the robot with little or no human intervention. Most solutions to the simultaneous localization and mapping (SLAM) problem aim to produce highly accurate maps of areas that are assumed to be static. In contrast, solutions for persistent navigation and mapping must produce reliable goal-directed navigation outcomes in an environment that is assumed to be in constant flux. We investigate the persistent navigation and mapping problem in the context of an autonomous robot that performs mock deliveries in a working office environment over a two-week period. The solution was based on the biologically inspired visual SLAM system, RatSLAM. RatSLAM performed SLAM continuously while interacting with global and local navigation systems, and a task selection module that selected between exploration, delivery, and recharging modes. The robot performed 1,143 delivery tasks to 11 different locations with only one delivery failure (from which it recovered), traveled a total distance of more than 40 km over 37 hours of active operation, and recharged autonomously a total of 23 times.},
author = {Milford, Michael and Wyeth, Gordon},
doi = {10.1177/0278364909340592},
file = {::},
isbn = {0278-3649},
issn = {02783649},
journal = {International Journal of Robotics Research},
keywords = {RatSLAM,SLAM,biologically inspired,persistent navigation and mapping},
number = {9},
pages = {1131--1153},
title = {{Persistent navigation and mapping using a biologically inspired slam system}},
volume = {29},
year = {2010}
}
@article{Hiraoka2017,
author = {Hiraoka, Takuya and Neubig, Graham and Yoshino, Koichiro and Toda, Tomoki and Nakamura, Satoshi},
doi = {10.1007/978-981-10-2585-3_5},
isbn = {9789811025846},
issn = {18761119},
journal = {Lecture Notes in Electrical Engineering},
keywords = {Active learning,Dialog management,Example-based dialog},
pages = {67--78},
title = {{Active learning for example-based dialog systems}},
volume = {999 LNEE},
year = {2017}
}
@article{Bonnet2015,
author = {Bonnet, Jonathan and Gleizes, Marie Pierre and Kaddoum, Elsy and Rainjonneau, Serge and Flandin, Gregory},
doi = {10.1109/SASO.2015.9},
file = {::},
isbn = {9781467375351},
issn = {19493681},
journal = {International Conference on Self-Adaptive and Self-Organizing Systems, SASO},
keywords = {adaptive multi-agent system,multisatellite,planning},
pages = {11--20},
title = {{Multi-satellite Mission Planning Using a Self-Adaptive Multi-agent System}},
volume = {2015-Octob},
year = {2015}
}
@article{Barto2003,
abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of {\{}semi-Markov{\}} decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
author = {Barto, Andrew G. and Mahadevan, Sridhar},
doi = {10.1023/A:1025696116075},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Barto, Mahadevan/2003/Recent Advances in Hierarchical Reinforcement Learning.pdf:pdf},
isbn = {0924-6703},
issn = {09246703},
journal = {Discrete Event Dynamic Systems},
pages = {341--379},
title = {{Recent Advances in Hierarchical Reinforcement Learning}},
url = {http://dx.doi.org/10.1023/A:1025696116075},
volume = {13},
year = {2003}
}
@incollection{Castro2012,
abstract = {Abstract. Temporally extended actions are usually effective in speeding up reinforcement learning. In this paper we present a mechanism for automatically constructing such actions, expressed as options [Sutton et al., 1999], in a finite Markov Decision Process (MDP). To do this, we compute a bisimulation metric [Ferns et al., 2004] between the states in a small MDP and the states in a large MDP, which we want to solve. The shape of this metric is then used to completely define a set of options for the large MDP. We demonstrate empirically that our approach is able to improve the speed of reinforcement learning, and is generally not sensitive to parameter tuning.},
author = {Castro, Pablo Samuel and Precup, Doina},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-29946-9_16},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Castro, Precup/2012/Automatic Construction of Temporally Extended Actions for MDPs Using Bisimulation Metrics.pdf:pdf},
isbn = {9783642299452},
issn = {03029743},
pages = {140--152},
title = {{Automatic Construction of Temporally Extended Actions for MDPs Using Bisimulation Metrics}},
url = {http://link.springer.com/10.1007/978-3-642-29946-9{\_}16},
volume = {7188 LNAI},
year = {2012}
}
@inproceedings{Brafman2015,
abstract = {To engage diverse agents in cooperative behavior, it is important, even necessary, to provide algo- rithms that do not reveal information that is private or proprietary. A number of recent planning algo- rithms enable agents to plan together for shared goals without disclosing information about their private state and actions. But these algorithms lack clear and formal privacy guarantees: the fact that they do not require agents to explicitly reveal pri- vate information, does not imply that such informa- tion cannot be deduced. The main contribution of this paper is an enhanced version of the distributed forward-search planning framework of Nissim and Brafman that reveals less information than the orig- inal algorithm, and the first, to our knowledge, dis- cussion and formal proof of privacy guarantees for distributed planning and search algorithms.},
author = {Brafman, Ronen I},
booktitle = {Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI 2015)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Brafman/2015/A Privacy Preserving Algorithm for Multi-Agent Planning and Search.pdf:pdf},
pages = {1530--1536},
title = {{A Privacy Preserving Algorithm for Multi-Agent Planning and Search}},
year = {2015}
}
@article{Guo2016,
author = {Guo, Meng and Dimarogonas, Dimos V},
doi = {10.1109/TASE.2016.2628389},
file = {::},
issn = {15455955},
pages = {1--12},
title = {{Task and Motion Coordination for Heterogeneous Multiagent Systems With Loosely Coupled Local Tasks}},
year = {2016}
}
@article{Botvinick2012,
abstract = {The hierarchical structure of human and animal behavior has been of critical interest in neuroscience for many years. Yet understanding the neural processes that give rise to such structure remains an open challenge. In recent research, a new perspective on hierarchical behavior has begun to take shape, inspired by ideas from machine learning, and in particular the framework of hierarchical reinforcement learning. Hierarchical reinforcement learning builds on traditional reinforcement learning mechanisms, extending them to accommodate temporally extended behaviors or subroutines. The resulting computational paradigm has begun to influence both theoretical and empirical work in neuroscience, conceptually aligning the study of hierarchical behavior with research on other aspects of learning and decision making, and giving rise to some thought-provoking new findings. ?? 2012.},
author = {Botvinick, Matthew Michael},
doi = {10.1016/j.conb.2012.05.008},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Botvinick/2012/Hierarchical reinforcement learning and decision making.pdf:pdf},
isbn = {0818653302},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {956--962},
pmid = {22695048},
publisher = {Elsevier Ltd},
title = {{Hierarchical reinforcement learning and decision making}},
url = {http://dx.doi.org/10.1016/j.conb.2012.05.008},
volume = {22},
year = {2012}
}
@article{Bai2017,
abstract = {In the context of hierarchical reinforcement learn-ing, the idea of hierarchies of abstract machines (HAMs) is to write a partial policy as a set of hierar-chical finite state machines with unspecified choice states, and use reinforcement learning to learn an optimal completion of this partial policy. Given a HAM with deep hierarchical structure, there of-ten exist many internal transitions where a machine calls another machine with the environment state unchanged. In this paper, we propose a new hier-archical reinforcement learning algorithm that au-tomatically discovers such internal transitions, and shortcircuits them recursively in the computation of Q values. The resulting HAMQ-INT algorithm outperforms the state of the art significantly on the benchmark Taxi domain and a much more complex RoboCup Keepaway domain.},
author = {Bai, Aijun and Russell, Stuart},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bai, Russell/2017/Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging Internal Transitions.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {Proc. of the 26th International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning: Reinforcement Learning,Planning and Scheduling: Markov Decisions Processe,Robotics and Vision: Multi-Robot Systems,Robotics and Vision: Robotics},
pages = {1418--1424},
title = {{Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging Internal Transitions}},
year = {2017}
}
@article{Konidaris2016,
abstract = {We describe a framework for building abstraction hierarchies whereby an agent alternates skill- and representation-acquisition phases to construct a sequence of increasingly abstract Markov decision processes. Our formulation builds on recent results showing that the appropriate abstract representation of a problem is specified by the agent's skills. We describe how such a hierarchy can be used for fast planning, and illustrate the construction of an appropriate hierarchy for the Taxi domain.},
archivePrefix = {arXiv},
arxivId = {1509.07582},
author = {Konidaris, George},
doi = {10.1016/j.surg.2015.03.052.Rate},
eprint = {1509.07582},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Konidaris/2016/Constructing abstraction hierarchies using a skill-symbol loop.pdf:pdf},
isbn = {6176366127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning},
pages = {1648--1654},
pmid = {28579718},
title = {{Constructing abstraction hierarchies using a skill-symbol loop}},
volume = {2016-Janua},
year = {2016}
}
@article{Sabater2005,
abstract = {The scientific research in the area of computational mechanisms for trust and reputation in virtual societies is a recent discipline oriented to increase the reliability and performance of electronic communities. Computer science has moved from the paradigm of isolated machines to the paradigm of networks and distributed computing. Likewise, artificial intelligence is quickly moving from the paradigm of isolated and non-situated intelligence to the paradigm of situated, social and collective intelligence. The new paradigm of the so called intelligent or autonomous agents and multi-agent systems (MAS) together with the spectacular emergence of the information society technologies (specially reflected by the popularization of electronic commerce) are responsible for the increasing interest on trust and reputation mechanisms applied to electronic societies. This review wants to offer a panoramic view on current computational trust and reputation models.},
author = {Sabater, Jordi and Sierra, Carles},
doi = {10.1007/s10462-004-0041-5},
file = {::},
isbn = {02692821 (ISSN)},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Reputation,Trust},
month = {sep},
number = {1},
pages = {33--60},
title = {{Review on Computational Trust and Reputation Models}},
url = {http://link.springer.com/10.1007/s10462-004-0041-5},
volume = {24},
year = {2005}
}
@article{Roncone2017,
abstract = {— Collaborative robots represent a clear added value to manufacturing, as they promise to increase productivity and improve working conditions of such environments. Although modern robotic systems have become safe and reliable enough to operate close to human workers on a day-to-day basis, the workload is still skewed in favor of a limited contribution from the robot's side, and a significant cognitive load is allotted to the human. We believe the transition from robots as recipients of human instruction to robots as capable collaborators hinges around the implementation of transparent systems, where mental models about the task are shared between peers, and the human partner is freed from the responsibility of taking care of both actors. In this work, we implement a transparent task planner able to be deployed in realistic, near-future applications. The proposed framework is capable of basic reasoning capabilities for what concerns role assignment and task allocation, and it interfaces with the human partner at the level of abstraction he is most comfortable with. The system is readily available to non-expert users, and programmable with high-level commands in an intuitive interface. Our results demonstrate an overall improvement in terms of completion time, as well as a reduced cognitive load for the human partner.},
author = {Roncone, Alessandro and Mangin, Olivier and Scassellati, Brian},
doi = {10.1109/ICRA.2017.7989122},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Roncone, Mangin, Scassellati/2017/Transparent role assignment and task allocation in human robot collaboration.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Social Human-Robot Interaction,Human Factors and H},
pages = {1014--1021},
title = {{Transparent role assignment and task allocation in human robot collaboration}},
year = {2017}
}
@article{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
doi = {10.1016/0004-3702(71)90010-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fikes, Nilsson/1971/STRIPS A new approach to the application of theorem proving to problem solving.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {plan},
mendeley-tags = {plan},
number = {3-4},
pages = {189--208},
title = {{STRIPS: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}
@article{Hayes2016,
abstract = {Collaboration between humans and robots requires solutions to an array of challenging problems, including multi-agent planning, state estimation, and goal inference. There already exist feasible solutions for many of these challenges, but they depend upon having rich task models. In this work we detail a novel type of Hierarchical Task Network we call a Clique/Chain HTN (CC-HTN), alongside an algorithm for autonomously constructing them from topological properties derived from graphical task representations. As the presented method relies on the structure of the task itself, our work imposes no particular type of symbolic insight into motor primitives or environmental representation, making it applicable to a wide variety of use cases critical to human-robot interaction. We present evaluations within a multi-resolution goal inference task and a transfer learning application showing the utility of our approach.},
author = {Hayes, Bradley and Scassellati, Brian},
doi = {10.1109/ICRA.2016.7487760},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hayes, Scassellati/2016/Autonomously constructing hierarchical task networks for planning and human-robot collaboration.pdf:pdf},
isbn = {9781467380263},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {5469--5476},
title = {{Autonomously constructing hierarchical task networks for planning and human-robot collaboration}},
year = {2016}
}
@article{Fox2017,
abstract = {Augmenting an agent's control with useful higher-level behaviors called options can greatly reduce the sample complexity of reinforcement learning, but manually designing options is infeasible in high-dimensional and abstract state spaces. While recent work has proposed several techniques for automated option discovery, they do not scale to multi-level hierarchies and to expressive representations such as deep networks. We present Discovery of Deep Options (DDO), a policy-gradient algorithm that discovers parametrized options from a set of demonstration trajectories, and can be used recursively to discover additional levels of the hierarchy. The scalability of our approach to multi-level hierarchies stems from the decoupling of low-level option discovery from high-level meta-control policy learning, facilitated by under-parametrization of the high level. We demonstrate that using the discovered options to augment the action space of Deep Q-Network agents can accelerate learning by guiding exploration in tasks where random actions are unlikely to reach valuable states. We show that DDO is effective in adding options that accelerate learning in 4 out of 5 Atari RAM environments chosen in our experiments. We also show that DDO can discover structure in robot-assisted surgical videos and kinematics that match expert annotation with 72{\%} accuracy.},
archivePrefix = {arXiv},
arxivId = {1703.08294},
author = {Fox, Roy and Krishnan, Sanjay and Stoica, Ion and Goldberg, Ken},
eprint = {1703.08294},
file = {::},
isbn = {9781510827806},
title = {{Multi-Level Discovery of Deep Options}},
url = {http://arxiv.org/abs/1703.08294},
year = {2017}
}
@article{Sutton2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sutton, Richard S. and Singh, Satinder},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Sutton, Precup, Singh/1999/Between MDPs and Semi-MDPs A Framework for Temporal Abstraction in Reinforcement Learning.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {PhD Proposal},
keywords = {Option},
number = {1999},
pages = {181--211},
pmid = {25246403},
title = {{Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning}},
volume = {1},
year = {1999}
}
@article{Simsek2005,
abstract = {We present a new subgoal-based method for automatically creating useful skills in reinforcement learning. Our method identifies subgoals by partitioning local state transition graphs—those that are constructed using only the most recent experiences of the agent. The local scope of our subgoal discovery method allows it to successfully identify the type of subgoals we seek—states that lie between two densely-connected regions of the state space—while producing an algorithm with low computational cost.},
author = {Şimşek, {\"{O}}zg{\"{u}}r and Wolfe, Alicia P. and Barto, Andrew G.},
doi = {10.1145/1102351.1102454},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Şimşek, Wolfe, Barto/2005/Identifying useful subgoals in reinforcement learning by local graph partitioning.pdf:pdf},
isbn = {1595931805},
journal = {Proceedings of the 22nd international conference on Machine learning  - ICML '05},
pages = {816--823},
title = {{Identifying useful subgoals in reinforcement learning by local graph partitioning}},
url = {http://portal.acm.org/citation.cfm?doid=1102351.1102454},
year = {2005}
}
@article{Glass1999,
author = {Glass, James R},
journal = {Proceedings of the 1999 IEEE ASRU Workshop},
title = {{Challenges for spoken dialogue systems}},
year = {1999}
}
@article{Mcgovern2002,
abstract = {The ability to create and to use abstractions in complex environemnts, that is, to systematically ignore irrelevant details, is a key reason that humans are effective problem solvers. Although the utility of abstraction is commonly accepted, there has been relatively little research on autonomously discovering or creating useful abstractions. A system that can create new abstractions autonomously can learn and plan in situations that its original designer was not able to anticipate. This dissertation introduces two related methods that allow an agent to autonomously discover and create temporal abstractions from its accumulated experience with its environment. A temporal abstraction is an encapsulation of a complex set of actions into a single higher-level action that allows an agent to learn and plan while ignoring details that appear at finer levels of temporal resolution. The main idea of both methods is to search for patterns that occur frequently within an agent's accumulated successful experience and that do not occur in unsuccessful experiences. These patterns are used to create the new temporal abstractions. The two types of temporal abstractions that our methods create are 1) suboals and closed-loop policies for achieving them, and 2) open-loop policies, or action sequences, that are useful "macros." We demonstrate the utility of both types of temporal abstractions in several simulated tasks, including two simulated mobile robot tasks. We use these tasks to demonstrate that the autonomously created temporal abstractions can both facilitate the learning of an agent within a task and can enable effective knowledge transfer related tasks. As a larger task, we focus on the difficult problem of scheduling the assembly instructions for computers with multiple pipelines in such a manner that the reordered instructions will execute as quickly as possible. We demonstrate that the autonomously discovered action sequences can significantly improve performance of the scheduler and can enable effective knowledge transfer across similar processors. Both methods can extract the temporal abstractions from collections of behavioral trajectories generated by different processes. In particular, we demonstrate that the methods can be effective when applied to collections generated by reinforcement learning agents, heuristic searchers, and human tele-operators.},
author = {Mcgovern, Elizabeth Amy},
file = {::},
isbn = {0-493-71665-3},
issn = {16113349},
journal = {Power},
number = {May},
title = {{Autonomous discovery of temporal abstractions from interaction with an environment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.3079{\&}rep=rep1{\&}type=pdf},
year = {2002}
}
@article{Alexandersson2004,
author = {Alexandersson, Jan and Becker, Tilman and Engel, Ralf and L{\"{o}}ckelt, Markus and Pecourt, Elsa and Poller, Peter and Pfleger, Norbert and Reithinger, Norbert},
journal = {HLT-NAACL 2004 Workshop: 2nd Workshop on Scalable Natural Language Understanding},
pages = {25--32},
title = {{Ends-based Dialogue Processing}},
year = {2004}
}
@book{Leontiev1977,
address = {М.},
author = {Леонтьев, Алексей Николаевич},
edition = {Изд. 2-е},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Леонтьев/1977/Деятельность. Сознание. Личность.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {304},
publisher = {Политиздат},
title = {{Деятельность. Сознание. Личность}},
year = {1977}
}
@article{Of2010,
author = {Of, Foundations and Agents, Computational},
file = {::},
isbn = {9780977858231},
issn = {0004-3702},
number = {95},
pages = {19--20},
title = {{Artificial Intelligence}},
volume = {86},
year = {2010}
}
@article{Ghavamzadeh2015,
author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
doi = {10.1561/2200000049},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Ghavamzadeh et al/2015/Bayesian Reinforcement Learning A Survey.pdf:pdf},
isbn = {2200000049},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
number = {5-6},
pages = {359--483},
title = {{Bayesian Reinforcement Learning: A Survey}},
url = {http://www.nowpublishers.com/article/Details/MAL-049},
volume = {8},
year = {2015}
}
@article{Crosby2014,
abstract = {In this paper we present a novel approach to multiagent planning in domains with concurrent actions and associated concurrent action constraints. In these domains, we associate the actions of individual agents with subsets of objects, which allows for a transformation of the problems into single-agent planning problems that are considerably easier to solve. The transformation forces agents to select joint actions associated with a single subset of objects at a time, and ensures that the concurrency constraints on this subset are satisfied. Joint actions are serialised such that each agent performs their part of the action separately. The number of actions in the resulting single-agent planning problem turns out to be manageable in many real-world domains, thus allowing the problem to be solved efficiently using a standard single-agent planner. We also describe a cost-optimal algorithm for compressing the resulting plan, i.e. merging individual actions in order to reduce the total number of joint actions. Results show that our approach can handle large problems that are impossible to solve for most multiagent planners.},
author = {Crosby, Matthew and Jonsson, Anders and Rovatsos, Michael},
doi = {10.3233/978-1-61499-419-0-237},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Crosby, Jonsson, Rovatsos/2014/A single-agent approach to multiagent planning.pdf:pdf},
isbn = {9781614994183},
issn = {09226389},
journal = {Frontiers in Artificial Intelligence and Applications},
pages = {237--242},
title = {{A single-agent approach to multiagent planning}},
volume = {263},
year = {2014}
}
@article{Oizumi2014,
abstract = {This paper presents Integrated Information Theory (IIT) of consciousness 3.0, which incorporates several advances over previous formulations. IIT starts from phenomenological axioms: information says that each experience is specific – it is what it is by how it differs from alternative experiences; integration says that it is unified – irreducible to non- interdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as ‘‘differences that make a difference'' within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, IIT arrives at an identity: an experience is a maximally irreducible conceptual structure (MICS, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a complex. According to IIT, a MICS specifies the quality of an experience and integrated information WMax its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated MICS; a complex can generate a MICS even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true ‘‘zombies'' – unconscious feed-forward systems that are functionally equivalent to conscious complexes. Citation:},
author = {Oizumi, Masafumi and Albantakis, Larissa and Tononi, Giulio},
doi = {10.1371/journal.pcbi.1003588},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Oizumi, Albantakis, Tononi/2014/From the Phenomenology to the Mechanisms of Consciousness Integrated Information Theory 3.0.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {consciousness},
mendeley-tags = {consciousness},
number = {5},
pages = {e1003588},
title = {{From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003588},
volume = {10},
year = {2014}
}
@article{Panov2015g,
abstract = {Рассматриваются особенности представления пространственных и временных знаний для планирования согласованного перемещения коалиции интеллектуальных агентов. В качестве примера подобной задачи рассмотрен перелет группы беспилотных летательных аппаратов в заданную область на местности с препятствиями. Рассматривается знаковый подход к описанию знаний агента, основанный на психологической теории деятельности и биологически правдоподобной иерархической модели распознавания. Особое внимание уделено описанию действий и процессам обучения на основе поступающей первичной информации.},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.pdf:pdf},
journal = {Робототехника и техническая кибернетика},
keywords = {14-07-31194,elibrary,mypub,группа БПЛА,знак,иерархия автоматов,когнитивные процессы,представление знаний},
language = {russian},
mendeley-tags = {14-07-31194,elibrary,mypub},
number = {4(9)},
pages = {34--40},
title = {{Представление знаний автономных агентов, планирующих согласованные перемещения}},
url = {https://elibrary.ru/item.asp?id=25085187},
year = {2015}
}
@inproceedings{Goel2017,
author = {Goel, Karan and Mu, Tong and Brunskill, Emma},
booktitle = {Hierarchical RL Workshop, NIPS 2017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Goel, Mu, Brunskill/2017/Optimal Hierarchical Policy Extraction From Noisy Imperfect Demonstrations.pdf:pdf},
title = {{Optimal Hierarchical Policy Extraction From Noisy Imperfect Demonstrations}},
url = {https://drive.google.com/file/d/101FsZkczKMfGeUBTP-089mhkTeepj8IW/view},
year = {2017}
}
@article{Abdul-Kader2015,
abstract = {—Human-Computer Speech is gaining momentum as a technique of computer interaction. There has been a recent upsurge in speech based search engines and assistants such as Siri, Google Chrome and Cortana. Natural Language Processing (NLP) techniques such as NLTK for Python can be applied to analyse speech, and intelligent responses can be found by designing an engine to provide appropriate human like responses. This type of programme is called a Chatbot, which is the focus of this study. This paper presents a survey on the techniques used to design Chatbots and a comparison is made between different design techniques from nine carefully selected papers according to the main methods adopted. These papers are representative of the significant improvements in Chatbots in the last decade. The paper discusses the similarities and differences in the techniques and examines in particular the Loebner prize-winning Chatbots.},
archivePrefix = {arXiv},
arxivId = {1310.4774},
author = {Abdul-Kader, Sameera A and Woods, John},
eprint = {1310.4774},
journal = {IJACSA) International Journal of Advanced Computer Science and Applications},
keywords = {Chatbot,Loebner Prize,NLP,NLTK,SQL,Turing Test,—AIML},
number = {7},
pages = {72--80},
title = {{Survey on Chatbot Design Techniques in Speech Conversation Systems}},
url = {www.ijacsa.thesai.org},
volume = {6},
year = {2015}
}
@article{Gorodetsky2009,
abstract = {В работе рассматривается технология построения прикладных систем группового управления, со- стоящих из большого числа автономных подсистем, организованных в сеть, узлы которой могут работать под управлением различных операционных систем и в различных коммуникационных средах. Технология интегрирует подходы распределенного принятия решений, многоагентных систем, ориентированной на сервис архитектуры и вычислений на основе парных взаимодействий. Технология поддерживается инструментальными средствами, ко- торые обеспечивают эффективную разработку агентов и механизмов их взаимодействия. Приводятся примеры использования технологии в ряде приложений, в частности, для автономного управления воздушным движением в районе аэропорта.},
author = {Городецкий, В. И. and Карсаев, О. В. and Самойлов, В. В. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Городецкий et al/2009/Прикладные многоагентные системы группового управления.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
language = {russian},
number = {2},
pages = {3--24},
title = {{Прикладные многоагентные системы группового управления}},
year = {2009}
}
@inproceedings{Apeldoorn2015,
author = {Apeldoorn, Daan},
booktitle = {Proceedings of the 5th Workshop on Dynamics of Knowledge and Belief (DKB-2015) and the 4th Workshop KI {\&} Kognition (KIK-2015) co-located with 38th German Conference on Artificial Intelligence (KI-2015)},
editor = {Beierle, Christoph and Kern-Isberner, Gabriele and Ragni, Marco and Frieder, Stolzenburg},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Apeldoorn/2015/Learning Rules for Cooperative Solving of Spatio-Temporal Problems.pdf:pdf},
keywords = {cooperative problem solving,knowledge extraction,learning,multi-agent simulation,rule},
pages = {5--15},
title = {{Learning Rules for Cooperative Solving of Spatio-Temporal Problems}},
year = {2015}
}
@article{Wahlster1989,
abstract = {This chapter surveys the field of user modeling in artificial intelligence dialog systems. First, reasons why user modeling has become so important in the last few years are pointed out, and definitions are proposed for the terms 'user model' and 'user modeling component'. Research within and outside of artificial intelligence which is related to user modeling in dialog systems is discussed. In Section 2, techniques for constructing user models in the course of a dialog are presented and, in Section 3, recent proposals for representing a wide range of assumptions about a user's beliefs and goals in a system's knowledge base are surveyed. Examples for the application of user models in systems developed to date are then given, and some social implications discussed. Finally, unsolved problems like coping with collective beliefs or resource-limited processes are investigated, and prospects for application- oriented research are outlined. Although the survey is restricted to user models in natural- language dialog systems, most of the concepts and methods discussed can be extended to AI dialog systems in general.},
author = {Wahlster, Wolfgang and Kobsa, Alfred},
doi = {10.1007/978-3-642-83230-7},
isbn = {0-387-18380-9; 3-540-18380-9 Print},
journal = {User Models in Dialog Systems},
number = {Sfb 314},
pages = {4--34},
pmid = {3383829},
title = {{User models in dialog systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.9428{\&}rep=rep1{\&}type=pdf{\%}5Cnhttp://link.springer.com/chapter/10.1007/978-3-642-83230-7{\_}1},
year = {1989}
}
@article{Crosby2015,
author = {Crosby, Matthew},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Crosby/2015/ADP an Agent Decomposition Planner CoDMAP 2015.pdf:pdf},
journal = {ICAPS Proceedings of the Competition of Distributed and Multi-Agent Planners (CoDMAP-15)},
pages = {4--7},
title = {{ADP an Agent Decomposition Planner CoDMAP 2015}},
year = {2015}
}
@article{Osipov2015d,
abstract = {Рассматриваются процедуры формирования элемента картины мира субъекта деятельности (знака), введенные в первой части работы. Исследуется процесс формирование пары образ – значение знака с учетом современных представлений о строении и функционировании коры головного мозга человека. Строится алгоритм синтеза плана поведения и предлагается новая архитектура интеллектуальных агентов, обладающих, в частности, способностями к распределению ролей в коалициях.},
author = {Осипов, Г. С. and Панов, А. И. and Чудова, Н. В.},
doi = {10.7868/S0002338815050108},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2015/Управление поведением как функция сознания. II. Синтез плана поведения.pdf:pdf},
isbn = {0002-3388},
journal = {Известия Российский академии наук. Теория и системы управления},
keywords = {14-11-00692,15-07-06214,elibrary,mypub,vak},
language = {russian},
mendeley-tags = {14-11-00692,15-07-06214,elibrary,mypub,vak},
number = {6},
pages = {47--61},
title = {{Управление поведением как функция сознания. II. Синтез плана поведения}},
year = {2015}
}
@article{Gordon,
author = {Gordon, Joshua},
title = {{Spoken Dialog System Architecture}}
}
@inproceedings{Primeau2016,
author = {Primeau, Nicolas and Falcon, Rafael and Abielmona, Rami and Groza, Voicu and Petriu, Emil},
booktitle = {2016 IEEE 20th Jubilee International Conference on Intelligent Engineering Systems (INES)},
doi = {10.1109/INES.2016.7555136},
file = {::},
isbn = {978-1-5090-1216-9},
month = {jun},
pages = {21--26},
publisher = {IEEE},
title = {{Improving task allocation in risk-aware robotic sensor networks via auction protocol selection}},
url = {http://ieeexplore.ieee.org/document/7555136/},
year = {2016}
}
@article{Cao2012,
abstract = {We describe an approach to incorporating Bayesian priors in the MAXQ framework for hierarchical reinforcement learning (HRL). We define priors on the primitive environment model and on task pseudo-rewards. Since models for composite tasks can be complex, we use a mixed model-based/model-free learning approach to find an optimal hierarchical policy. We show empirically that (i) our approach results in improved convergence over non-Bayesian baselines, (ii) using both task hierarchies and Bayesian priors is better than either alone, (iii) taking advantage of the task hierarchy reduces the computational cost of Bayesian reinforcement learning and (iv) in this framework, task pseudo-rewards can be learned instead of being manually specified, leading to hierarchically optimal rather than recursively optimal policies.},
author = {Cao, F and Ray, Soumya},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cao, Ray/2012/Bayesian hierarchical reinforcement learning.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {73--81},
title = {{Bayesian hierarchical reinforcement learning}},
url = {http://papers.nips.cc/paper/4752-bay},
year = {2012}
}
@article{Panov2015g,
abstract = {Рассматриваются особенности представления пространственных и временных знаний для планирования согласованного перемещения коалиции интеллектуальных агентов. В качестве примера подобной задачи рассмотрен перелет группы беспилотных летательных аппаратов в заданную область на местности с препятствиями. Рассматривается знаковый подход к описанию знаний агента, основанный на психологической теории деятельности и биологически правдоподобной иерархической модели распознавания. Особое внимание уделено описанию действий и процессам обучения на основе поступающей первичной информации.},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.pdf:pdf},
journal = {Робототехника и техническая кибернетика},
keywords = {14-07-31194,elibrary,mypub,группа БПЛА,знак,иерархия автоматов,когнитивные процессы,представление знаний},
language = {russian},
mendeley-tags = {14-07-31194,elibrary,mypub},
number = {4(9)},
pages = {34--40},
title = {{Представление знаний автономных агентов, планирующих согласованные перемещения}},
year = {2015}
}
@book{Osipov2009,
address = {М.},
author = {Осипов, Г. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов/2009/Лекции по искусственному интеллекту.pdf:pdf},
keywords = {osipov},
language = {russian},
mendeley-tags = {osipov},
pages = {266},
publisher = {УРСС},
title = {{Лекции по искусственному интеллекту}},
year = {2009}
}
@inproceedings{Singh2005,
author = {Singh, Satinder and Barto, Andrew G. and Chentanez, Nuttapong},
booktitle = {Proceeding of NIPS 2005},
doi = {10.1.1.123.395},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Singh, Barto, Chentanez/2005/Intrinsically motivated reinforcement learning.pdf:pdf},
pages = {1281--1288},
title = {{Intrinsically motivated reinforcement learning}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2005{\_}724.pdf},
year = {2005}
}
@article{Panov2016b,
abstract = {Behavior planning is known to be one of the basic cognitive functions, which is essential for any cognitive architecture of any control system used in robotics. At the same time most of the widespread planning algorithms employed in those systems are developed using only approaches and models of Artificial Intelligence and don't take into account numerous results of cognitive experiments. As a result, there is a strong need for novel methods of behavior planning suitable for modern cognitive architectures aimed at robot control. One such method is presented in this work and is studied within a special class of navigation task called smart relocation task. The method is based on the hierarchical two-level model of abstraction and knowledge representation, e.g. symbolic and subsymbolic. On the symbolic level sign world model is used for knowledge representation and hierarchical planning algorithm, MAP, is utilized for planning. On the subsymbolic level the task of path planning is considered and solved as a graph search problem. Interaction between both planners is examined and inter-level interfaces and feedback loops are described. Preliminary experimental results are presented.},
author = {Panov, Aleksandr I. and Yakovlev, Konstantin S.},
doi = {10.1016/j.procs.2016.07.414},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov, Yakovlev/2016/Psychologically Inspired Planning Method for Smart Relocation Task(2).pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Panov, Yakovlev/2016/Psychologically Inspired Planning Method for Smart Relocation Task.pdf:pdf},
issn = {1877-0509},
journal = {Procedia Computer Science},
keywords = {16-11-00048,behavior planning,computer cognitive modeling,map,myconf,path planning,planner,scopus,sign world model,theory of activity,wos{\_}core},
mendeley-tags = {16-11-00048,myconf,scopus,wos{\_}core},
pages = {115--124},
title = {{Psychologically Inspired Planning Method for Smart Relocation Task}},
url = {http://www.sciencedirect.com/science/article/pii/S1877050916316702},
volume = {88},
year = {2016}
}
@article{Andre2002,
abstract = {Hierarchical reinforcement learning ALisp - a language to support represent hierarchical model. The authors present way to organize information in hierarchical fashion. In which, at each level, each state contains only necessary information for RL, and speed up learning process then. That state is called abstract state in the paper.},
author = {Andre, David and Russell, Stuart},
file = {::},
isbn = {0-262-51129-0},
issn = {1049-5258},
journal = {Aaai},
number = {Dietterich 2000},
pages = {119--125},
title = {{State Abstraction for Programmable Reinforcement Learning Agents}},
url = {http://www.aaai.org/Papers/AAAI/2002/AAAI02-019.pdf},
year = {2002}
}
@article{Johnston2013,
abstract = {We explore the plausibility of using automated spoken dialog systems (SDS) for administer- ing survey interviews. Because the goals of a survey dialog system differ from more tradi- tional information-seeking and transactional applications, different measures of task accu- racy and success may be warranted. We report a large-scale experimental evaluation of an SDS that administered survey interviews with questions drawn from government and social scientific surveys. We compare two dialog confirmation strategies: (1) a traditional strate- gy of explicit confirmation on low-confidence recognition; and (2) no confirmation. With ex- plicit confirmation, the small percentage of re- sidual errors had little to no impact on survey data measurement. Even without confirmation, while there are significantly more errors, im- pact on the substantive conclusions of the sur- vey is still very limited.},
author = {Johnston, Michael and Ehlen, Patrick and Conrad, Frederick G and Schober, Michael F and Antoun, Christopher and Fail, Stefanie and Hupp, Andrew and Vickers, Lucas and Yan, Huiying and Zhang, Chan},
isbn = {9781937284954},
journal = {Proceedings of the SIGdial 2013 Conference: The 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
number = {August},
pages = {329--333},
title = {{Spoken Dialog Systems for Automated Survey Interviewing}},
url = {http://mfschober.net/Johnstonetal13.pdf},
year = {2013}
}
@article{Pospelov1996,
author = {Поспелов, Д. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Поспелов/1996/Прикладная семиотика и искусственный интеллект.pdf:pdf},
journal = {Программные продукты и системы},
language = {russian},
number = {3},
pages = {10--13},
title = {{Прикладная семиотика и искусственный интеллект}},
year = {1996}
}
@article{Frans2017,
abstract = {We develop a metalearning approach for learning hierarchically structured policies, improving sample efficiency on unseen tasks through the use of shared primitives---policies that are executed for large numbers of timesteps. Specifically, a set of primitives are shared within a distribution of tasks, and are switched between by task-specific policies. We provide a concrete metric for measuring the strength of such hierarchies, leading to an optimization problem for quickly reaching high reward on unseen tasks. We then present an algorithm to solve this problem end-to-end through the use of any off-the-shelf reinforcement learning method, by repeatedly sampling new tasks and resetting task-specific policies. We successfully discover meaningful motor primitives for the directional movement of four-legged robots, solely by interacting with distributions of mazes. We also demonstrate the transferability of primitives to solve long-timescale sparse-reward obstacle courses, and we enable 3D humanoid robots to robustly walk and crawl with the same policy.},
archivePrefix = {arXiv},
arxivId = {1710.09767},
author = {Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
eprint = {1710.09767},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frans et al/2017/Meta Learning Shared Hierarchies.pdf:pdf},
pages = {1--11},
title = {{Meta Learning Shared Hierarchies}},
url = {http://arxiv.org/abs/1710.09767},
year = {2017}
}
@article{Jennings1995a,
abstract = {One reason why Distributed AI (DAI) technology has been deployed in relatively few real-size applications is that it lacks a clear and implementable model of cooperative problem solving which specifies how agents should operate and interact in complex, dynamic and unpredictable environments. As a consequence of the experience gained whilst building a number of DAI systems for industrial applications, a new principled model of cooperation has been developed. This model, called Joint Responsibility, has the notion of joint intentions at its core. It specifies pre-conditions which must be attained before collaboration can commence and prescribes how individuals should behave both when joint activity is progressing satisfactorily and also when it runs into difficulty. The theoretical model has been used to guide the implementation of a general-purpose cooperation framework and the qualitative and quantitative benefits of this implementation have been assessed through a series of comparative experiments in the real-world domain of electricity transportation management. Finally, the success of the approach of building a system with an explicit and grounded representation of cooperative problem solving is used to outline a proposal for the next generation of multi-agent systems. {\textcopyright} 1995.},
author = {Jennings, N. R.},
doi = {10.1016/0004-3702(94)00020-2},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Jennings/1995/Controlling cooperative problem solving in industrial multi-agent systems using joint intentions.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
number = {2},
pages = {195--240},
title = {{Controlling cooperative problem solving in industrial multi-agent systems using joint intentions}},
volume = {75},
year = {1995}
}
@inproceedings{Mehta2008b,
abstract = {We present an algorithm, HI-MAT (Hierar- chy Induction via Models And Trajectories), that discovers MAXQ task hierarchies by ap- plying dynamic Bayesian network models to a successful trajectory from a source rein- forcement learning task. HI-MAT discovers subtasks by analyzing the causal and tem- poral relationships among the actions in the trajectory. Under appropriate assumptions, HI-MAT induces hierarchies that are consis- tent with the observed trajectory and have compact value-function tables employing safe state abstractions. We demonstrate empir- ically that HI-MAT constructs compact hi- erarchies that are comparable to manually- engineered hierarchies and facilitate signifi- cant speedup in learning when transferred to a target task.},
address = {New York, New York, USA},
author = {Mehta, Neville and Ray, Soumya and Tadepalli, Prasad and Dietterich, Thomas},
booktitle = {Proceedings of the 25th international conference on Machine learning - ICML '08},
doi = {10.1145/1390156.1390238},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mehta et al/2008/Automatic discovery and transfer of MAXQ hierarchies.pdf:pdf},
isbn = {9781605582054},
pages = {648--655},
publisher = {ACM Press},
title = {{Automatic discovery and transfer of MAXQ hierarchies}},
url = {http://portal.acm.org/citation.cfm?id=1390238 http://portal.acm.org/citation.cfm?doid=1390156.1390238},
year = {2008}
}
@article{Osipov2015d,
abstract = {Рассматриваются процедуры формирования элемента картины мира субъекта деятельности (знака), введенные в первой части работы. Исследуется процесс формирование пары образ – значение знака с учетом современных представлений о строении и функционировании коры головного мозга человека. Строится алгоритм синтеза плана поведения и предлагается новая архитектура интеллектуальных агентов, обладающих, в частности, способностями к распределению ролей в коалициях.},
author = {Осипов, Г. С. and Панов, А. И. and Чудова, Н. В.},
doi = {10.7868/S0002338815050108},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Осипов, Панов, Чудова/2015/Управление поведением как функция сознания. II. Синтез плана поведения.pdf:pdf},
isbn = {0002338815},
journal = {Известия РАН. Теория и системы управления},
keywords = {14-11-00692,15-07-06214,elibrary,mypub,vak},
language = {russian},
mendeley-tags = {14-11-00692,15-07-06214,elibrary,mypub,vak},
number = {6},
pages = {47--61},
title = {{Управление поведением как функция сознания. II. Синтез плана поведения}},
year = {2015}
}
@article{Chandrasekaran2017,
author = {Chandrasekaran, Muthukumaran and Doshi, Prashant and Zeng, Yifeng and Chen, Yingke},
doi = {10.1007/s10458-016-9354-4},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {Multiagent systems,Ad hoc teamwork,Sequential deci},
number = {4},
pages = {821--860},
publisher = {Springer US},
title = {{Can bounded and self-interested agents be teammates? Application to planning in ad hoc teams}},
url = {http://link.springer.com/10.1007/s10458-016-9354-4},
volume = {31},
year = {2017}
}
@article{Parr1998,
abstract = {We present a new approach to reinforcement learning in which the poli- cies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework inwhich knowledge can be transferred across problems and in which component solutions can be recombined to solve larger and more complicated problems. Our approach can be seen as providing a link between reinforcement learn- ing and “behavior-based” or “teleo-reactive” approaches to control. We present provably convergent algorithms for problem-solving and learn- ing with hierarchical machines and demonstrate their effectiveness on a problem with several thousand states. 1},
author = {Parr, Ronald and Russell, Stuart},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Parr, Russell/1998/Reinforcement learning with hierarchies of machines.pdf:pdf},
isbn = {0-262-10076-2},
issn = {0031-8116},
journal = {Neural Information Processing Systems (NIPS)},
pages = {1043--1049},
title = {{Reinforcement learning with hierarchies of machines}},
url = {http://www.cs.berkeley.edu/{~}russell/classes/cs294/s11/readings/Parr+Russell:1998.pdf},
year = {1998}
}
@phdthesis{Rasmussen2014,
author = {Rasmussen, Daniel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rasmussen/2014/Hierarchical reinforcement learning in a biologically plausible neural architecture.pdf:pdf},
pages = {175},
school = {Unversetu of Waterloo},
title = {{Hierarchical reinforcement learning in a biologically plausible neural architecture}},
year = {2014}
}
@article{Makarov2015a,
abstract = {В работе рассмотрен ряд вопросов, возникающих в области автоматизации управления малыми беспилотными летательными аппаратами (БПЛА) мультироторного типа. Предложена совокупность методов планирования и управления, рассмотрена задача организации взаимодействия различных методов и алгоритмов (авторских и известных) в единую интеллектуальную систему управления БПЛА. Предлагается использование трех уровней управления – стратегического, тактического и реактивного, описывается соответствующая архитектура – STRL (от англ. strategic, tactical, reactive, layered). Использование этой архитектуры позволит автоматизировать управление коалициями БПЛА при решении широкого круга задач в различных средах.},
author = {Макаров, Д. А. and Панов, А. И. and Яковлев, К. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Макаров, Панов, Яковлев/2015/Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами.doc:doc},
journal = {Искусственный интеллект и принятие решений},
keywords = {14-11-00692,elibrary,mypub,vak,wos{\_}rsci,беспилотные летательные аппараты,знаковая картина мира,интеллектуальная система управления,многоуровневая архитектура,нелинейное управление,планирование траектории,уравнение Риккати},
language = {russian},
mendeley-tags = {14-11-00692,elibrary,mypub,vak,wos{\_}rsci},
number = {3},
pages = {18--33},
title = {{Архитектура многоуровневой интеллектуальной системы управления беспилотными летательными аппаратами}},
year = {2015}
}
@article{Roy2005,
author = {Roy, D.},
doi = {10.1016/j.artint.2005.04.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Roy/2005/Semiotic schemas A framework for grounding language in action and perception.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {1,action,and consequently our ability,and the physical world,cross-modal,embodied,grounding,language,language and meaning,meaning,multimodal,perception,representation,schemas,semiotic,semiotics,situated,the relationship between words,to},
mendeley-tags = {semiotics},
number = {1-2},
pages = {170--205},
title = {{Semiotic schemas: A framework for grounding language in action and perception}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370205001037},
volume = {167},
year = {2005}
}
@article{Panov2015g,
abstract = {Рассматриваются особенности представления пространственных и временных знаний для планирования согласованного перемещения коалиции интеллектуальных агентов. В качестве примера подобной задачи рассмотрен перелет группы беспилотных летательных аппаратов в заданную область на местности с препятствиями. Рассматривается знаковый подход к описанию знаний агента, основанный на психологической теории деятельности и биологически правдоподобной иерархической модели распознавания. Особое внимание уделено описанию действий и процессам обучения на основе поступающей первичной информации.},
author = {Панов, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.docx:docx;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Панов/2015/Представление знаний автономных агентов, планирующих согласованные перемещения.pdf:pdf},
journal = {Робототехника и техническая кибернетика},
keywords = {14-07-31194,elibrary,mypub,группа БПЛА,знак,иерархия автоматов,когнитивные процессы,представление знаний},
language = {russian},
mendeley-tags = {14-07-31194,elibrary,mypub},
number = {4(9)},
pages = {34--40},
title = {{Представление знаний автономных агентов, планирующих согласованные перемещения}},
url = {https://elibrary.ru/item.asp?id=25085187},
year = {2015}
}
@article{Kaelbling2013,
abstract = {We describe an integrated strategy for planning, perception, state estimation and action in complex mobile manipulation domains based on planning in the belief space of probability distributions over states using hierarchical goal regression (pre-image back-chaining). We develop a vocabulary of logical expressions that describe sets of belief states, which are goals and subgoals in the planning process. We show that a relatively small set of symbolic operators can give rise to task-oriented perception in support of the manipulation goals. An implementation of this method is demonstrated in simulation and on a real PR2 robot, showing robust, flexible solution of mobile manipulation problems with multiple objects and substantial uncertainty.},
author = {Kaelbling, Leslie Pack and Lozano-P{\'{e}}rez, Tomas},
doi = {10.1177/0278364913484072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kaelbling, Lozano-P{\'{e}}rez/2013/Integrated task and motion planning in belief space.pdf:pdf},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
number = {9-10},
pages = {1194--1227},
title = {{Integrated task and motion planning in belief space}},
url = {http://ijr.sagepub.com/content/32/9-10/1194.abstract?etoc},
volume = {32},
year = {2013}
}
@article{Woudenberg2014,
abstract = {Conversational software, that is software with which a user can con- verse in a natural language such as English or Dutch, can be classified into two distinct categories: chatbots and dialogue systems. Chatbots work according to the principle of pattern matching where user input is matched to a fixed response. In dialogue systems, user input is parsed into some semantical rep- resentation. This representation is then used by a component called a dialogue manager to determine what the response should be. A dia- logue manager maintains a state of the conversation by tracking who spoke last, what knowledge is private and shared, the current goal, what plan should be followed to resolve an open issue and how much of the user input was understood. Both categories of systems have their advantages and disadvan- tages. Chatbot systems are trivial to build and maintain, but are too simplistic for applications that do more than answering frequently asked questions. Dialogue systems on the other hand are harder to develop and maintain, can deal with less variety in user input, but are capable of handling and generating all kinds of linguistic phenomena such as grounding and information revision. This thesis presents a system that combines ideas from chatbots and dialogue system. This hybrid system doesn't parse natural language into a semantic presentation, but contains a dialogue manager that can handle natural language directly. This system would make it easy to implement and maintain new domains even when the developer has little or no knowledge of computational linguistics. The system would also be able to deal with a variety of linguistic phenomena. A statistics tutor has been implemented using this hybrid system with which three students interacted. This shows that it's reasonably easy to build and maintain new domains using this approach. It is also shown that the statistics tutor is able to deal with phenomena such as grounding, question accommodation and information revision.},
author = {Woudenberg, A F Van},
title = {{A Chatbot Dialogue Manager Chatbots and Dialogue Systems : A Hybrid Approach}},
year = {2014}
}
@inproceedings{MacGlashan2010,
abstract = {We present skill bootstrapping, a proposed new research direction for agent learning and planning that allows an agent to start with low-level primitive actions, and develop skills that can be used for higher-level planning. Skills are developed over the course of solving many different problems in a domain, using reinforcement learning techniques to complement the benefits and disadvantages of heuristic-search planning. We describe the overall architecture of the proposed approach, discuss how it relates to other work, and give motivating examples for why this approach would be successful.},
author = {MacGlashan, James and DesJArdins, Marie},
booktitle = {24th AAAI Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/MacGlashan, DesJArdins/2010/Hierarchical Skill Learning for High-Level Planning.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/MacGlashan, DesJArdins/2010/Hierarchical Skill Learning for High-Level Planning(2).pdf:pdf},
isbn = {9781577354666},
keywords = {abstraction,approximation,planning,reinforcement learning},
pages = {1988--1989},
title = {{Hierarchical Skill Learning for High-Level Planning}},
volume = {3},
year = {2010}
}
@inproceedings{Mehta2008a,
abstract = {We present an algorithm, HI-MAT (Hierar- chy Induction via Models And Trajectories), that discovers MAXQ task hierarchies by ap- plying dynamic Bayesian network models to a successful trajectory from a source rein- forcement learning task. HI-MAT discovers subtasks by analyzing the causal and tem- poral relationships among the actions in the trajectory. Under appropriate assumptions, HI-MAT induces hierarchies that are consis- tent with the observed trajectory and have compact value-function tables employing safe state abstractions. We demonstrate empir- ically that HI-MAT constructs compact hi- erarchies that are comparable to manually- engineered hierarchies and facilitate signifi- cant speedup in learning when transferred to a target task.},
address = {New York, New York, USA},
author = {Mehta, Neville and Ray, Soumya and Tadepalli, Prasad and Dietterich, Thomas},
booktitle = {Proceedings of the 25th international conference on Machine learning - ICML '08},
doi = {10.1145/1390156.1390238},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mehta et al/2008/Automatic discovery and transfer of MAXQ hierarchies.pdf:pdf},
isbn = {9781605582054},
pages = {648--655},
publisher = {ACM Press},
title = {{Automatic discovery and transfer of MAXQ hierarchies}},
url = {http://portal.acm.org/citation.cfm?id=1390238 http://portal.acm.org/citation.cfm?doid=1390156.1390238},
year = {2008}
}
@article{Hayes2016b,
abstract = {Collaboration between humans and robots requires solutions to an array of challenging problems, including multi-agent planning, state estimation, and goal inference. There already exist feasible solutions for many of these challenges, but they depend upon having rich task models. In this work we detail a novel type of Hierarchical Task Network we call a Clique/Chain HTN (CC-HTN), alongside an algorithm for autonomously constructing them from topological properties derived from graphical task representations. As the presented method relies on the structure of the task itself, our work imposes no particular type of symbolic insight into motor primitives or environmental representation, making it applicable to a wide variety of use cases critical to human-robot interaction. We present evaluations within a multi-resolution goal inference task and a transfer learning application showing the utility of our approach.},
author = {Hayes, Bradley and Scassellati, Brian},
doi = {10.1109/ICRA.2016.7487760},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hayes, Scassellati/2016/Autonomously constructing hierarchical task networks for planning and human-robot collaboration.pdf:pdf},
isbn = {9781467380263},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {5469--5476},
title = {{Autonomously constructing hierarchical task networks for planning and human-robot collaboration}},
volume = {2016-June},
year = {2016}
}
@article{Dietterich2000a,
abstract = {Reinforcement learning addresses the problem of learning optimal policies for sequential decision-making problems involving stochastic operators and numerical reward functions rather than the more traditional deterministic operators and logical goal predicates. In many ways, reinforcement learning research is recapitulating the development of classical research in planning and problem solving. After studying the problem of solving flat problem spaces, researchers have recently turned their attention to hierarchical methods that incorporate subroutines and state abstractions. This paper gives an overview of the MAXQ value function decomposition and its support for state abstraction and action abstraction.},
archivePrefix = {arXiv},
arxivId = {cs/9905015},
author = {Dietterich, Thomas G},
doi = {10.1007/3-540-44914-0_2},
eprint = {9905015},
file = {::},
isbn = {3540678395},
issn = {16113349},
journal = {Abstraction Reformulation and Approximation},
pages = {26--44},
pmid = {25246403},
primaryClass = {cs},
title = {{An Overview of MAXQ Hierarchical Reinforcement Learning}},
url = {http://www.springerlink.com/index/W11KBY3DH4VEEHDN.pdf},
volume = {1864/2000},
year = {2000}
}
@article{Dietterich2000,
abstract = {This paper presents a new approach to hierarchical reinforcement learning based on de-composing the target Markov decision process MDP into a hierarchy o f smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The decomposition, known as the MAXQ decom-position, has both a procedural semantics|as a subroutine hierarchy|and a declarative semantics|as a representation of the value function of a hierarchical policy. MAXQ uniies and extends previous work on hierarchical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. It is based on the assumption that the programmer can identify useful subgoals and deene subtasks that achieve these subgoals. By deening such subgoals, the programmer constrains the set of policies that need to be considered during reinforcement learning. The MAXQ v alue function decomposition can represent the value function of any policy that is consistent with the given hierarchy. The decomposition also creates oppor-tunities to exploit state abstractions, so that individual MDPs within the hierarchy can ignore large parts of the state space. This is important for the practical application of the method. This paper deenes the MAXQ hierarchy, proves formal results on its representa-tional power, and establishes sve conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges with probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the eve kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q with state abstractions converges to a recursively optimal policy much faster than nat Q learning. The fact that MAXQ learns a representation of the value function has an important beneet: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the eeectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoos in hierarchical reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:cs/9905014v1},
author = {Dietterich, Thomas G},
doi = {10.1613/jair.639},
eprint = {9905014v1},
file = {::},
isbn = {978-3-540-67839-7},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {227--303},
primaryClass = {arXiv:cs},
title = {{Hierarchical reinforcement learning with the MAXQ value function decomp osition}},
volume = {13},
year = {2000}
}
