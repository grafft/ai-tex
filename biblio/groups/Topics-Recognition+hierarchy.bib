Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Ding2017a,
abstract = {When a stimulus is presented, its encoding is known to progress from low-to high-level features. How these features are decoded to produce perception is less clear, and most models assume that decoding follows the same low-to high-level hierarchy of encoding. There are also theories arguing for global precedence, reversed hierarchy, or bidirectional processing, but they are descriptive without quantitative comparison with human perception. Moreover, ob-servers often inspect different parts of a scene sequentially to form overall perception, suggesting that perceptual decoding requires working memory, yet few models consider how working-memory properties may affect decoding hierarchy. We probed decoding hierarchy by comparing absolute judgments of single orientations and relative/ordinal judgments between two sequentially presented orientations. We found that lower-level, absolute judgments failed to account for higher-level, relative/ordinal judgments. However, when ordinal judgment was used to retrospectively decode memory representations of absolute orientations, striking aspects of absolute judgments, including the correlation and forward/backward afteref-fects between two reported orientations in a trial, were explained. We propose that the brain prioritizes decoding of higher-level features because they are more behaviorally relevant, and more invariant and categorical, and thus easier to specify and maintain in noisy working memory, and that more reliable higher-level decoding constrains less reliable lower-level decoding. Bayesian prior | interreport correlation | bidirectional tilt aftereffect | efficient coding | adaptation theory},
author = {Ding, Stephanie and Cueva, Christopher J and Tsodyks, Misha and Qian, Ning},
doi = {10.1073/pnas.1706906114},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Ding et al/2017/Visual perception as retrospective Bayesian decoding from high- to low-level features.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {43},
pages = {E9115--E9124},
title = {{Visual perception as retrospective Bayesian decoding from high- to low-level features}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1706906114},
volume = {114},
year = {2017}
}
@article{Spratling2017,
author = {Spratling, M. W.},
doi = {10.1007/s12559-016-9445-1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Spratling/2017/A Hierarchical Predictive Coding Model of Object Recognition in Natural Images.pdf:pdf},
issn = {18669964},
journal = {Cognitive Computation},
keywords = {Deep neural networks,Implicit shape model,Neural networks,Object recognition,Predictive coding,Sparse coding},
number = {2},
pages = {151--167},
publisher = {Cognitive Computation},
title = {{A Hierarchical Predictive Coding Model of Object Recognition in Natural Images}},
volume = {9},
year = {2017}
}
@article{George2017,
author = {George, D. and Lehrach, W. and Kansky, K. and L{\'{a}}zaro-Gredilla, M. and Laan, C. and Marthi, B. and Lou, X. and Meng, Z. and Liu, Y. and Wang, H. and Lavin, A. and Phoenix, D. S.},
doi = {10.1126/science.aag2612},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George et al/2017/A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George et al/2017/A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs(2).pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {oct},
number = {October},
pages = {eaag2612},
pmid = {29074582},
title = {{A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs}},
url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aag2612},
volume = {10},
year = {2017}
}
