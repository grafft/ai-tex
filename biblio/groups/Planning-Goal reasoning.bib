Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Molineaux2010,
abstract = {Modern complex games and simulations pose many challenges for an intelligent agent, including partial observability, continuous time and effects, hostile opponents, and exogenous events. We present ARTUE (Autonomous Response to Unexpected Events), a domain-independent autonomous agent that dynamically reasons about what goals to pursue in response to unexpected circumstances in these types of environments. ARTUE integrates AI research in planning, environment monitoring, explanation, goal generation, and goal management. To explain our conceptualization of the problem ARTUE addresses, we present a new conceptual framework, goal-driven autonomy, for agents that reason about their goals. We evaluate ARTUE on scenarios in the TAO Sandbox, a Navy training simulation, and demonstrate its novel architecture, which includes components for Hierarchical Task Network planning, explanation, and goal management. Our evaluation shows that ARTUE can perform well in a complex environment and that each component is necessary and contributes to the performance of the integrated system.},
author = {Molineaux, Matt and Klenk, Matthew and Aha, David W},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence/Molineaux, Klenk, Aha/Molineaux, Klenk, Aha - 2010 - Goal-Driven Autonomy in a Navy Strategy Simulation.pdf:pdf},
keywords = {special track integrated intelligence},
pages = {1548--1554},
title = {{Goal-Driven Autonomy in a Navy Strategy Simulation}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1928/2251},
year = {2010}
}
@inproceedings{Powell2011,
abstract = {If given manually-crafted goal selection knowledge, goal reasoning agents can dynamically determine which goals they should achieve in complex environments. These agents should instead learn goal selection knowledge through expert interaction. We describe T-ARTUE, a goal reasoning agent that performs case-based active and interactive learning to discover goal selection knowledge. We also report tests of its performance in a complex environment. We found that, under some conditions, T-ARTUE can quickly learn goal selection knowledge.},
author = {Powell, Jay and Molineaux, Matthew and Aha, David W},
booktitle = {Proceedings of the Twenty-Fourth International Florida Artificial Intelligence Research Society Conference Active},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Twenty-Fourth International Florida Artificial Intelligence Research Society Conference Active/Powell, Molineaux, Aha/Powell, Molineaux, Aha - 2011 - Active and Interactive Discovery of Goa.pdf:pdf},
isbn = {9781577355014},
keywords = {Special Track on Case-Based Reasoning},
pages = {413--418},
title = {{Active and Interactive Discovery of Goal Selection Knowledge}},
year = {2011}
}
@article{Pollock1998,
author = {Pollock, John L.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Artificial Intelligence/Pollock/Pollock - 1998 - The logical foundations of goal-regression planning in autonomous agents.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {plan},
mendeley-tags = {plan},
pages = {267--334},
title = {{The logical foundations of goal-regression planning in autonomous agents}},
volume = {106},
year = {1998}
}
@article{Wilson2013,
abstract = {Goal-driven autonomy is a framework for intelligent agents that automatically formulate and manage goals in dynamic environments, where goal formulation is the task of identifying goals that the agent should attempt to achieve. We argue that goal formulation is central to high-level autonomy, and explain why identifying domain-independent heuristics for this task is an important research topic in high- level control. We describe two novel domain-independent heuristics for goal formulation (motivators) that evaluate the utility of goals based on the projected consequences of achieving them. We then describe their integration in M- ARTUE, an agent that balances the satisfaction of internal needs with the achievement of goals introduced externally. We assess its performance in a series of experiments in the Rovers With Compass domain. Our results show that using domain-independent heuristics yields performance comparable to using domain-specific knowledge for goal formulation. Finally, in ablation studies we demonstrate that each motivator contributes significantly to M-ARTUE's performance.},
author = {Wilson, Mark and Molineaux, Matthew and Aha, David W},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Twenty-Sixth International Florida Artificial Intelligence Research Society Conference Domain-Independent/Wilson, Molineaux, Aha/Wilson, Molineaux, Aha - 2013 - Domain-Independent Heuristic.pdf:pdf},
isbn = {9781577356059},
journal = {Proceedings of the Twenty-Sixth International Florida Artificial Intelligence Research Society Conference Domain-Independent},
keywords = {General Conference Papers},
pages = {160--165},
title = {{Domain-Independent Heuristics for Goal Formulation}},
url = {http://www.stormingmedia.us/25/2564/A256495.html},
year = {2013}
}
@inproceedings{Roberts2014,
abstract = {Goal Reasoning (GR) concerns actors that assume the responsibility for dynamically selecting the goals they pursue. Our focus is on modeling an actor{\{}$\backslash$textquoteright{\}}s decision making when they encounter notable events. We model GR as an iterative refinement process, where constraints introduced for each abstraction layer shape the solutions for successive layers. Our model provides a conceptual framework for robotics researchers and practitioners. We present a goal lifecycle and define a formal model for GR that (1) relates distinct disciplines concerning actors that operate on goals, and (2) provides a way to evaluate actors. We introduce GR using an example on waypoint navigation and outline its application, in three projects, for controlling simulated and real-world vehicles. We emphasize the relation of GR to planning, and encourage PlanRob researchers to collaborate in exploring this exciting frontier.},
author = {Roberts, Mark and Vattam, Swaroop and Alford, Ronald and Auslander, Bryan and Karneeb, Justin and Molineaux, Matthew and Apker, Thomas and Wilson, Mark and McMahon, James and Aha, David W.},
booktitle = {Working Notes of the Planning and Robotics Workshop at ICAPS},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Working Notes of the Planning and Robotics Workshop at ICAPS/Roberts et al/Roberts et al. - 2014 - Iterative Goal Refinement for Robotics.pdf:pdf},
title = {{Iterative Goal Refinement for Robotics}},
year = {2014}
}
@incollection{Munoz-Avila2010,
author = {Mu{\~{n}}oz-Avila, H{\'{e}}ctor and Jaidee, Ulit and Aha, David W and Carter, Elizabeth},
booktitle = {Case-Based Reasoning},
doi = {10.1007/978-3-642-14274-1_18},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Case-Based Reasoning/Mu{\~{n}}oz-Avila et al/Mu{\~{n}}oz-Avila et al. - 2010 - Goal-Driven Autonomy with Case-Based Reasoning.pdf:pdf},
pages = {228--241},
title = {{Goal-Driven Autonomy with Case-Based Reasoning}},
url = {http://link.springer.com/10.1007/978-3-642-14274-1{\_}18},
year = {2010}
}
@article{Cox2017a,
abstract = {Cognitive agents operating in complex and dynamic domains benefit from significant goal management. Operations on goals include formulation, selection, change, monitoring and delegation in addition to goal achievement. Here we model these operations as transformations on goals. An agent may observe events that affect the agent's ability to achieve its goals. Hence goal transformations allow unachievable goals to be converted into similar achievable goals. This paper exam-ines an implementation of goal change within a cognitive ar-chitecture. We introduce goal transformation at the metacog-nitive level as well as goal transformation in an automated planner and discuss the costs and benefits of each approach. We evaluate goal change in the MIDCA architecture using a resource-restricted planning domain, demonstrating a perfor-mance benefit due to goal operations.},
author = {Cox, Michael T and Dannenhauer, Dustin and Kondrakunta, Sravya},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 31th Conference on Artificial Intelligence (AAAI 2017)/Cox, Dannenhauer, Kondrakunta/Cox, Dannenhauer, Kondrakunta - 2017 - Goal Operations for Cognitive Systems.pdf:pdf},
journal = {Proceedings of the 31th Conference on Artificial Intelligence (AAAI 2017)},
keywords = {Special Track on Cognitive Systems},
pages = {4385--4391},
title = {{Goal Operations for Cognitive Systems}},
year = {2017}
}
@article{Alford2016,
abstract = {Considerable work has focused on enhancing the semantics of Hierarchical Task Networks (HTNs) in order to advance the state-of-the-art in hierarchical planning. For instance, the Hierarchical Goal Net-work (HGN) formalism operates over a hierarchy of goals to facilitate tighter integration of decompo-sitional planning with classical planning. Another example is the Action Notation Markup Language (ANML) which adds aspects of generative planning and task-sharing to the standard HTN semantics. The aim of this work is to formally analyze the effects of these modifications to HTN semantics on the computational complexity and expressivity of HTN planning. To facilitate analysis, we unify goal and task planning into Goal-Task Network (GTN) planning. GTN models use HTN and HGN constructs, but have a solution-preserving mapping back to HTN planning. We then show theoretical results that provide new insights into both the ex-pressivity as well as computational complexity of GTN planning under a number of different seman-tics. Our work lays a firm footing to clarify ex-act semantics for recent planners based on ANML, HGNs, and similar hierarchical languages.},
author = {Alford, Ron and Shivashankar, Vikas and Roberts, Mark and Frank, Jeremy and Aha, David W.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IJCAI International Joint Conference on Artificial Intelligence/Alford et al/Alford et al. - 2016 - Hierarchical planning Relating task and goal decomposition with task sharing.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {3022--3028},
title = {{Hierarchical planning: Relating task and goal decomposition with task sharing}},
year = {2016}
}
@article{Vattam2013,
abstract = {Goal-directed behavior is a hallmark of intelligence. While the majority of artificial intelligence research assumes goals are static and externally provided, many real-world applications involve unanticipated changes in the environment that may require changes to the goals themselves. Goal reasoning, which emphasizes the explicit representation of goals, their automatic formulation and dynamic management, is considered an important aspect of high-level autonomy. Building from these three basic requirements, we describe and apply a framework for surveying research related to goal reasoning that focuses on triggers and methods for goal formulation and goal management. We also summarize current research and highlight potential areas of future work.},
author = {Vattam, Swaroop and Klenk, Matthew and Molineaux, Matthew and Aha, David W},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Goal Reasoning Papers from the ACS Workshop/Vattam et al/Vattam et al. - 2013 - Breadth of Approaches to Goal Reasoning A Research Survey.pdf:pdf},
journal = {Goal Reasoning: Papers from the ACS Workshop},
pages = {111--126},
title = {{Breadth of Approaches to Goal Reasoning : A Research Survey}},
year = {2013}
}
@incollection{Jaidee2013,
abstract = {Although several recent studies have been published on goal reasoning (i.e., the study of agents that can self-select their goals), none have focused on the task of learning and acting on large state and action spaces. We introduce GDA-C, a case-based goal reasoning algorithm that divides the state and action space among cooperating learning agents. Cooperation between agents emerges because (1) they share a common reward function and (2) GDA-C formulates the goal that each agent needs to achieve. We claim that its case-based approach for goal formulation is critical to the agents' performance. To test this claim we conducted an empirical study using the Wargus RTS environment, where we found that GDA-C outperforms its non-GDA ablation. {\textcopyright} 2013 Springer-Verlag.},
author = {Jaidee, Ulit and Mu{\~{n}}oz-Avila, H{\'{e}}ctor and Aha, David W.},
booktitle = {Case-Based Reasoning Research and Development},
doi = {10.1007/978-3-642-39056-2_12},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Case-Based Reasoning Research and Development/Jaidee, Mu{\~{n}}oz-Avila, Aha/Jaidee, Mu{\~{n}}oz-Avila, Aha - 2013 - Case-Based Goal-Driven Coordination of Multiple Learning Agents.pdf:pdf},
isbn = {9783642390555},
issn = {03029743},
keywords = {Goal-driven autonomy,case-based reasoning,multi-agent systems},
pages = {164--178},
title = {{Case-Based Goal-Driven Coordination of Multiple Learning Agents}},
url = {http://link.springer.com/10.1007/978-3-642-39056-2{\_}12},
year = {2013}
}
