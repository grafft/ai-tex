Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{Edelman1987,
address = {New York},
author = {Edelman, G. M.},
pages = {400},
publisher = {Basic Books},
title = {{Neural Darwinism: The Theory Of Neuronal Group Selection}},
year = {1987}
}
@incollection{Cotterill1987,
author = {Cotterill, Rodney M. J.},
booktitle = {Physics in Living Matter},
editor = {Baeriswyl, Dionys and Droz, Michel and Malaspinas, Andreas and Martinoli, Piero},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics in Living Matter/1987/Cotterill - 1987.pdf:pdf},
pages = {138--151},
publisher = {Springer-Verlag},
title = {{Physics of the Brain}},
year = {1987}
}
@article{Chalita2016,
author = {Chalita, Mario Andr{\'{e}}s and Lis, Diego and Caverzasi, Agust{\'{i}}n},
doi = {10.1016/j.bica.2016.03.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Chalita, Lis, Caverzasi - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {reinforcement learning},
pages = {45--63},
title = {{Reinforcement learning in a bio-connectionist model based in the thalamo-cortical neural circuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300159},
year = {2016}
}
@article{Manuscript2014a,
author = {Pfeiffer, Brad E. and Foster, David J.},
doi = {10.1038/nature12112.Hippocampal},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature/2013/Pfeiffer, Foster - 2013.pdf:pdf},
journal = {Nature},
number = {7447},
pages = {74--79},
title = {{Hippocampal place cell sequences depict future paths to remembered goals}},
volume = {497},
year = {2013}
}
@article{Osovec1983,
author = {Осовец, С. М. and Гинзбург, Д. А. and Гурфинкель, В. С. and Зенков, Л. Р. and Латаш, Л. П. and Малкин, В. Б. and Мельничук, П. В. and Пастернак, Е. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1983/Осовец et al. - 1983.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {1},
pages = {103--150},
title = {{Электрическая активность мозга: механизмы и интерпретация}},
volume = {141},
year = {1983}
}
@article{Litvak2009,
abstract = {In this letter, we develop and simulate a large-scale network of spiking neurons that approximates the inference computations performed by graphical models. Unlike previous related schemes, which used sum and product operations in either the log or linear domains, the current model uses an inference scheme based on the sum and maximization operations in the log domain. Simulations show that using these operations, a large-scale circuit, which combines populations of spiking neurons as basic building blocks, is capable of finding close approximations to the full mathematical computations performed by graphical models within a few hundred milliseconds. The circuit is general in the sense that it can be wired for any graph structure, it supports multistate variables, and it uses standard leaky integrate-and-fire neuronal units. Following previous work, which proposed relations between graphical models and the large-scale cortical anatomy, we focus on the cortical microcircuitry and propose how anatomical and physiological aspects of the local circuitry may map onto elements of the graphical model implementation. We discuss in particular the roles of three major types of inhibitory neurons (small fast-spiking basket cells, large layer 2/3 basket cells, and double-bouquet neurons), subpopulations of strongly interconnected neurons with their unique connectivity patterns in different cortical layers, and the possible role of minicolumns in the realization of the population-based maximum operation.},
author = {Litvak, Shai and Ullman, Shimon},
doi = {10.1162/neco.2009.05-08-783},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2009/Litvak, Ullman - 2009.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
number = {11},
pages = {3010--3056},
pmid = {19686065},
title = {{Cortical circuitry implementing graphical models}},
volume = {21},
year = {2009}
}
@article{Stewart2012,
abstract = {We expand our existing spiking neuron model of decision making in the cortex and basal ganglia to include local learning on the synaptic connections between the cortex and striatum, modulated by a dopaminergic reward signal. We then compare this model to animal data in the bandit task, which is used to test rodent learning in conditions involving forced choice under rewards. Our results indicate a good match in terms of both behavioral learning results and spike patterns in the ventral striatum. The model successfully generalizes to learning the utilities of multiple actions, and can learn to choose different actions in different states. The purpose of our model is to provide both high-level behavioral predictions and low-level spike timing predictions while respecting known neurophysiology and neuroanatomy.},
author = {Stewart, Terrence C and Bekolay, Trevor and Eliasmith, Chris},
doi = {10.3389/fnins.2012.00002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Neuroscience/2012/Stewart, Bekolay, Eliasmith - 2012.pdf:pdf},
issn = {1662-4548},
journal = {Frontiers in Neuroscience},
keywords = {Basal ganglia,Neural engineering framework,Reinforcement learning,Two-armed bandit,Ventral striatum},
pages = {2},
pmid = {22319465},
title = {{Learning to Select Actions with Spiking Neurons in the Basal Ganglia}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861903649{\&}partnerID=tZOtx3y1 http://journal.frontiersin.org/article/10.3389/fnins.2012.00002/abstract},
volume = {6},
year = {2012}
}
@inproceedings{Rao2005,
author = {Rao, A. Ravishankar and Cecchi, Guillermo and Peck, Charles and Kozloski, James},
booktitle = {Proc. SPIE},
doi = {10.1117/12.585526},
editor = {Rogowitz, Bernice E. and Pappas, Thrasyvoulos N. and Daly, Scott J.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proc. SPIE/2005/Rao et al. - 2005.pdf:pdf},
issn = {0277786X},
month = {mar},
pages = {17},
title = {{A model of the formation of a self-organized cortical representation of color}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.585526},
year = {2005}
}
@article{George2005,
abstract = {We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1109/IJCNN.2005.1556155},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)/2005/George, Hawkins - 2005.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)},
keywords = {Bayes methods,Bayesian model,Bayesian network structure,anatomical data,belief networks,cortical circuit,cortical phenomena,htm,invariant visual pattern recognition,large scale architecture,learning (artificial intelligence),learning algorithm,micro-circuits,movement pattern,neural nets,object concept,pattern recognition,probability,probability sequence,temporal stability,visual cortex},
mendeley-tags = {htm},
pages = {1812--1817},
pmid = {1556155},
title = {{A hierarchical Bayesian model of invariant pattern recognition in the visual cortex}},
volume = {3},
year = {2005}
}
@unpublished{Shumsky2015a,
author = {Шумский, С. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Шумский - 2015.pdf:pdf},
language = {russian},
pages = {1--31},
title = {{Язык и мозг: как человек понимает речь}},
year = {2015}
}
@inproceedings{Vityaev2012b,
address = {Ростов-на-Дону},
author = {Витяев, Е. Е.},
booktitle = {Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)/2012/Витяев - 2012.pdf:pdf},
language = {russian},
pages = {81--84},
title = {{Формальная модель нейрона, обеспечивающая непротиворечивость предсказаний}},
volume = {2},
year = {2012}
}
@article{Rolls2013,
abstract = {The mechanisms for pattern completion and pattern separation are described in the context of a theory of hippocampal function in which the hippocampal CA3 system operates as a single attractor or autoassociation network to enable rapid, one-trial, associations between any spatial location (place in rodents, or spatial view in primates) and an object or reward, and to provide for completion of the whole memory during recall from any part. The factors important in the pattern completion in CA3 together with a large number of independent memories stored in CA3 include a sparse distributed representation which is enhanced by the graded firing rates of CA3 neurons, representations that are independent due to the randomizing effect of the mossy fibers, heterosynaptic long-term depression as well as long-term potentiation in the recurrent collateral synapses, and diluted connectivity to minimize the number of multiple synapses between any pair of CA3 neurons which otherwise distort the basins of attraction. Recall of information from CA3 is implemented by the entorhinal cortex perforant path synapses to CA3 cells, which in acting as a pattern associator allow some pattern generalization. Pattern separation is performed in the dentate granule cells using competitive learning to convert grid-like entorhinal cortex firing to place-like fields. Pattern separation in CA3, which is important for completion of any one of the stored patterns from a fragment, is provided for by the randomizing effect of the mossy fiber synapses to which neurogenesis may contribute, by the large number of dentate granule cells each with a sparse representation, and by the sparse independent representations in CA3. Recall to the neocortex is achieved by a reverse hierarchical series of pattern association networks implemented by the hippocampo-cortical backprojections, each one of which performs some pattern generalization, to retrieve a complete pattern of cortical firing in higher-order cortical areas.},
author = {Rolls, Edmund T.},
doi = {10.3389/fnsys.2013.00074},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in systems neuroscience/2013/Rolls - 2013.pdf:pdf},
isbn = {1662-5137 (Print)$\backslash$r1662-5137 (Linking)},
issn = {1662-5137},
journal = {Frontiers in systems neuroscience},
keywords = {association network,attractor network,competitive network,episodic memory,hippocampus,hippocampus, pattern separation, pattern completio,pattern,pattern completio,pattern completion,pattern separation,recall},
number = {October},
pages = {74},
pmid = {24198767},
title = {{The mechanisms for pattern completion and pattern separation in the hippocampus}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3812781{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@book{Edelmen1981,
address = {М.},
author = {Эделмен, Дж. and Маунткасл, В.},
editor = {Соколов, Е. Н.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1981/Эделмен, Маунткасл - 1981.pdf:pdf},
language = {russian},
pages = {135},
publisher = {Мир},
title = {{Разумный мозг}},
translator = {Алексеенко, Н. Ю.},
year = {1981}
}
@unpublished{Shumsky2015b,
author = {Шумский, С. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Шумский - 2015(2).pdf:pdf},
language = {russian},
pages = {40},
title = {{Реинжениринг архитектуры мозга: роль и взаимодействие основных подсистем}},
year = {2015}
}
@unpublished{Ahmad,
author = {Ahmad, Subutai and Cui, Yuwei},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Ahmad, Cui - 2015.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--27},
title = {{Annotated Bibliography for HTM Researchers}},
year = {2015}
}
@article{Alexander2011,
abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
author = {Alexander, William H and Brown, Joshua W},
doi = {10.1038/nn.2921},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature neuroscience/2011/Alexander, Brown - 2011.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Brain Mapping,Choice Behavior,Choice Behavior: physiology,Cognition,Cognition: physiology,Computer Simulation,Computer-Assisted,Conflict (Psychology),Humans,Image Processing,Magnetic Resonance Imaging,Models,Movement,Movement: physiology,Neurological,Oxygen,Oxygen: blood,Photic Stimulation,Predictive Value of Tests,Prefrontal Cortex,Prefrontal Cortex: blood supply,Prefrontal Cortex: physiology,Reward,Time Factors,Visual Perception},
number = {10},
pages = {1338--44},
pmid = {21926982},
publisher = {Nature Publishing Group},
title = {{Medial prefrontal cortex as an action-outcome predictor}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3183374{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@article{Rao2004,
abstract = {A large number of human psychophysical results have been successfully explained in recent years using Bayesian models. However, the neural implementation of such models remains largely unclear. In this article, we show that a network architecture commonly used to model the cerebral cortex can implement Bayesian inference for an arbitrary hidden Markov model. We illustrate the approach using an orientation discrimination task and a visual motion detection task. In the case of orientation discrimination, we show that the model network can infer the posterior distribution over orientations and correctly estimate stimulus orientation in the presence of significant noise. In the case of motion detection, we show that the resulting model network exhibits direction selectivity and correctly computes the posterior probabilities over motion direction and position. When used to solve the well-known random dots motion discrimination task, the model generates responses that mimic the activities of evidence-accumulating neurons in cortical areas LIP and FEF. The framework we introduce posits a new interpretation of cortical activities in terms of log posterior probabilities of stimuli occurring in the natural world.},
author = {Rao, Rajesh P N},
doi = {10.1162/08997660460733976},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2004/Rao - 2004.pdf:pdf},
isbn = {08997660460733976},
issn = {0899-7667},
journal = {Neural computation},
number = {1},
pages = {1--38},
pmid = {15006021},
title = {{Bayesian computation in recurrent neural circuits}},
volume = {16},
year = {2004}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature Reviews Neuroscience/2010/Friston - 2010.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {2},
pages = {127--138},
publisher = {Nature Publishing Group},
title = {{The free-energy principle: a unified brain theory?}},
url = {http://www.nature.com/doifinder/10.1038/nrn2787},
volume = {11},
year = {2010}
}
@article{Gurney2001,
abstract = {We present a biologically plausible model of processing intrinsic to the basal ganglia based on the computational premise that action selection is a primary role of these central brain structures. By encoding the propensity for selecting a given action in a scalar value (the salience), it is shown that action selection may be recast in terms of signal selection. The generic properties of signal selection are defined and neural networks for this type of computation examined. A comparison between these networks and basal ganglia anatomy leads to a novel functional decomposition of the basal ganglia architecture into 'selection' and 'control' pathways. The former pathway performs the selection per se via a feedforward off-centre on-surround network. The control pathway regulates the action of the selection pathway to ensure its effective operation, and synergistically complements its dopaminergic modulation. The model contrasts with the prevailing functional segregation of basal ganglia into 'direct' and 'indirect' pathways.},
author = {Gurney, K and Prescott, T J and Redgrave, P},
doi = {10.1007/PL00007984},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biological cybernetics/2001/Gurney, Prescott, Redgrave - 2001.pdf:pdf},
isbn = {0340-1200 (Print)$\backslash$n0340-1200 (Linking)},
issn = {0340-1200},
journal = {Biological cybernetics},
number = {6},
pages = {401--410},
pmid = {11417052},
title = {{A computational model of action selection in the basal ganglia. I. A new functional anatomy}},
volume = {84},
year = {2001}
}
@techreport{Cortical2014,
author = {Hawkins, Jeff and Ahmad, Subutai and Byrne, Fergal and Surpur, Chetan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Hawkins et al. - 2014.pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {62},
title = {{Hierarchical Temporal Memory including HTM Cortical Learning Algorithms}},
url = {numenta.org},
year = {2014}
}
@article{Nekorkon2008,
author = {Некоркин, В. И.},
doi = {10.3367/UFNr.0178.200803f.0313},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2008/Некоркин - 2008.pdf:pdf},
issn = {0042-1294},
journal = {Успехи физических наук},
language = {russian},
number = {3},
pages = {313--323},
title = {{Нейронные колебания и волны в нейродинамике}},
url = {http://ufn.ru/ru/articles/2008/3/f/},
volume = {178},
year = {2008}
}
@unpublished{Project2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02142v1},
author = {Billaudelle, Sebastian and Ahmad, Subutai},
eprint = {arXiv:1505.02142v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Billaudelle, Ahmad - 2015.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--10},
title = {{Porting HTM Models to the Heidelberg Neuromorphic Computing Platform}},
year = {2015}
}
@article{Allgaiera,
author = {Albus, James S.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/International Journal of Machine Consciousness/2010/Albus - 2010.pdf:pdf},
journal = {International Journal of Machine Consciousness},
keywords = {brain,eureqa,fmri,neuroimaging,symbolic regression},
number = {2},
pages = {193--211},
title = {{Reverse Engineering the Brain}},
volume = {2},
year = {2010}
}
@article{Rolls2010,
abstract = {A quantitative computational theory of the operation of the hippocampus as an episodic memory system is described. The CA3 system operates as a single attractor or autoassociation network to enable rapid, one-trial associations between any spatial location (place in rodents or spatial view in primates) and an object or reward and to provide for completion of the whole memory during recall from any part. The theory is extended to associations between time and object or reward to implement temporal order memory, also important in episodic memory. The dentate gyrus performs pattern separation by competitive learning to produce sparse representations, producing for example neurons with place-like fields from entorhinal cortex grid cells. The dentate granule cells produce by the very small number of mossy fibre connections to CA3 a randomizing pattern separation effect important during learning but not recall that separates out the patterns represented by CA3 firing to be very different from each other, which is optimal for an unstructured episodic memory system in which each memory must be kept distinct from other memories. The direct perforant path input to CA3 is quantitatively appropriate to provide the cue for recall in CA3, but not for learning. The CA1 recodes information from CA3 to set up associatively learned backprojections to neocortex to allow subsequent retrieval of information to neocortex, providing a quantitative account of the large number of hippocampo-neocortical and neocortical-neocortical backprojections. Tests of the theory including hippocampal subregion analyses and hippocampal NMDA receptor knockouts are described and support the theory. ?? 2010 Elsevier B.V.},
author = {Rolls, Edmund T.},
doi = {10.1016/j.bbr.2010.03.027},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Behavioural Brain Research/2010/Rolls - 2010.pdf:pdf},
isbn = {0166-4328},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {Attractor network,Competitive network,Completion,Episodic memory,Hippocampus,Object-place memory,Pattern separation,Recall,Spatial view neurons},
number = {2},
pages = {180--196},
pmid = {20307583},
publisher = {Elsevier B.V.},
title = {{A computational theory of episodic memory formation in the hippocampus}},
url = {http://dx.doi.org/10.1016/j.bbr.2010.03.027},
volume = {215},
year = {2010}
}
@article{Acedo2015,
author = {Acedo, L. and Lamprianidou, E. and Mora{\~{n}}o, J.-a. and Villanueva-Oller, J. and Villanueva, R.-J.},
doi = {10.1016/j.physa.2015.05.017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physica A Statistical Mechanics and its Applications/2015/Acedo et al. - 2015.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
language = {english},
pages = {111--119},
publisher = {Elsevier B.V.},
title = {{Firing patterns in a random network cellular automata model of the brain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037843711500432X},
volume = {435},
year = {2015}
}
@incollection{Hepp1987,
author = {Hepp, K. and Henn, V.},
booktitle = {Physics in Living Matter},
editor = {Baeriswyl, Dionys and Droz, Michel and Malaspinas, Andreas and Martinoli, Piero},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics in Living Matter/1987/Hepp, Henn - 1987.pdf:pdf},
pages = {163--177},
title = {{Nonabelian Neurodynamics}},
year = {1987}
}
@techreport{Hawkins2011,
author = {Hawkins, Jeff and Ahmad, Subutai and Dubinsky, Donna},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011(2).pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--68},
title = {{Hiearachical Temporal Memory including HTM Cortical Learning Algorithms}},
year = {2011}
}
@article{Lorincz2015b,
abstract = {Ever since the discovery of columnar structures, their function remained enigmatic. As a potential explanation for this puzzling function, we introduce the 'Columnar Machine'. We join two neural network types, Structured Sparse Coding (SSC) of generative nature exploiting sparse groups of neurons and Feed-Forward Networks (FFNs) into one architecture. Memories supporting recognition can be quickly loaded into SSC via supervision or can be learned by SSC in a self-organized manner. However, SSC evaluation is slow. We train FFNs for predicting the sparse groups and then the representation is computed by fast undercomplete methods. This two step procedure enables fast estimation of the overcomplete group sparse representations. The suggested architecture works fast and it is biologically plausible. Beyond the function of the minicolumnar structure it may shed light onto the role of fast feed-forward inhibitory thalamocortical channels and cortico-cortical feed-back connections. We demonstrate the method for natural image sequences where we exploit temporal structure and for a cognitive task where we explain the meaning of unknown words from their contexts.},
author = {Lorincz, Andras and Milacski, Zoltan and Pinter, Bal{\'{a}}zs and Vero, Anita L.},
doi = {10.1016/j.bica.2015.10.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Lorincz et al. - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Feed-forward inhibition,Minicolumns,Sparsity,Structured representation},
pages = {19--33},
title = {{Columnar Machine: Fast estimation of structured sparse codes}},
volume = {15},
year = {2016}
}
@inproceedings{Ananthanarayanan2009,
author = {Ananthanarayanan, Rajagopal and Esser, Steven K and Simon, Horst D and Modha, Dharmendra S},
booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis/2009/Ananthanarayanan et al. - 2009.pdf:pdf},
number = {c},
pages = {1--12},
title = {{The Cat is Out of the Bag : Cortical Simulations with 10 9 Neurons , 10 13 Synapses}},
year = {2009}
}
@phdthesis{George2008,
author = {George, Dileep},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2008/George - 2008.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
number = {June},
pages = {191},
school = {Stanford University},
title = {{How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition}},
year = {2008}
}
@book{Mountcastle1998,
address = {Cambridge},
author = {Mountcastle, V. B.},
pages = {512},
publisher = {Harvard University Press},
title = {{Perceptual Neuroscience. The Cerebral Cortex}},
year = {1998}
}
@article{Barrera2014,
author = {Barrera, Alejandra and Tejera, Gonzalo and Llofriu, Martin and Weitzenfeld, Alfredo},
doi = {10.1080/13875868.2014.961602},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Spatial Cognition {\&} Computation/2014/Barrera et al. - 2014.pdf:pdf},
issn = {1387-5868},
journal = {Spatial Cognition {\&} Computation},
number = {1},
pages = {27--59},
title = {{Learning Spatial Localization: From Rat Studies to Computational Models of the Hippocampus}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13875868.2014.961602},
volume = {15},
year = {2014}
}
@article{Martin2015,
abstract = {Neurons at early stages of the visual cortex signal elemental features, such as pieces of contour, but how these signals are organized into perceptual objects is unclear. Theories have proposed that spiking synchrony between these neurons encodes how features are grouped (binding-by-synchrony), but recent studies did not find the predicted increase in synchrony with binding. Here we propose that features are grouped to "proto-objects" by intrinsic feedback circuits that enhance the responses of the participating feature neurons. This hypothesis predicts synchrony exclusively between feature neurons that receive feedback from the same grouping circuit. We recorded from neurons in macaque visual cortex and used border-ownership selectivity, an intrinsic property of the neurons, to infer whether or not two neurons are part of the same grouping circuit. We found that binding produced synchrony between same-circuit neurons, but not between other pairs of neurons, as predicted by the grouping hypothesis. In a selective attention task, synchrony emerged with ignored as well as attended objects, and higher synchrony was associated with faster behavioral responses, as would be expected from early grouping mechanisms that provide the structure for object-based processing. Thus, synchrony could be produced by automatic activation of intrinsic grouping circuits. However, the binding-related elevation of synchrony was weak compared with its random fluctuations, arguing against synchrony as a code for binding. In contrast, feedback grouping circuits encode binding by modulating the response strength of related feature neurons. Thus, our results suggest a novel coding mechanism that might underlie the proto-objects of perception.},
author = {Martin, A. B. and von der Heydt, R.},
doi = {10.1523/JNEUROSCI.3590-14.2015},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Neuroscience/2015/Martin, von der Heydt - 2015.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {area v2,attention,binding,figure,ground organization,objects,spike synchrony},
number = {17},
pages = {6860--6870},
pmid = {25926461},
title = {{Spike Synchrony Reveals Emergence of Proto-Objects in Visual Cortex}},
url = {http://www.jneurosci.org/content/35/17/6860.short},
volume = {35},
year = {2015}
}
@article{Chersi2013,
abstract = {Dual-system theories postulate that actions are supported either by a goal-directed or by a habit-driven response system. Neuroimaging and anatomo-functional studies have provided evidence that the prefrontal cortex plays a fundamental role in the first type of action control, while internal brain areas such as the basal ganglia are more active during habitual and overtrained responses. Additionally, it has been shown that areas of the cortex and the basal ganglia are connected through multiple parallel "channels", which are thought to function as an action selection mechanism resolving competitions between alternative options available in a given context. In this paper we propose a multi-layer network of spiking neurons that implements in detail the thalamo-cortical circuits that are believed to be involved in action learning and execution. A key feature of this model is that neurons are organized in small pools in the motor cortex and form independent loops with specific pools of the basal ganglia where inhibitory circuits implement a multistep selection mechanism. The described model has been validated utilizing it to control the actions of a virtual monkey that has to learn to turn on briefly flashing lights by pressing corresponding buttons on a board. When the animal is able to fluently execute the task the button-light associations are remapped so that it has to suppress its habitual behavior in order to execute goal-directed actions. The model nicely shows how sensory-motor associations for action sequences are formed at the cortico-basal ganglia level and how goal-directed decisions may override automatic motor responses.},
author = {Chersi, Fabian and Mirolli, Marco and Pezzulo, Giovanni and Baldassarre, Gianluca},
doi = {10.1016/j.neunet.2012.11.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/2013/Chersi et al. - 2013.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {AMPA,AMPA: physiology,Action Potentials,Action Potentials: physiology,Animals,Basal Ganglia,Basal Ganglia: cytology,Basal Ganglia: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Goals,Habits,Haplorhini,Models,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neurological,Neurons,Neurons: physiology,Neurotransmitter Agents,Neurotransmitter Agents: physiology,Problem Solving,Problem Solving: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Receptors,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Thalamus,Thalamus: cytology,Thalamus: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
pages = {212--24},
pmid = {23266482},
publisher = {Elsevier Ltd},
title = {{A spiking neuron model of the cortico-basal ganglia circuits for goal-directed and habitual action learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23266482},
volume = {41},
year = {2013}
}
@article{Prinz2006,
author = {Prinz, Nwsaa and Butera, Rj},
doi = {10.1007/978-1-4614-0739-3},
editor = {Schultheiss, Nathan W. and Prinz, Astrid A. and Butera, Robert J.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Springer/2006/Prinz, Butera - 2006.pdf:pdf},
isbn = {9781461407386},
issn = {9781461407386},
journal = {Springer},
pages = {33--52},
title = {{Phase Response Curves in Neuroscience}},
url = {http://scholarpedia.org/article/Phase{\_}resetting{\_}curve{\%}5Cnhttp://link.springer.com/content/pdf/10.1007/978-1-4614-0739-3.pdf},
year = {2006}
}
@unpublished{Smith2015,
author = {Smith, J E},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Smith - 2015.pdf:pdf},
pages = {1--82},
title = {{Biologically Plausible Spiking Neural Networks}},
year = {2015}
}
@article{Doya2000a,
abstract = {The classical notion that the basal ganglia and the cerebellum are dedicated to motor control has been challenged by the accumulation of evidence revealing their involvement in non- motor, cognitive functions. From a computational viewpoint, it has been suggested that the cerebellum, the basal ganglia, and the cerebral cortex are specialized for different types of learning: namely, supervised learning, reinforcement learning and unsupervised learning, respectively. This idea of learning- oriented specialization is helpful in understanding the complementary roles of the basal ganglia and the cerebellum in motor control and cognitive functions},
author = {Doya, Kenji},
doi = {10.1016/S0959-4388(00)00153-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2000/Doya - 2000.pdf:pdf},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
pages = {732--739},
pmid = {11240282},
title = {{Complementary roles of basal ganglia and cerebellum in learning and motor control}},
volume = {10},
year = {2000}
}
@book{Aimone2014,
abstract = {The discovery of new cell types, such as grid and time cells, in the hippocampal formation has been accompanied by major anatomical and theoretical insights in the years. This book provides comprehensive, up-to-date information ...},
author = {Aimone, James B and Deng, Wei and Gage, Fred H},
booktitle = {Space, Time and Memory in the Hippocampal Formation},
doi = {10.1007/978-3-7091-1292-2},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Space, Time and Memory in the Hippocampal Formation/2014/Aimone, Deng, Gage - 2014.pdf:pdf},
isbn = {978-3-7091-1291-5},
pages = {409--429},
title = {{Space,Time and Memory in the Hippocampal Formation}},
url = {http://link.springer.com/10.1007/978-3-7091-1292-2},
year = {2014}
}
@article{Pfister2014,
author = {Bauer, Roman and Zubler, Frederic and Pfister, Sabina and Hauri, Andreas and Pfeiffer, Michael and Muir, Dylan R and Douglas, Rodney J},
doi = {10.1371/journal.pcbi.1003994},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLOS Computational Biology/2014/Bauer et al. - 2014.pdf:pdf},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1003994},
title = {{Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks}},
volume = {10},
year = {2014}
}
@article{Felleman1991,
author = {Felleman, D. J. and van Essen, D. C.},
journal = {Cerebral Cortex},
number = {1},
pages = {1--47},
title = {{Distributed hierarchical processing in the primate cerebral cortex}},
volume = {1},
year = {1991}
}
@article{Solovyeva2015,
abstract = {In this work we reveal and explore a new class of attractor neural networks, based on inborn connections provided by model molecular markers, the molecular marker based attractor neural networks (MMBANN). We have explored conditions for the existence of attractor states, critical relations between their parameters and the spectrum of single neuron models, which can implement the MMBANN. Besides, we describe functional models (perceptron and SOM) which obtain significant advantages, while using MMBANN. In particular, the perceptron based on MMBANN, gets specificity gain in orders of error probabilities values, MMBANN SOM obtains real neurophysiological meaning, the number of possible grandma cells increases 1000- fold with MMBANN. Each set of markers has a metric, which is used to make connections between neurons containing the markers. The resulting neural networks have sets of attractor states, which can serve as finite grids for representation of variables in computations. These grids may show dimensions of d = 0, 1, 2,... We work with static and dynamic attractor neural networks of dimensions d = 0 and d = 1. We also argue that the number of dimensions which can be represented by attractors of activities of neural networks with the number of elements N=104 does not exceed 8.},
archivePrefix = {arXiv},
arxivId = {1508.01060},
author = {Solovyeva, Ksenia P and Karandashev, Iakov M and Zhavoronkov, Alex and Dunin-Barkowski, Witali L.},
doi = {10.3389},
eprint = {1508.01060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Front. Syst. Neurosci/2015/Solovyeva et al. - 2015.pdf:pdf},
issn = {1662-5137},
journal = {Front. Syst. Neurosci.},
keywords = {Hopfield networks,bump attractor,cortical column,dynamic attractor,hopfield networks,innate connections,neural networks,self-organizing mapping},
pmid = {26778977},
title = {{Models of Innate Neural Attractors and Their Applications for Neural Information Processing}},
volume = {9},
year = {2015}
}
@article{Sokolov2005,
author = {Соколов, Е. Н. and Незлина, Н. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Журнал высшей нервной деятельности/2005/Соколов, Незлина - 2005.pdf:pdf},
issn = {00444677},
journal = {Журнал высшей нервной деятельности},
language = {russian},
number = {4},
pages = {459--471},
pmid = {16217959},
title = {{Нейродарвинизм: моделирование отбора нейронных групп}},
volume = {55},
year = {2005}
}
@article{VandenHeuvel2013,
abstract = {The human brain shows several characteristics of an efficient communication network architecture, including short communication paths and the existence of modules interlinked by a small set of highly connected regions. Studies of structural networks comprising macroscopic white matter projections have shown that these putative hubs are densely interconnected, giving rise to a spatially distributed and topologically central collective called the “rich club.” In parallel, studies of intrinsic brain activity have consistently revealed distinct functional communities or resting-state networks (RSNs), indicative of specialized processing and segregation of neuronal information. However, the pattern of structural connectivity interconnecting these functional RSNs and how such inter-RSN structural connections might bring about functional integration between RSNs remain largely unknown. Combining high-resolution diffusion weighted imaging with resting-state fMRI, we present novel evidence suggesting that the rich club structure plays a central role in cross-linking macroscopic RSNs of the human brain. Rich club hub nodes were present in all functional networks, accounted for a large proportion of “connector nodes,” and were found to coincide with regions in which multiple networks overlap. In addition, a large proportion of all inter-RSN connections were found to involve rich club nodes, and these connections participated in a disproportionate number of communication paths linking nodes in different RSNs. Our findings suggest that the brain's rich club serves as a macroscopic anatomical substrate to cross-link functional networks and thus plays an important role in the integration of information between segregated functional domains of the human cortex.},
author = {van den Heuvel, M. P. and Sporns, O.},
doi = {10.1523/JNEUROSCI.2128-13.2013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Neuroscience/2013/van den Heuvel, Sporns - 2013.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {36},
pages = {14489--14500},
title = {{An Anatomical Substrate for Integration among Functional Networks in Human Cortex}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2128-13.2013},
volume = {33},
year = {2013}
}
@article{Castejon2016,
author = {Castejon, Carlos and Nu{\~{n}}ez, Angel},
doi = {10.3389/fncir.2016.00081},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Neural Circuits/2016/Castejon, Nu{\~{n}}ez - 2016.pdf:pdf},
journal = {Frontiers in Neural Circuits},
keywords = {brain oscillations,cell ensembles,cerebral cortex,computation,discrete,discrete computation,fast-spiking cells,neural synchronization,processing resolution,sensory processing},
pages = {1--12},
title = {{Cortical Neural Computation by Discrete Results Hypothesis}},
volume = {10},
year = {2016}
}
@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2009/George, Hawkins - 2009.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Markov Chains,Memory,Memory: physiology,Models,Neurological,Pattern Recognition,Pyramidal Cells,Pyramidal Cells: physiology,htm},
mendeley-tags = {htm},
number = {10},
pages = {e1000532},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2749218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Cadieu2014,
abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise, the number of neural recording sites, and the number trials, and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
archivePrefix = {arXiv},
arxivId = {1406.3284},
author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L. K. and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan a. and Majaj, Najib J. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.1003963},
eprint = {1406.3284},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Arxiv/2014/Cadieu et al. - 2014.pdf:pdf},
issn = {15537358},
journal = {Arxiv},
number = {12},
pages = {35},
pmid = {25521294},
title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
url = {http://arxiv.org/abs/1406.3284},
volume = {10},
year = {2014}
}
@inproceedings{Rohrbein2007,
author = {Rohrbein, Florian and Eggert, Julian and Korner, Edgar},
booktitle = {ICCM-2007-Eighth International Conference on Cognitivy Modeling},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ICCM-2007-Eighth International Conference on Cognitivy Modeling/2007/Rohrbein, Eggert, Korner - 2007.pdf:pdf},
keywords = {biologically,columnar-like nodes and do,cortical column,detailed modeling of the,knowledge representation,not target at a,relational structures,single cortical column,the},
pages = {307--312},
title = {{Prototypical Relations for Cortex-Inspired Semantic Representations}},
year = {2007}
}
@incollection{Vityaev1997,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1997/Витяев - 1997.pdf:pdf},
language = {russian},
pages = {9--52},
publisher = {Институт математики им. С.Л. Соболев},
series = {Вычислительные системы},
title = {{Целеполагание как принцип работы мозга}},
year = {1997}
}
@book{Krasnoschekova2007,
address = {СПб.},
author = {Краснощекова, Е. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2007/Краснощекова - 2007.pdf:pdf},
language = {russian},
pages = {130},
publisher = {Издательство СпбГУ},
title = {{Модульная организация нервных центров}},
year = {2007}
}
@article{Albus2010,
abstract = {The brain is first and foremost a control system that is capable of building an internal representation of the external world, and using this representation to make decisions, set goals and priorities, formulate plans, and control behavior with intent to achieve its goals. The internal representation is distributed throughout the brain in two forms: (1) firmware embedded in synaptic connections and axon-dendrite circuitry, and (2) dynamic state-variables encoded in the firing rates of neurons in computational loops in the spinal cord, midbrain, subcortical nuclei, and arrays of cortical columns. It assumes that clusters and arrays of neurons are capable of computing logical predicates, smooth arithmetic functions, and matrix transformations over a space defined by large input vectors and arrays. Feedback from output to input of these neural computational units enable them to function as finite-state-automata (fsa), Markov decision processes (MDP), or delay lines in processing signals and generating strings and grammars. Thus, clusters of neurons are capable of parsing and generating language, decomposing tasks, generating plans, and executing scripts. In the cortex, neurons are arranged in arrays of cortical columns that interact in tight loops with their underlying subcortical nuclei. It is hypothesized that these circuits compute sophisticated mathematical and logical functions that maintain and use complex abstract data structures. It is proposed that cortical hypercolumns together with their underlying thalamic nuclei can be modeled as a cortical computational unit (CCU) consisting of a frame-like data structure (containing attributes and pointers) plus the computational processes and mechanisms required to maintain it and use it for perception cognition, and sensory-motor behavior. In sensory processing areas of the brain, CCU processes enable focus of attention, segmentation, grouping, and classification. Pointers stored in CCU frames define relationships that link pixels and signals to objects and events in situations and episodes. CCU frame pointers also link objects and events to class prototypes and overlay them with meaning and emotional values. In behavior generating areas of the brain, CCU processes make decisions, set goals and priorities, generate plans, and control behavior. In general, CCU pointers are used to define rules, grammars, procedures, plans, and behaviors. CCU pointers also define abstract data structures analogous to lists, frames, objects, classes, rules, plans, and semantic nets. It is suggested that it may be possible to reverse engineer the human brain at the CCU level of fidelity using next-generation massively parallel computer hardware and software.},
author = {Albus, James S.},
doi = {10.1016/j.ins.2009.12.031},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Information Sciences/2010/Albus - 2010.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {Brain modeling,Cognitive modeling,Human neocortex,Image processing,Knowledge representation,Perception,Reverse engineering the brain,Segmentation,Signals to symbols},
number = {9},
pages = {1519--1554},
publisher = {Elsevier Inc.},
title = {{A model of computation and representation in the brain}},
url = {http://dx.doi.org/10.1016/j.ins.2009.12.031},
volume = {180},
year = {2010}
}
@article{Anderson2004,
abstract = {Adaptive control of thought-rational (ACT-R; J. R. Anderson {\&} C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.},
author = {Anderson, John R and Bothell, Daniel and Byrne, Michael D and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
doi = {10.1037/0033-295X.111.4.1036},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychological review/2004/Anderson et al. - 2004.pdf:pdf},
isbn = {ISSN{\~{}}{\~{}}2004-1901},
issn = {0033-295X},
journal = {Psychological review},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {4},
pages = {1036--1060},
pmid = {15482072},
title = {{An integrated theory of the mind}},
volume = {111},
year = {2004}
}
@article{Samborska2016,
author = {Samborska, Veronika and Gordleeva, Susanna and Ullner, Ekkehard and Lebedeva, Albina and Kazantsev, Viktor and Zaikin, Alexey},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Opera Medica {\&} Physiologica/2016/Samborska et al. - 2016.pdf:pdf},
journal = {Opera Medica {\&} Physiologica},
keywords = {complexity,glial-neural,intelligence,network analysis,neural networks,nonlinearity,perceptron},
number = {1},
pages = {23--38},
title = {{Mammalian Brain As a Network of Networks}},
year = {2016}
}
@article{Riesenhuber1999,
author = {Riesenhuber, Maximilian and Poggio, Tomaso},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature Neuroscience/1999/Riesenhuber, Poggio - 1999.pdf:pdf},
journal = {Nature Neuroscience},
number = {11},
pages = {1019--1025},
title = {{Hierarchical models of object recognition in cortex}},
volume = {2},
year = {1999}
}
@article{Goertzel2010,
abstract = {A number of leading cognitive architectures that are inspired by the human brain, at various levels of granularity, are reviewed and compared, with special attention paid to the way their internal structures and dynamics map onto neural processes. Four categories of Biologically Inspired Cognitive Architectures (BICAs) are considered, with multiple examples of each category briefly reviewed, and selected examples discussed in more depth: primarily symbolic architectures (e.g. ACT-R), emergentist architectures (e.g. DeSTIN), developmental robotics architectures (e.g. IM-CLEVER), and our central focus, hybrid architectures (e.g. LIDA, CLARION, 4D/RCS, DUAL, MicroPsi, and OpenCog). Given the state of the art in BICA, it is not yet possible to tell whether emulating the brain on the architectural level is going to be enough to allow rough emulation of brain function; and given the state of the art in neuroscience, it is not yet possible to connect BICAs with large-scale brain simulations in a thoroughgoing way. However, it is nonetheless possible to draw reasonably close function connections between various components of various BICAs and various brain regions and dynamics, and as both BICAs and brain simulations mature, these connections should become richer and may extend further into the domain of internal dynamics as well as overall behavior. ?? 2010 Elsevier B.V.},
author = {Goertzel, Ben and Lian, Ruiting and Arel, Itamar and de Garis, Hugo and Chen, Shuo},
doi = {10.1016/j.neucom.2010.08.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neurocomputing/2010/Goertzel et al. - 2010.pdf:pdf},
isbn = {0925-2312},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Artificial brains,Cognitive architectures},
number = {1-3},
pages = {30--49},
publisher = {Elsevier},
title = {{A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures}},
url = {http://dx.doi.org/10.1016/j.neucom.2010.08.012},
volume = {74},
year = {2010}
}
@incollection{Vityaev1998a,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1998/Витяев - 1998(2).pdf:pdf},
language = {russian},
pages = {3--61},
publisher = {Институт математики им. С.Л. Соболев},
title = {{Формальная модель работы мозга, основанная на принципе предсказания}},
year = {1998}
}
@article{Abarbanel1996,
author = {Абарбанель, Г. Д. И. and Рабинович, М. И. and Селверстон, А. and Баженов, М. В. and Хуэрта, Р. and Сущик, М. М. and Рубчинский, Л. Л.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1996/Абарбанель et al. - 1996.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {4},
pages = {363--390},
title = {{Синхрониазция в нейронных ансамблях}},
volume = {166},
year = {1996}
}
@article{Izhikevich2008,
abstract = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging (DTI) of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic STDP). The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
author = {Izhikevich, Eugene M. and Edelman, Gerald M.},
doi = {10.1073/pnas.0712231105},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/2008/Izhikevich, Edelman - 2008.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Animals,Biological,Brain,Brain: anatomy {\&} histology,Cats,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Computer Simulation,Humans,Mammals,Models,Neurological,Neurons,Synapses,Thalamic Nuclei,Visual Cortex,Visual Cortex: anatomy {\&} histology},
number = {9},
pages = {3593--8},
pmid = {18292226},
title = {{Large-scale model of mammalian thalamocortical systems}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2265160{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2008}
}
@article{Rabinovich2015,
author = {Rabinovich, Mikhail I. and Simmons, Alan N. and Varona, Pablo},
doi = {10.1016/j.tics.2015.06.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2015/Rabinovich, Simmons, Varona - 2015.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {cognitive dynamical principles,competition,functional cognitive networks,robust cognitive processing,sequential stability and winnerless,stable heteroclinic channel,transient brain dynamics},
number = {8},
pages = {453--461},
publisher = {Elsevier Ltd},
title = {{Dynamical bridge between brain and mind}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661315001424},
volume = {19},
year = {2015}
}
@phdthesis{Price2011a,
author = {Price, Ryan William},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011(2).pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {115},
school = {Portland State University},
title = {{Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures}},
year = {2011}
}
@article{Markram2015,
abstract = {We present a first-draft digital reconstruction of the microcircuitry of somatosensory cortex of juvenile rat. The reconstruction uses cellular and synaptic organizing principles to algorithmically reconstruct detailed anatomy and physiology from sparse experimental data. An objective anatomical method defines a neocortical volume of 0.29 ± 0.01 mm3 containing ∼31,000 neurons, and patch-clamp studies identify 55 layer-specific morphological and 207 morpho-electrical neuron subtypes. When digitally reconstructed neurons are positioned in the volume and synapse formation is restricted to biological bouton densities and numbers of synapses per connection, their overlapping arbors form ∼8 million connections with ∼37 million synapses. Simulations reproduce an array of in vitro and in vivo experiments without parameter tuning. Additionally, we find a spectrum of network states with a sharp transition from synchronous to asynchronous activity, modulated by physiological mechanisms. The spectrum of network states, dynamically reconfigured around this transition, supports diverse information processing strategies. PaperClip Video Abstract},
author = {Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael W. and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Kahou, Guy Antoine Atenekeng and Berger, Thomas K. and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean Denis and Delalondre, Fabien and Delattre, Vincent and Druckmann, Shaul and Dumusc, Raphael and Dynes, James and Eilemann, Stefan and Gal, Eyal and Gevaert, Michael Emiel and Ghobril, Jean Pierre and Gidon, Albert and Graham, Joe W. and Gupta, Anirudh and Haenel, Valentin and Hay, Etay and Heinis, Thomas and Hernando, Juan B. and Hines, Michael and Kanari, Lida and Keller, Daniel and Kenyon, John and Khazen, Georges and Kim, Yihwa and King, James G. and Kisvarday, Zoltan and Kumbhar, Pramod and Lasserre, S{\'{e}}bastien and {Le B{\'{e}}}, Jean Vincent and Magalh{\~{a}}es, Bruno R C and Merch{\'{a}}n-P{\'{e}}rez, Angel and Meystre, Julie and Morrice, Benjamin Roy and Muller, Jeffrey and Mu{\~{n}}oz-C{\'{e}}spedes, Alberto and Muralidhar, Shruti and Muthurasa, Keerthan and Nachbaur, Daniel and Newton, Taylor H. and Nolte, Max and Ovcharenko, Aleksandr and Palacios, Juan and Pastor, Luis and Perin, Rodrigo and Ranjan, Rajnish and Riachi, Imad and Rodr{\'{i}}guez, Jos{\'{e}} Rodrigo and Riquelme, Juan Luis and R{\"{o}}ssert, Christian and Sfyrakis, Konstantinos and Shi, Ying and Shillcock, Julian C. and Silberberg, Gilad and Silva, Ricardo and Tauheed, Farhan and Telefont, Martin and Toledo-Rodriguez, Maria and Tr{\"{a}}nkler, Thomas and {Van Geit}, Werner and D{\'{i}}az, Jafet Villafranca and Walker, Richard and Wang, Yun and Zaninetta, Stefano M. and Defelipe, Javier and Hill, Sean L. and Segev, Idan and Sch{\"{u}}rmann, Felix},
doi = {10.1016/j.cell.2015.09.029},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cell/2015/Markram et al. - 2015.pdf:pdf},
isbn = {1097-4172 (Electronic)$\backslash$r0092-8674 (Linking)},
issn = {10974172},
journal = {Cell},
number = {2},
pages = {456--492},
pmid = {26451489},
title = {{Reconstruction and Simulation of Neocortical Microcircuitry}},
volume = {163},
year = {2015}
}
@article{Anderson2010,
abstract = {An emerging class of theories concerning the functional structure of the brain takes the reuse of neural circuitry for various cognitive purposes to be a central organizational principle. According to these theories, it is quite common for neural circuits established for one purpose to be exapted (exploited, recycled, redeployed) during evolution or normal development, and be put to different uses, often without losing their original functions. Neural reuse theories thus differ from the usual understanding of the role of neural plasticity (which is, after all, a kind of reuse) in brain organization along the following lines: According to neural reuse, circuits can continue to acquire new uses after an initial or original function is established; the acquisition of new uses need not involve unusual circumstances such as injury or loss of established function; and the acquisition of a new use need not involve (much) local change to circuit structure (e.g., it might involve only the establishment of functional connections to new neural partners). Thus, neural reuse theories offer a distinct perspective on several topics of general interest, such as: the evolution and development of the brain, including (for instance) the evolutionary-developmental pathway supporting primate tool use and human language; the degree of modularity in brain organization; the degree of localization of cognitive function; and the cortical parcellation problem and the prospects (and proper methods to employ) for function to structure mapping. The idea also has some practical implications in the areas of rehabilitative medicine and machine interface design.},
author = {Anderson, Michael L.},
doi = {10.1017/S0140525X10000853},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The Behavioral and brain sciences/2010/Anderson - 2010.pdf:pdf},
issn = {1469-1825},
journal = {The Behavioral and brain sciences},
keywords = {Animals,Biological Evolution,Brain,Brain Mapping,Brain: anatomy {\&} histology,Brain: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Cognitive Science,Higher Nervous Activity,Higher Nervous Activity: physiology,Humans,Language,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Primates},
number = {4},
pages = {245--66},
pmid = {20964882},
title = {{Neural reuse: a fundamental organizational principle of the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20964882},
volume = {33},
year = {2010}
}
@article{Eliasmith2014,
abstract = {We provide an overview and comparison of several recent large-scale brain models. In addition to discussing challenges involved with building large neural models, we identify several expected benefits of pursuing such a research program. We argue that these benefits are only likely to be realized if two basic guidelines are made central to the pursuit. The first is that such models need to be intimately tied to behavior. The second is that models, and more importantly their underlying methods, should provide mechanisms for varying the level of simulated detail. Consequently, we express concerns with models that insist on a 'correct' amount of detail while expecting interesting behavior to simply emerge. ?? 2013 Elsevier Ltd.},
author = {Eliasmith, Chris and Trujillo, Oliver},
doi = {10.1016/j.conb.2013.09.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2014/Eliasmith, Trujillo - 2014.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
pages = {1--6},
pmid = {24709593},
publisher = {Elsevier Ltd},
title = {{The use and abuse of large-scale brain models}},
url = {http://dx.doi.org/10.1016/j.conb.2013.09.009},
volume = {25},
year = {2014}
}
@article{Ivanitsky1994,
author = {Иваницкий, Г. Р. and Медвинский, А. Б. and Цыганов, М. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1994/Иваницкий, Медвинский, Цыганов - 1994.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1041--1072},
title = {{От динамики популяционных автоволн, формируемых живыми клетками, к нейроинформатике}},
volume = {164},
year = {1994}
}
@misc{Bialek2002,
abstract = {We all are fascinated by the phenomena of intelligent behavior, as generated both by our own brains and by the brains of other animals. As physicists we would like to understand if there are some general principles that govern the structure and dynamics of the neural circuits that underlie these phenomena. At the molecular level there is an extraordinary universality, but these mechanisms are surprisingly complex. This raises the question of how the brain selects from these diverse mechanisms and adapts to compute "the right thing" in each context. One approach is to ask what problems the brain really solves. There are several examples - from the ability of the visual system to count photons on a dark night to our gestalt recognition of statistical tendencies toward symmetry in random patterns - where the performance of the system in fact approaches some fundamental physical or statistical limits. This suggests that some sort of optimization principles may be at work, and there are examples where these principles have been formulated clearly and generated predictions which are confirmed in new experiments; a central theme in this work is the matching of the coding and computational strategies of the brain to the statistical structure of the world around us. Extension of these principles to the problem of learning leads us into interesting theoretical questions about how to measure the complexity of the data from which we learn and the complexity of the models that we use in learning, as well as opening some new opportunities for experiment. This combination of theoretical and experimental work gives us some new (if still speculative) perspectives on classical problems and controversies in cognition.},
archivePrefix = {arXiv},
arxivId = {physics/0205030},
author = {Bialek, William},
booktitle = {http://arxiv.org/abs/physics/0205030},
eprint = {0205030},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/httparxiv.orgabsphysics0205030/2002/Bialek - 2002.pdf:pdf},
number = {July 2001},
pages = {1--85},
primaryClass = {physics},
title = {{Thinking about the brain}},
url = {http://arxiv.org/abs/physics/0205030},
urldate = {2014-09-27},
year = {2002}
}
@article{Corbetta2008,
abstract = {Survival can depend on the ability to change a current course of action to respond to potentially advantageous or threatening stimuli. This "reorienting" response involves the coordinated action of a right hemisphere dominant ventral frontoparietal network that interrupts and resets ongoing activity and a dorsal frontoparietal network specialized for selecting and linking stimuli and responses. At rest, each network is distinct and internally correlated, but when attention is focused, the ventral network is suppressed to prevent reorienting to distracting events. These different patterns of recruitment may reflect inputs to the ventral attention network from the locus coeruleus/norepinephrine system. While originally conceptualized as a system for redirecting attention from one object to another, recent evidence suggests a more general role in switching between networks, which may explain recent evidence of its involvement in functions such as social cognition.},
author = {Corbetta, Maurizio and Patel, Gaurav and Shulman, Gordon L},
doi = {10.1016/j.neuron.2008.04.017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2008/Corbetta, Patel, Shulman - 2008.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Attention,Attention: physiology,Brain,Brain: physiology,Cognition,Cognition: physiology,Environment,Humans,Nerve Net,Nerve Net: physiology,Orientation,Orientation: physiology},
number = {3},
pages = {306--24},
pmid = {18466742},
title = {{The reorienting system of the human brain: from environment to theory of mind}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2441869{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {58},
year = {2008}
}
@article{Coward2014,
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.},
author = {Coward, L. Andrew},
doi = {10.1016/j.procs.2014.11.100},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Procedia Computer Science/2014/Coward - 2014.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {NeuroModels},
mendeley-tags = {NeuroModels},
pages = {164--175},
title = {{Brain Computational Primitives}},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914015452},
volume = {41},
year = {2014}
}
@incollection{Kawato2009,
author = {Kawato, M.},
booktitle = {Encyclopedia of Neuroscience},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Encyclopedia of Neuroscience/2009/Kawato - 2009.pdf:pdf},
pages = {757--767},
title = {{Cerebellum: Models}},
volume = {2},
year = {2009}
}
@article{Holtmaat2009,
abstract = {Synaptic plasticity in adult neural circuits may involve the strengthening or weakening of existing synapses as well as structural plasticity, including synapse formation and elimination. Indeed, long-term in vivo imaging studies are beginning to reveal the structural dynamics of neocortical neurons in the normal and injured adult brain. Although the overall cell-specific morphology of axons and dendrites, as well as of a subpopulation of small synaptic structures, are remarkably stable, there is increasing evidence that experience-dependent plasticity of specific circuits in the somatosensory and visual cortex involves cell type-specific structural plasticity: some boutons and dendritic spines appear and disappear, accompanied by synapse formation and elimination, respectively. This Review focuses on recent evidence for such structural forms of synaptic plasticity in the mammalian cortex and outlines open questions.},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Holtmaat, Anthony and Svoboda, Karel},
doi = {10.1038/nrn2721},
eprint = {1309.2848v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature reviews. Neuroscience/2009/Holtmaat, Svoboda - 2009.pdf:pdf},
isbn = {1471-0048},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
number = {9},
pages = {647--658},
pmid = {19693029},
title = {{Experience-dependent structural synaptic plasticity in the mammalian brain.}},
volume = {10},
year = {2009}
}
@article{Gallese1996,
author = {Gallese, Vittorio and Fadiga, Luciano and Fogassi, Leonardo and Rizzolatti, Giacomo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Brain/1996/Gallese et al. - 1996.pdf:pdf},
journal = {Brain},
keywords = {action encoding,macaque monkey,premotor cortex,visual responses},
number = {5},
pages = {593--609},
title = {{Action recognition in the premotor cortex}},
volume = {119},
year = {1996}
}
@incollection{Vityaev1998,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1998/Витяев - 1998.pdf:pdf},
language = {russian},
pages = {14--40},
publisher = {Институт математики им. С.Л. Соболев},
series = {Вычислительные системы},
title = {{Вероятностное прогнозирование и предсказание как принцип работы мозга}},
year = {1998}
}
@article{Tetzlaff2013,
abstract = {Memory storage in the brain relies on mechanisms acting on time scales from minutes, for long-term synaptic potentiation, to days, for memory consolidation. During such processes, neural circuits distinguish synapses relevant for forming a long-term storage, which are consolidated, from synapses of short-term storage, which fade. How time scale integration and synaptic differentiation is simultaneously achieved remains unclear. Here we show that synaptic scaling - a slow process usually associated with the maintenance of activity homeostasis - combined with synaptic plasticity may simultaneously achieve both, thereby providing a natural separation of short- from long-term storage. The interaction between plasticity and scaling provides also an explanation for an established paradox where memory consolidation critically depends on the exact order of learning and recall. These results indicate that scaling may be fundamental for stabilizing memories, providing a dynamic link between early and late memory formation processes.},
author = {Tetzlaff, Christian and Kolodziejski, Christoph and Timme, Marc and Tsodyks, Misha and W{\"{o}}rg{\"{o}}tter, Florentin},
doi = {10.1371/journal.pcbi.1003307},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2013/Tetzlaff et al. - 2013.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,Long-Term,Long-Term: physiology,Memory,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Short-Term,Short-Term: physiology,Synapses,Synapses: physiology},
number = {10},
pages = {e1003307},
pmid = {24204240},
title = {{Synaptic scaling enables dynamically distinct short- and long-term memory formation}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3814677{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2013}
}
@article{John2013,
abstract = {The classical dichotomy between cognition and emotion equated the first with rationality or logic and the second with irrational behaviors. The idea that cognition and emotion are separable, antagonistic forces competing for dominance of mind has been hard to displace despite abundant evidence to the contrary. For instance, it is now known that a pathological absence of emotion leads to profound impairment of decision making. Behavioral observations of this kind are corroborated at the mechanistic level: neuroanatomical studies reveal that brain areas typically described as underlying either cognitive or emotional processes are linked in ways that imply complex interactions that do not resemble a simple mutual antagonism. Instead, physiological studies and network simulations suggest that top-down signals from prefrontal cortex realize "cognitive control" in part by either suppressing or promoting emotional responses controlled by the amygdala, in a way that facilitates adaptation to changing task demands. Behavioral, anatomical, and physiological data suggest that emotion and cognition are equal partners in enabling a continuum or matrix of flexible behaviors that are subserved by multiple brain regions acting in concert. Here we focus on neuroanatomical data that highlight circuitry that structures cognitive-emotional interactions by directly or indirectly linking prefrontal areas with the amygdala. We also present an initial computational circuit model, based on anatomical, physiological, and behavioral data to explicitly frame the learning and performance mechanisms by which cognition and emotion interact to achieve flexible behavior.},
author = {John, Yohan J and Bullock, Daniel and Zikopoulos, Basilis and Barbas, Helen},
doi = {10.3389/fnhum.2013.00101},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in human neuroscience/2013/John et al. - 2013.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {1,amygdala,cognition,cognition into adaptive perception-action,computational neuroscience,emotions,integrating emotion and,introduction,network,neural,neuroanatomy,ofc,orbitofrontal cortex,orbitofrontal cortex (OFC),thalamic ret,thalamic reticular nucleus},
number = {April},
pages = {101},
pmid = {23565082},
title = {{Anatomy and computational modeling of networks underlying cognitive-emotional interaction}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3613599{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Brown2015,
author = {Brown, T I and Carr, V A and LaRocque, K F and Favila, S E and Gordon, A M and Bowles, B and Wagner, A D},
doi = {10.1126/science.aaf0784},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Science/2015/Brown et al. - 2015.pdf:pdf},
issn = {0036-8075},
journal = {Science},
number = {6291},
pages = {1323--1326},
pmid = {27284194},
title = {{Prospective representation of navigational goals in the human hippocampus}},
volume = {352},
year = {2015}
}
@inproceedings{Dura-Bernal2011,
author = {Dura-Bernal, Salvador and Wennekers, Thomas and Denham, Susan L.},
booktitle = {45th Annual Conference on Information Sciences and Systems},
doi = {10.1109/CISS.2011.5766096},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/45th Annual Conference on Information Sciences and Systems/2011/Dura-Bernal, Wennekers, Denham - 2011.pdf:pdf},
isbn = {978-1-4244-9846-8},
keywords = {bayesian belief propagation,hierarchical percep-},
pages = {1--6},
publisher = {IEEE},
title = {{Modelling object perception in cortex: Hierarchical Bayesian networks and belief propagation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5766096},
year = {2011}
}
@article{Roland2010,
abstract = {A fundamental goal in vision science is to determine how many neurons in how many areas are required to compute a coherent interpretation of the visual scene. Here I propose six principles of cortical dynamics of visual processing in the first 150 ms following the appearance of a visual stimulus. Fast synaptic communication between neurons depends on the driving neurons and the biophysical history and driving forces of the target neurons. Under these constraints, the retina communicates changes in the field of view driving large populations of neurons in visual areas into a dynamic sequence of feed-forward communication and integration of the inward current of the change signal into the dendrites of higher order area neurons (30-70 ms). Simultaneously an even larger number of neurons within each area receiving feed-forward input are pre-excited to sub-threshold levels. The higher order area neurons communicate the results of their computations as feedback adding inward current to the excited and pre-excited neurons in lower areas. This feedback reconciles computational differences between higher and lower areas (75-120 ms). This brings the lower area neurons into a new dynamic regime characterized by reduced driving forces and sparse firing reflecting the visual areas interpretation of the current scene (140 ms). The population membrane potentials and net-inward/outward currents and firing are well behaved at the mesoscopic scale, such that the decoding in retinotopic cortical space shows the visual areas' interpretation of the current scene. These dynamics have plausible biophysical explanations. The principles are theoretical, predictive, supported by recent experiments and easily lend themselves to experimental tests or computational modeling.},
author = {Roland, Per E},
doi = {10.3389/fnsys.2010.00028},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Systems Neuroscience/2010/Roland - 2010.pdf:pdf},
isbn = {ISSN 1662-5137},
issn = {16625137},
journal = {Frontiers in Systems Neuroscience},
keywords = {coher-,cortical theory,ent view of cortical,failed to give a,feedback,functions and visual perception,inter-area communication,laminar firing,may be both,membrane potential,object motion,object vision,scientists so far have,the reasons that visual,voltage-sensitive dyes},
pages = {28},
pmid = {20661451},
title = {{Six principles of visual cortical dynamics}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2010.00028/abstract},
volume = {4},
year = {2010}
}
@article{Lochmann2011,
abstract = {Perception is about making sense, that is, understanding what events in the outside world caused the sensory observations. Consistent with this intuition, many aspects of human behavior confronting noise and ambiguity are well explained by principles of causal inference. Extending these insights, recent studies have applied the same powerful set of tools to perceptual processing at the neural level. According to these approaches, microscopic neural structures solve elementary probabilistic tasks and can be combined to construct hierarchical predictive models of the sensory input. This framework suggests that variability in neural responses reflects the inherent uncertainty associated with sensory interpretations and that sensory neurons are active predictors rather than passive filters of their inputs. Causal inference can account parsimoniously and quantitatively for non-linear dynamical properties in single synapses, single neurons and sensory receptive fields.},
author = {Lochmann, Timm and Deneve, Sophie},
doi = {10.1016/j.conb.2011.05.018},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current opinion in neurobiology/2011/Lochmann, Deneve - 2011.pdf:pdf},
issn = {1873-6882},
journal = {Current opinion in neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Concept Formation,Concept Formation: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Perception,Perception: physiology,Probability,Sensation,Sensory Receptor Cells,Sensory Receptor Cells: physiology},
number = {5},
pages = {774--81},
pmid = {21742484},
publisher = {Elsevier Ltd},
title = {{Neural processing as causal inference}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21742484},
volume = {21},
year = {2011}
}
@article{Borisuk2002,
author = {Борисюк, Г. Н. and Борисюк, Р. М. and Казанович, Я. Б. and Иваницкий, Г. Р.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2002/Борисюк et al. - 2002.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1189--1214},
title = {{Модели динамики нейронной активности при обработке информации мозгом - итоги ``десятилетия''}},
volume = {170},
year = {2002}
}
@article{Rinkus2010,
abstract = {No generic function for the minicolumn - i.e., one that would apply equally well to all cortical areas and species - has yet been proposed. I propose that the minicolumn does have a generic functionality, which only becomes clear when seen in the context of the function of the higher-level, subsuming unit, the macrocolumn. I propose that: (a) a macrocolumn's function is to store sparse distributed representations of its inputs and to be a recognizer of those inputs; and (b) the generic function of the minicolumn is to enforce macrocolumnar code sparseness. The minicolumn, defined here as a physically localized pool of approximately 20 L2/3 pyramidals, does this by acting as a winner-take-all (WTA) competitive module, implying that macrocolumnar codes consist of approximately 70 active L2/3 cells, assuming approximately 70 minicolumns per macrocolumn. I describe an algorithm for activating these codes during both learning and retrievals, which causes more similar inputs to map to more highly intersecting codes, a property which yields ultra-fast (immediate, first-shot) storage and retrieval. The algorithm achieves this by adding an amount of randomness (noise) into the code selection process, which is inversely proportional to an input's familiarity. I propose a possible mapping of the algorithm onto cortical circuitry, and adduce evidence for a neuromodulatory implementation of this familiarity-contingent noise mechanism. The model is distinguished from other recent columnar cortical circuit models in proposing a generic minicolumnar function in which a group of cells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of the sparse distributed macrocolumnar code.},
author = {Rinkus, Gerard J},
doi = {10.3389/fnana.2010.00017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroanatomy/2010/Rinkus - 2010.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in neuroanatomy},
keywords = {NeuroModels,learning,macrocolumn,memory,minicolumn,novelty detection,population coding,sparse distributed representations,winner-take-all},
mendeley-tags = {NeuroModels},
number = {June},
pages = {17},
pmid = {20577587},
title = {{A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2889687{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
