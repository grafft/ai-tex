Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@incollection{Munoz-Avila2010,
author = {Mu{\~{n}}oz-Avila, H{\'{e}}ctor and Jaidee, Ulit and Aha, David W and Carter, Elizabeth},
booktitle = {Case-Based Reasoning},
doi = {10.1007/978-3-642-14274-1_18},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mu{\~{n}}oz-Avila et al/2010/Goal-Driven Autonomy with Case-Based Reasoning.pdf:pdf},
pages = {228--241},
title = {{Goal-Driven Autonomy with Case-Based Reasoning}},
url = {http://link.springer.com/10.1007/978-3-642-14274-1{\_}18},
year = {2010}
}
@inproceedings{Karlsson2012,
abstract = {The ability to perform both causal (means-end) and geometric reasoning is important in order to achieve au- tonomy for advanced robotic systems. In this paper, we describe work in progress on planning for a humanoid two-arm robotic system where task and path planning capabilities have been integrated into a coherent planning framework. We address a number of challenges of integrating combined task and path planning with the complete robotic system, in particular concerning perception and execution. Geometric backtracking is considered: this is the process of revisiting geometric choices (grasps, positions etc.) in previous actions in order to be able to satisfy the geometric preconditions of the action presently under consideration of the planner. We argue that geometric backtracking is required for resolution completeness. Our approach is demon- strated on a real robotic platform, Justin at DLR, and in a simulation of the same robot. In the latter, we consider the consequences of geometric backtracking.},
author = {Karlsson, Lars and Bidot, Julien and Lagriffoul, Fabien and Saffiotti, Alessandro and Hillenbrand, Ulrich and Schmidt, Florian},
booktitle = {TAMPRA 2012: Proceedings of the Workshop on Combining Task and Motion Planning for Real-World Applications},
editor = {Cirillo, Marcello and Gerkey, Brian and Pecora, Federico and Stilman, Mike},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Karlsson et al/2012/Combining Task and Path Planning for a Humanoid Two-arm Robotic System.pdf:pdf},
keywords = {plan},
mendeley-tags = {plan},
pages = {13--20},
title = {{Combining Task and Path Planning for a Humanoid Two-arm Robotic System}},
year = {2012}
}
@article{Hendler1990,
abstract = {This article reviews research in the development of plan generation systems. Our goal is to familiarize the reader with some of the important problems that have arisen in the design of planning systems and to discuss some of the many solutions that have been developed in the over 30 years of research in this area. In this article, we broadly cover the major ideas in the field of AI planning and show the direction in which some current research is going. We define some of the terms commonly used in the planning literature, describe some of the basic issues coming from the design of planning systems, and survey results in the area. Because such tasks are virtually never ending, and thus, any finite document must be incomplete, we provide references to connect each idea to the appropriate literature and allow readers access to the work most relevant to their own research or applications.},
author = {Hendler, James a. and Tate, Austin and Drummond, Mark},
doi = {10.1609/aimag.v11i2.833},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hendler, Tate, Drummond/1990/AI Planning Systems and Techniques.pdf:pdf},
isbn = {0738-4602},
issn = {0738-4602},
journal = {AI Magazine},
keywords = {plan,planning},
mendeley-tags = {plan},
number = {2},
pages = {61--77},
title = {{AI Planning: Systems and Techniques}},
url = {http://aaaipress.org/ojs/index.php/aimagazine/article/view/833},
volume = {11},
year = {1990}
}
@article{Fox2003a,
abstract = {In recent years research in the planning community has moved increasingly toward s application of planners to realistic problems involving both time and many typ es of resources. For example, interest in planning demonstrated by the space res earch community has inspired work in observation scheduling, planetary rover ex ploration and spacecraft control domains. Other temporal and resource-intensive domains including logistics planning, plant control and manufacturing have also helped to focus the community on the modelling and reasoning issues that must be confronted to make planning technology meet the challenges of application. The International Planning Competitions have acted as an important motivating fo rce behind the progress that has been made in planning since 1998. The third com petition (held in 2002) set the planning community the challenge of handling tim e and numeric resources. This necessitated the development of a modelling langua ge capable of expressing temporal and numeric properties of planning domains. In this paper we describe the language, PDDL2.1, that was used in the competition. We describe the syntax of the language, its formal semantics and the validation of concurrent plans. We observe that PDDL2.1 has considerable modelling power --- exceeding the capabilities of current planning technology --- and presents a number of important challenges to the research community.},
archivePrefix = {arXiv},
arxivId = {1106.4561},
author = {Fox, Maria and Long, Derek},
doi = {10.1613/jair.1129},
eprint = {1106.4561},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fox, Long/2003/PDDL2.1 An extension to PDDL for expressing temporal planning domains.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {61--124},
title = {{PDDL2.1: An extension to PDDL for expressing temporal planning domains}},
volume = {20},
year = {2003}
}
@article{Mizraji2015,
abstract = {We organize our behavior and store structured information with many procedures that require the coding of spatial and temporal order in specific neural modules. In the simplest cases, spatial and temporal relations are condensed in prepositions like “below” and “above”, “behind” and “in front of”, or “before” and “after”, etc. Neural operators lie beneath these words, sharing some similarities with logical gates that compute spatial and temporal asymmetric relations. We show how these operators can be modeled by means of neural matrix memories acting on Kronecker tensor products of vectors. The complexity of these memories is further enhanced by their ability to store episodes unfolding in space and time. How does the brain scale up from the raw plasticity of contingent episodic memories to the apparent stable connectivity of large neural networks? We clarify this transition by analyzing a model that flexibly codes episodic spatial and temporal structures into contextual markers capable of linking different memory modules.},
author = {Mizraji, Eduardo and Lin, Juan},
doi = {10.1007/s11571-015-9343-3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mizraji, Lin/2015/Modeling spatial–temporal operations with context-dependent associative memories.pdf:pdf},
isbn = {1157101593},
issn = {1871-4080},
journal = {Cognitive Neurodynamics},
keywords = {Cognitive order relations,Context-dependent associative memories,Hierarchical models,Neural computation},
number = {5},
pages = {523--534},
publisher = {Springer Netherlands},
title = {{Modeling spatial–temporal operations with context-dependent associative memories}},
url = {http://link.springer.com/10.1007/s11571-015-9343-3},
volume = {9},
year = {2015}
}
@article{Bergmann1996,
author = {Bergmann, Ralph and Wilke, Wolfgang},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bergmann, Wilke/1996/PARIS Flexible Plan Adaptation by Abstraction and Re nement.pdf:pdf},
journal = {Proceedings of the Workshop on Adaptation in Case-Based Reasoning, ECAI'96},
keywords = {plan},
mendeley-tags = {plan},
title = {{PARIS: Flexible Plan Adaptation by Abstraction and Re nement}},
year = {1996}
}
@article{Bai2013,
abstract = {When a robot uses an imperfect system model to plan its actions, a key challenge is the exploration-exploitation trade-off between two sometimes conflicting objectives: (i) learning and improving the model, and (ii) immediate progress towards the goal, according to the current model. To address model uncertainty systematically, we propose to use Bayesian reinforcement learning and cast it as a partially observable Markov decision process (POMDP). We present a simple algorithm for offline POMDP planning in the continuous state space. Offline planning produces a POMDP policy, which can be executed efficiently online as a finite-state controller. This approach seamlessly integrates planning and learning: it incorporates learning objectives in the computed plan, which then enables the robot to learn nearly optimally online and reach the goal. We evaluated the approach in simulations on two distinct tasks, acrobot swing-up and autonomous vehicle navigation amidst pedestrians, and obtained interesting preliminary results.},
author = {Bai, Haoyu and Hsu, David and Lee, Wee Sun},
doi = {10.1109/ICRA.2013.6630972},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bai, Hsu, Lee/2013/Planning how to learn.pdf:pdf},
isbn = {9781467356411},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {2853--2859},
title = {{Planning how to learn}},
year = {2013}
}
@inproceedings{Pratama2014,
abstract = {Uncertainty is one of the most difficult factors to handle when we wish to develop an algorithm for robot motion planning in real circumstances. This paper presents a solution for a robot to deal with “lack of observation” in the scope of object manipulation. Considering a robotic bartender that picks up a glass filled with an unknown amount of water and tilts it to pour the water into empty glasses, the question is how to find the angle at which the giver glass is tilted to pour the water to the same level in each of empty receiver glasses. To achieve the objective, the amount of water poured is represented with mathematical models of non-linear functions, and numerical simulations are performed using the point-based value iteration algorithm for POMDP to get corresponding tilting angles of the giver glass. We found that the experimental result accuracy reaches 99.025{\%} of similarity with the assumed mathematical model, given an initial tilting angle and the water level in the initial glass. We further verified the validity of the proposed algorithm through dynamic simulations.},
author = {Pratama, Ferdian and Jeong, Sungmoon and Chong, Nak Young},
booktitle = {The 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI 2014)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Pratama, Jeong, Chong/2014/Learning Manipulative Skills Using a POMDP Framework.pdf:pdf},
isbn = {9781479953332},
keywords = {adaptive systems,dextrous manipulations,learning behavior,plan},
mendeley-tags = {plan},
pages = {169--175},
title = {{Learning Manipulative Skills Using a POMDP Framework}},
year = {2014}
}
@article{Yoon2008,
abstract = {A number of today's state-of-the-art planners are based on forward state-space search. The im- pressive performance can be attributed to progress in computing domain independent heuristics that perform well across many domains. However, it is easy to find domains where such heuristics provide poor guidance, leading to planning failure. Motivated by such failures, the focus of this pa- per is to investigate mechanisms for learning domain-specific knowledge to better control forward search in a given domain. While there has been a large body of work on inductive learning of con- trol knowledge for AI planning, there is a void of work aimed at forward-state-space search. One reason for this may be that it is challenging to specify a knowledge representation for compactly representing important concepts across a wide range of domains. One of the main contributions of this work is to introduce a novel feature space for representing such control knowledge. The key idea is to define features in terms of information computed via relaxed plan extraction, which has been a major source of success for non-learning planners. This gives a new way of leverag- ing relaxed planning techniques in the context of learning. Using this feature space, we describe three forms of control knowledge—reactive policies (decision list rules and measures of progress) and linear heuristics—and show how to learn them and incorporate them into forward state-space search. Our empirical results show that our approaches are able to surpass state-of-the-art non- learning planners across a wide range of planning competition domains.},
author = {Yoon, Sungwook and Fern, A and Givan, R},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Yoon, Fern, Givan/2008/Learning control knowledge for forward search planning.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {The Journal of Machine Learning Research},
keywords = {knowledge representation,machine learning,planning,search},
pages = {683--718},
title = {{Learning control knowledge for forward search planning}},
url = {http://dl.acm.org/citation.cfm?id=1390705},
volume = {9},
year = {2008}
}
@article{Cox2017a,
abstract = {Cognitive agents operating in complex and dynamic domains benefit from significant goal management. Operations on goals include formulation, selection, change, monitoring and delegation in addition to goal achievement. Here we model these operations as transformations on goals. An agent may observe events that affect the agent's ability to achieve its goals. Hence goal transformations allow unachievable goals to be converted into similar achievable goals. This paper exam-ines an implementation of goal change within a cognitive ar-chitecture. We introduce goal transformation at the metacog-nitive level as well as goal transformation in an automated planner and discuss the costs and benefits of each approach. We evaluate goal change in the MIDCA architecture using a resource-restricted planning domain, demonstrating a perfor-mance benefit due to goal operations.},
author = {Cox, Michael T and Dannenhauer, Dustin and Kondrakunta, Sravya},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cox, Dannenhauer, Kondrakunta/2017/Goal Operations for Cognitive Systems.pdf:pdf},
journal = {Proceedings of the 31th Conference on Artificial Intelligence (AAAI 2017)},
keywords = {Special Track on Cognitive Systems},
pages = {4385--4391},
title = {{Goal Operations for Cognitive Systems}},
year = {2017}
}
@article{DellaPenna2012,
abstract = {Many real world problems involve hybrid systems, subject to (continuous) physical effects and controlled by (discrete) digital equipments. Indeed, many efforts are being made to extend the current planning systems and modelling languages to support such kind of domains. However, hybrid systems often present also a nonlinear behaviour and planning with continuous nonlinear change that is still a challenging issue.{\textless}/p{\textgreater} {\textless}p class="a-plus-plus"{\textgreater}In this paper we present the UPMurphi tool, a universal planner based on the discretise and validate approach that is capable of reasoning with mixed discrete/continuous domains, fully respecting the semantics of PDDL+. Given an initial discretisation, the hybrid system is discretised and given as input to UPMurphi, which performs universal planning on such an approximated model and checks the correctness of the results. If the validation fails, the approach is repeated by appropriately refining the discretisation.{\textless}/p{\textgreater} {\textless}p class="a-plus-plus"{\textgreater}To show the effectiveness of our approach, the paper presents two real hybrid domains where universal planning has been successfully performed using the UPMurphi tool.},
author = {{Della Penna}, Giuseppe and Magazzeni, Daniele and Mercorio, Fabio},
doi = {10.1007/s10489-011-0306-z},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Della Penna, Magazzeni, Mercorio/2012/A universal planning system for hybrid domains.pdf:pdf},
issn = {0924669X},
journal = {Applied Intelligence},
keywords = {Hybrid systems,PDDL+,Universal planning,plan},
mendeley-tags = {plan},
number = {4},
pages = {932--959},
title = {{A universal planning system for hybrid domains}},
volume = {36},
year = {2012}
}
@inproceedings{Molineaux2010,
abstract = {Modern complex games and simulations pose many challenges for an intelligent agent, including partial observability, continuous time and effects, hostile opponents, and exogenous events. We present ARTUE (Autonomous Response to Unexpected Events), a domain-independent autonomous agent that dynamically reasons about what goals to pursue in response to unexpected circumstances in these types of environments. ARTUE integrates AI research in planning, environment monitoring, explanation, goal generation, and goal management. To explain our conceptualization of the problem ARTUE addresses, we present a new conceptual framework, goal-driven autonomy, for agents that reason about their goals. We evaluate ARTUE on scenarios in the TAO Sandbox, a Navy training simulation, and demonstrate its novel architecture, which includes components for Hierarchical Task Network planning, explanation, and goal management. Our evaluation shows that ARTUE can perform well in a complex environment and that each component is necessary and contributes to the performance of the integrated system.},
author = {Molineaux, Matt and Klenk, Matthew and Aha, David W},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Molineaux, Klenk, Aha/2010/Goal-Driven Autonomy in a Navy Strategy Simulation.pdf:pdf},
keywords = {special track integrated intelligence},
pages = {1548--1554},
title = {{Goal-Driven Autonomy in a Navy Strategy Simulation}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1928/2251},
year = {2010}
}
@article{DeCarolis2001a,
abstract = {The aim of our research is to build a Reflexive Agent, that is able to either manifest an emotion it is feeling or to hide it. If the Agent decides to manifest its emotion, it can establish what verbal or nonverbal signals to employ communication in its and how to combine and synchronize them. In the decision of whether to express an emotion in a given context, a number of factors are considered, such as the Agent's own personality and goals, the Interlocutor's characteristics and the context. In planning how to communicate an emotion, various factors are considered as well: the available modalities (face, gaze, voice etc); the cognitive ease in producing and processing the various the expressiveness of every signal in communicating specific meanings; and, finally, the appropriateness of signals to social situations.},
author = {{De Carolis}, Berardina and Pelachaud, Catherine and Poggi, Isabella and {De Rosis}, Fiorella},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/De Carolis et al/2001/Behavior planning for a reflexive agent.pdf:pdf},
isbn = {1-55860-812-5, 978-1-558-60812-2},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1059--1064},
title = {{Behavior planning for a reflexive agent}},
year = {2001}
}
@incollection{Hertle2014,
abstract = {Domain-independent planning in general is broadly applicable to a wide range of tasks. Many formalisms exist that allow the description of different aspects of realistic problems. Which one to use is often no obvious choice, since a higher degree of expressiveness usually comes with an increased planning time and/or a decreased policy quality. Under the assumption that hard guarantees are not required, users are faced with a decision between multiple approaches. As a generic model we use a probabilistic description in the form of Markov Decision Processes (MDPs). We define abstracting translations into a classical planning formalism and fully observable nondeterministic planning. Our goal is to give insight into how state-of-the-art systems perform on different MDP planning domains.},
author = {Hertle, Andreas and Dornhege, Christian and Keller, Thomas and Mattm, Robert},
booktitle = {KI 2014: Advances in Artificial Intelligence},
editor = {Lutz, Carsten and Thielscher, Michael},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hertle et al/2014/An Experimental Comparison of Classical, FOND and Probabilistic Planning.pdf:pdf},
issn = {16113349},
pages = {297--308},
publisher = {Springer International Publishing},
title = {{An Experimental Comparison of Classical, FOND and Probabilistic Planning}},
year = {2014}
}
@article{Nau2003,
abstract = {The SHOP2 planning system received one of the awards for distinguished performance in the 2002 International Planning Competition. This paper describes the features of SHOP2 which enabled it to excel in the competition, especially those aspects of SHOP2 that deal with temporal and metric planning domains.},
archivePrefix = {arXiv},
arxivId = {1106.4869},
author = {Nau, Dana and Au, Tsz Chiu and Ilghami, Okhtay and Kuter, Ugur and Murdock, J. William and Wu, Dan and Yaman, Fusun},
doi = {10.1613/jair.1141},
eprint = {1106.4869},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nau et al/2003/SHOP2 An HTN planning system.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {379--404},
title = {{SHOP2: An HTN planning system}},
volume = {20},
year = {2003}
}
@incollection{Jaidee2013,
abstract = {Although several recent studies have been published on goal reasoning (i.e., the study of agents that can self-select their goals), none have focused on the task of learning and acting on large state and action spaces. We introduce GDA-C, a case-based goal reasoning algorithm that divides the state and action space among cooperating learning agents. Cooperation between agents emerges because (1) they share a common reward function and (2) GDA-C formulates the goal that each agent needs to achieve. We claim that its case-based approach for goal formulation is critical to the agents' performance. To test this claim we conducted an empirical study using the Wargus RTS environment, where we found that GDA-C outperforms its non-GDA ablation. {\textcopyright} 2013 Springer-Verlag.},
author = {Jaidee, Ulit and Mu{\~{n}}oz-Avila, H{\'{e}}ctor and Aha, David W.},
booktitle = {Case-Based Reasoning Research and Development},
doi = {10.1007/978-3-642-39056-2_12},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Jaidee, Mu{\~{n}}oz-Avila, Aha/2013/Case-Based Goal-Driven Coordination of Multiple Learning Agents.pdf:pdf},
isbn = {9783642390555},
issn = {03029743},
keywords = {Goal-driven autonomy,case-based reasoning,multi-agent systems},
pages = {164--178},
title = {{Case-Based Goal-Driven Coordination of Multiple Learning Agents}},
url = {http://link.springer.com/10.1007/978-3-642-39056-2{\_}12},
year = {2013}
}
@inproceedings{Vo2009,
abstract = {Despite the large body of work in both motion planning and multi-agent simulation, little work has focused on the problem of planning motion for groups of robots using external ¿controller¿ agents. We call this problem the group control problem. This problem is complex because it is highly underactuated, dynamic, and requires multi-agent cooperation. In this paper, we present a variety of new motion planning algorithms based on EST, RRT, and PRM methods for shepherds to guide flocks of robots through obstacle-filled environments. We show using simulation on several environments that under certain circumstances, motion planning can find paths that are too complicated for nai¿ve ¿simulation only¿ approaches. However, inconsistent results indicate that this problem is still in need of additional study.},
author = {Vo, Christopher and Harrison, Joseph F. and Lien, Jyh Ming},
booktitle = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
doi = {10.1109/IROS.2009.5354032},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vo, Harrison, Lien/2009/Behavior-based motion planning for group control.pdf:pdf},
isbn = {9781424438044},
pages = {3768--3773},
title = {{Behavior-based motion planning for group control}},
year = {2009}
}
@inproceedings{Silver2017,
author = {Silver, David and van Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and Degris, Thomas},
booktitle = {ICML 2017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Silver et al/2017/The Predictron End-To-End Learning and Planning.pdf:pdf},
keywords = {development plans,implementation,legislations,regulate,sustainable development},
title = {{The Predictron: End-To-End Learning and Planning}},
year = {2017}
}
@article{To2015,
author = {To, Son Thanh and Son, Tran Cao and Pontelli, Enrico},
doi = {10.1016/j.artint.2015.06.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/To, Son, Pontelli/2015/A generic approach to planning in the presence of incomplete information Theory and implementation.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {plan,planning with incomplete information},
mendeley-tags = {plan},
pages = {1--51},
publisher = {Elsevier B.V.},
title = {{A generic approach to planning in the presence of incomplete information: Theory and implementation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370215000855},
volume = {227},
year = {2015}
}
@article{Helmert2006,
abstract = {Fast Downward is a classical planning system based on heuristic search. It can deal with general deterministic planning problems encoded in the propositional fragment of PDDL2.2, including advanced features like ADL conditions and effects and derived predicates (axioms). Like other well-known planners such as HSP and FF, Fast Downward is a progression planner, searching the space of world states of a planning task in the forward direction. However, unlike other PDDL planning systems, Fast Downward does not use the propositional PDDL representation of a planning task directly. Instead, the input is first translated into an alternative representation called multivalued planning tasks, which makes many of the implicit constraints of a propositional planning task explicit. Exploiting this alternative representation, Fast Downward uses hierarchical decompositions of planning tasks for computing its heuristic function, called the causal graph heuristic, which is very different from traditional HSP-like heuristics based on ignoring negative interactions of operators. In this article, we give a full account of Fast Downwards approach to solving multi-valued planning tasks. We extend our earlier discussion of the causal graph heuristic to tasks involving},
archivePrefix = {arXiv},
arxivId = {arXiv:1109.6051v1},
author = {Helmert, Malte},
doi = {10.1613/jair.1705},
eprint = {arXiv:1109.6051v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Helmert/2006/The fast downward planning system.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {191--246},
title = {{The fast downward planning system}},
volume = {26},
year = {2006}
}
@article{Rueckert2016,
abstract = {A recurrent spiking neural network is proposed that implements planning as probabilistic inference for finite and infinite horizon tasks. The architecture splits this problem into two parts: The stochastic transient firing of the network embodies the dynamics of the planning task. With appropriate injected input this dynamics is shaped to generate high-reward state trajectories. A general class of reward- modulated plasticity rules for these afferent synapses is presented. The updates optimize the likelihood of getting a reward through a variant of an Expectation Maximization algorithm and learning is guaranteed to convergence to a local maximum. We find that the network dynamics are qualitatively similar to transient firing patterns during planning and foraging in the hippocampus of awake behaving rats. The model extends classical attractor models and provides a testable prediction on identifying modulating contextual information. In a real robot arm reaching and obstacle avoidance task the ability to represent multiple task solutions is investigated. The neural planning method with its local update rules provides the basis for future neuromorphic hardware implementations with promising potentials like large data processing abilities and early initiation of strategies to avoid dangerous situations in robot co-worker scenarios.},
author = {Rueckert, Elmar and Kappel, David and Tanneberg, Daniel and Pecevski, Dejan and Peters, Jan},
doi = {10.1038/srep21142},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rueckert et al/2016/Recurrent Spiking Networks Solve Planning Tasks.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
pages = {21142},
publisher = {Nature Publishing Group},
title = {{Recurrent Spiking Networks Solve Planning Tasks}},
url = {http://www.nature.com/articles/srep21142},
volume = {6},
year = {2016}
}
@inproceedings{Wolfe2011a,
author = {Wolfe, Jason and Russell, Stuart},
booktitle = {Proceedings of IJCAI International Joint Conference on Artificial Intelligence 2011},
doi = {10.5591/978-1-57735-516-8/IJCAI11-340},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Wolfe, Russell/2011/Bounded intention planning.pdf:pdf},
isbn = {9781577355120},
issn = {10450823},
keywords = {Planning and Scheduling,plan},
mendeley-tags = {plan},
pages = {2039--2045},
title = {{Bounded intention planning}},
year = {2011}
}
@article{Pollock1998,
author = {Pollock, John L.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Pollock/1998/The logical foundations of goal-regression planning in autonomous agents.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {plan},
mendeley-tags = {plan},
pages = {267--334},
title = {{The logical foundations of goal-regression planning in autonomous agents}},
volume = {106},
year = {1998}
}
@article{Alford2016,
abstract = {Considerable work has focused on enhancing the semantics of Hierarchical Task Networks (HTNs) in order to advance the state-of-the-art in hierarchical planning. For instance, the Hierarchical Goal Net-work (HGN) formalism operates over a hierarchy of goals to facilitate tighter integration of decompo-sitional planning with classical planning. Another example is the Action Notation Markup Language (ANML) which adds aspects of generative planning and task-sharing to the standard HTN semantics. The aim of this work is to formally analyze the effects of these modifications to HTN semantics on the computational complexity and expressivity of HTN planning. To facilitate analysis, we unify goal and task planning into Goal-Task Network (GTN) planning. GTN models use HTN and HGN constructs, but have a solution-preserving mapping back to HTN planning. We then show theoretical results that provide new insights into both the ex-pressivity as well as computational complexity of GTN planning under a number of different seman-tics. Our work lays a firm footing to clarify ex-act semantics for recent planners based on ANML, HGNs, and similar hierarchical languages.},
author = {Alford, Ron and Shivashankar, Vikas and Roberts, Mark and Frank, Jeremy and Aha, David W.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Alford et al/2016/Hierarchical planning Relating task and goal decomposition with task sharing.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {3022--3028},
title = {{Hierarchical planning: Relating task and goal decomposition with task sharing}},
year = {2016}
}
@article{Kovacs2012a,
abstract = {Despite a recent increase of research activity in the field of multi-agent planning there is still no de-facto standard for the description of multi-agent planning problems similarly to the Planning Domain Definition Language (PDDL) in case of deterministic single-agent planning. For this reason, in this paper a multi-agent extension of the currently latest official version of PDDL (3.1) is proposed together with a corresponding multi-agent planning track for the International Planning Competition (IPC). Our aim is to allow for a more direct comparison of planning systems and approaches, a greater reuse of research, and a more coordinated development in the field. Multi-agent planning is fundamentally different from the single-agent case with a broad range of applications (e.g. multi-robot domains). Not only is it inherently harder because of an exponential increase of the number of actions in general, but among others also constructive/destructive synergies of concurrent actions, and agents' different abilities and goals may need to be considered. The proposed multi-agent extension copes with these issues and allows planning both for and by agents even in temporal, numeric domains. It implies minimal changes to the syntax of PDDL3.1 and the related parsers.},
author = {Kovacs, Daniel L.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kovacs/2012/A Multi-Agent Extension of PDDL3.pdf:pdf},
journal = {ICAPS Workshop International Planning Competition: Past, Present and Future (WS-IPC 2012)},
keywords = {plan},
mendeley-tags = {plan},
pages = {19--37},
title = {{A Multi-Agent Extension of PDDL3}},
url = {http://e-archivo.uc3m.es:8080/bitstream/10016/14914/1/proceedings-WS-IPC2012.pdf{\#}page=23},
year = {2012}
}
@article{Wilson2013,
abstract = {Goal-driven autonomy is a framework for intelligent agents that automatically formulate and manage goals in dynamic environments, where goal formulation is the task of identifying goals that the agent should attempt to achieve. We argue that goal formulation is central to high-level autonomy, and explain why identifying domain-independent heuristics for this task is an important research topic in high- level control. We describe two novel domain-independent heuristics for goal formulation (motivators) that evaluate the utility of goals based on the projected consequences of achieving them. We then describe their integration in M- ARTUE, an agent that balances the satisfaction of internal needs with the achievement of goals introduced externally. We assess its performance in a series of experiments in the Rovers With Compass domain. Our results show that using domain-independent heuristics yields performance comparable to using domain-specific knowledge for goal formulation. Finally, in ablation studies we demonstrate that each motivator contributes significantly to M-ARTUE's performance.},
author = {Wilson, Mark and Molineaux, Matthew and Aha, David W},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Wilson, Molineaux, Aha/2013/Domain-Independent Heuristics for Goal Formulation.pdf:pdf},
isbn = {9781577356059},
journal = {Proceedings of the Twenty-Sixth International Florida Artificial Intelligence Research Society Conference Domain-Independent},
keywords = {General Conference Papers},
pages = {160--165},
title = {{Domain-Independent Heuristics for Goal Formulation}},
url = {http://www.stormingmedia.us/25/2564/A256495.html},
year = {2013}
}
@article{Gillespie2014a,
author = {Gillespie, Kellen and Gupta, Kalyan Moy and Drinkwater, Michael},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gillespie, Gupta, Drinkwater/2014/Case-Based Object Placement Planning.pdf:pdf},
issn = {16113349},
journal = {In Proceedings of the 22nd International Conference on Case-Based Reasoning},
keywords = {case-based reasoning,natural language understanding,object placement planning,spatial planning},
pages = {170--184},
title = {{Case-Based Object Placement Planning}},
year = {2014}
}
@article{Garrido2016,
abstract = {In this paper we propose myPTutor, a general and effective approach which uses AI planning techniques to create fully tailored learning routes, as sequences of Learning Objects (LOs) that fit the pedagogical and students' requirements. myPTutor has a potential applicability to support e-learning personalization by producing, and automatically solving, a planning model from (and to) e-learning standards in a vast number of real scenarios, from small to medium/large e-learning communities. Our experiments demonstrate that we can solve scenarios with large courses and a high number of students. Therefore, it is perfectly valid for schools, high schools and universities, especially if they already use Moodle, on top of which we have implemented myPTutor. It is also of practical significance for repairing unexpected discrepancies (while the students are executing their learning routes) by using a Case-Based Planning adaptation process that reduces the differences between the original and the new route, thus enhancing the learning process.},
author = {Garrido, Antonio and Morales, Lluvia and Serina, Ivan},
doi = {10.1016/j.eswa.2016.04.030},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Garrido, Morales, Serina/2016/On the use of case-based planning for e-learning personalization.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Case base planning,Learning route personalization,Plan adaptation,Planning,e-learning},
month = {oct},
pages = {1--15},
publisher = {Elsevier Ltd},
title = {{On the use of case-based planning for e-learning personalization}},
url = {http://www.sciencedirect.com/science/article/pii/S0957417416302032 http://linkinghub.elsevier.com/retrieve/pii/S0957417416302032},
volume = {60},
year = {2016}
}
@inproceedings{Elkawkagy2010,
author = {Elkawkagy, Mohamed and Schattenberg, Bernd and Biundo, Susanne},
booktitle = {ECAI 2010: 19th European Conference on Artificial Intelligence, 16-20 August 2010, Lisbon, Portugal : Including Prestigious Applications of Artificial Intelligence (PAIS-2010) : Proceedings},
doi = {10.3233/978-1-60750-606-5-229},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Elkawkagy, Schattenberg, Biundo/2010/Landmarks in Hierarchical Planning.pdf:pdf},
isbn = {9781607506065},
pages = {229--234},
title = {{Landmarks in Hierarchical Planning}},
year = {2010}
}
@inproceedings{Sardina2006,
author = {Sardina, Sebastian and Silva, Lavindra De and Padgham, Lin},
booktitle = {Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems (AAMAS'06)},
doi = {10.1145/1160633.1160813},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Sardina, Silva, Padgham/2006/Hierarchical Planning in BDI Agent Programming Languages A Formal Approach.pdf:pdf},
isbn = {1595933034},
keywords = {bdi agent-oriented programming,htn plannning},
pages = {1001--1008},
title = {{Hierarchical Planning in BDI Agent Programming Languages: A Formal Approach}},
year = {2006}
}
@article{Musliner2001,
author = {Musliner, D.J. and Goldman, R.P. and Pelican, M.J.S.},
doi = {10.1109/IROS.2001.976385},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Musliner, Goldman, Pelican/2001/Planning with increasingly complex executive models.pdf:pdf},
isbn = {0-7803-6612-3},
journal = {Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {2124--2130},
title = {{Planning with increasingly complex executive models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=976385},
volume = {4},
year = {2001}
}
@article{Hanks1995,
author = {Hanks, Steve and Weld, Daniel S.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hanks, Weld/1995/A Domain-Independent Algorithm for Plan Adaptation.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {319--360},
title = {{A Domain-Independent Algorithm for Plan Adaptation}},
volume = {2},
year = {1995}
}
@book{Zacharias2012,
address = {Berlin},
author = {Zacharias, Franziska},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Zacharias/2012/Knowledge Representations for Planning Manipulation Tasks.pdf:pdf},
isbn = {9783642251818},
pages = {144},
publisher = {Springer-Verlag},
title = {{Knowledge Representations for Planning Manipulation Tasks}},
volume = {16},
year = {2012}
}
@article{Hammond1990,
abstract = {This article presents a view of planning as a task supported by a dynamic memory. This view attempts to ingegrate models of memory, learning, and planning into a single system that learns about planning by creating new plans and analyzing how they interact with the world. We call this view of planning case-based planning. A case-based planner makes use of its own past experience in developing new plans. It relies on its memory of observed effects, rather than a set of causal rules, to create and modify new plans. Memories of past successes are accessed and modified to create new plans. Memories of past failures are used to warn the planner of impending problems, and memories of past repairs are called upon to tell the planner how to deal with them. This view of planning from experience supports and is supported by a learning system that incorporates new experiences into the planner's episodic memory. This learning algorithm gains from the planner's failures as well as its successes. Successful plans are stored in memory, indexed by the goals they satisfy and the problems they avoid. Failures are also stored and indexed by the features in the world that predict them. By storing failures as well as successes, the planner is able to anticipate and avoid future plan failures. Case-based planning is aimed at improving planning behavior in three areas: failure avoidance, plan repair, and plan reuse. It also attempts gains over current learning systems, in that the learning is driven by the functional needs of a planner. ?? 1990.},
author = {Hammond, Kristian J.},
doi = {10.1016/0364-0213(90)90018-R},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hammond/1990/Case-based planning A framework for planning from experience.PDF:PDF},
issn = {03640213},
journal = {Cognitive Science},
number = {3},
pages = {385--443},
title = {{Case-based planning: A framework for planning from experience}},
volume = {14},
year = {1990}
}
@article{Dehaene1997,
abstract = {Planning a goal-directed sequence of behavior is a higher function of the human brain that relies on the integrity of prefrontal cortical areas. In the Tower of London test, a puzzle in which beads sliding on pegs must be moved to match a designated goal configuration, patients with lesioned prefrontal cortex show deficits in planning a goal-directed sequence of moves. We propose a neuronal network model of sequence planning that passes this test and, when lesioned, fails in a way that mimics prefrontal patients' behavior. Our model comprises a descending planning system with hierarchically organized plan, operation, and gesture levels, and an ascending evaluative system that analyzes the problem and computes internal reward signals that index the correct/erroneous status of the plan. Multiple parallel pathways connecting the evaluative and planning systems amend the plan and adapt it to the current problem. The model illustrates how specialized hierarchically organized neuronal assemblies may collectively emulate central executive or supervisory functions of the human brain.},
author = {Dehaene, S and Changeux, J P},
doi = {10.1073/pnas.94.24.13293},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dehaene, Changeux/1997/A hierarchical neuronal network for planning behavior.pdf:pdf},
isbn = {0027-8424 (Print)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {24},
pages = {13293--13298},
pmid = {9371839},
title = {{A hierarchical neuronal network for planning behavior}},
volume = {94},
year = {1997}
}
@inproceedings{Cacace2015,
abstract = {In human-robot interactive scenarios communication and col- laboration during task execution are crucial issues. Since the human be- havior is unpredictable and ambiguous, an interactive robotic system is to continuously interpret intentions and goals adapting its executive and communicative processes according to the users behaviors. In this work, we propose an integrated system that exploits attentional mechanisms to flexibly adapt planning and executive processes to the multimodal human-robot interaction.},
author = {Cacace, Jonathan and Caccavale, Riccardo and Fiore, Michelangelo and Alam, Rachid},
booktitle = {Proceedings of the 2nd Italian Workshop on Artificial Intelligence and Robotics},
editor = {Alberto, Finzi and Mastrogiovanni, Fulvio and Orlandini, Andrea and Sgorbissa, Antonio},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cacace et al/2015/Attentional Plan Execution for Human-Robot Cooperation.pdf:pdf},
pages = {19--28},
series = {CEUR Workshop Proceedings},
title = {{Attentional Plan Execution for Human-Robot Cooperation}},
year = {2015}
}
@article{Kaelbling2016,
author = {Kaelbling, Leslie Pack},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kaelbling/2016/Implicit Belief-Space Pre-images for Hierarchical Planning and Execution.pdf:pdf},
isbn = {9781467380256},
pages = {5455--5462},
title = {{Implicit Belief-Space Pre-images for Hierarchical Planning and Execution}},
year = {2016}
}
@article{Barto1995,
abstract = {Learning methods based on dynamic programming (DP) are receiving increasing attention in artificial intelligence. Researchers have argued that DP provides the appropriate basis for compiling planning results into reactive strategies for real-time control, as well as for learning such strategies when the system being controlled is incompletely known. We introduce an algorithm based on DP, which we call Real-Time DP (RTDP), by which an embedded system can improve its performance with experience. RTDP generalizes Korf's Learning-Real-Time-A* algorithm to problems involving uncertainty. We invoke results from the theory of asynchronous DP to prove that RTDP achieves optimal behavior in several different classes of problems. We also use the theory of asynchronous DP to illuminate aspects of other DP-based reinforcement learning methods such as Watkins' Q-Learning algorithm. A secondary aim of this article is to provide a bridge between AI research on real-time planning and learning and relevant concepts and algorithms from control theory. ?? 1995 Elsevier Science B.V. All rights reserved.},
author = {Barto, Andrew G. and Bradtke, Steven J. and Singh, Satinder P.},
doi = {10.1016/0004-3702(94)00011-O},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Barto, Bradtke, Singh/1995/Learning to act using real-time dynamic programming.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
number = {1-2},
pages = {81--138},
title = {{Learning to act using real-time dynamic programming}},
volume = {72},
year = {1995}
}
@article{Gupta2017,
abstract = {We introduce a neural architecture for navigation in novel environments. Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment. The Cognitive Mapper and Planner (CMP) is based on two key ideas: a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the planner, and b) a spatial memory with the ability to plan given an incomplete set of observations about the world. CMP constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step. The accumulated belief of the world enables the agent to track visited regions of the environment. Our experiments demonstrate that CMP outperforms both reactive strategies and standard memory-based architectures and performs well in novel environments. Furthermore, we show that CMP can also achieve semantically specified goals, such as "go to a chair".},
archivePrefix = {arXiv},
arxivId = {1702.03920},
author = {Gupta, Saurabh and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
eprint = {1702.03920},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gupta et al/2017/Cognitive Mapping and Planning for Visual Navigation.pdf:pdf},
journal = {ArXiv: 1702.03920},
month = {feb},
title = {{Cognitive Mapping and Planning for Visual Navigation}},
url = {http://arxiv.org/abs/1702.03920},
year = {2017}
}
@article{Gupta1992,
abstract = {We prove complexity, approximability, and inapproximability results for the problem of finding an exchange equilibrium in markets with indivisible (integer) goods, most notably a polynomial-time algorithm that approximates the market equilibrium arbitrarily closely when the number of goods is bounded and the utilities are linear. We also show a communication complexity lower bound, implying that the ideal informational economy of a market with unique individual optima is unattainable in general.},
author = {Gupta, N. and Nau, D. S.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gupta, Nau/1992/On the complexity of Blocks-World planning.pdf:pdf},
journal = {Artificial Intelligence},
number = {2-3},
pages = {223--254},
title = {{On the complexity of Blocks-World planning}},
volume = {56},
year = {1992}
}
@article{Konidaris2004,
abstract = {We introduce a framework that enables an agent to autonomously learn its own symbolic representation of a low-level, continuous environment. Propositional symbols are formalized as names for probability distributions, providing a nat-ural means of dealing with uncertain rep-resentations and probabilistic plans. We determine the symbols that are sufficient for computing the probability with which a plan will succeed, and demonstrate the acquisition of a symbolic representation in a computer game domain.},
author = {Konidaris, George and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Konidaris, Kaelbling, Lozano-Perez/2004/Symbol Acquisition for Probabilistic High-Level Planning.pdf:pdf},
keywords = {Special Track on Machine Learning},
title = {{Symbol Acquisition for Probabilistic High-Level Planning}},
year = {2004}
}
@incollection{Matari2008,
abstract = {Nature is filled with examples of autonomous creatures capable of dealing with the diversity, unpredictability, and rapidly changing conditions of the real world. Such creatures must make decisions and take actions based on incomplete perception, time constraints, limited knowledge about the world, cognition, reasoning and physical capabilities, in uncontrolled conditions and with very limited cues about the intent of others. Consequently, one way of evaluating intelligence is based on the creatureʼs ability to make the most of what it has available to handle the complexities of the real world. The main objective of this chapter is to clarify behavior-based systems and their use in single- and multi-robot autonomous control problems and applications. The chapter is organized as follows. Section 38.1 overviews robot control, introducing behavior-based systems in relation to other established approaches to robot control. Section 38.2 follows by outlining the basic principles of behavior-based systems that make them distinct from other types of robot control architectures. The concept of basis behaviors, the means of modularizing behavior-based systems, is presented in Sect. 38.3. Section 38.4 describes how behaviors are used as building blocks for creating representations for use by behavior-based systems, enabling the robot to reason about the world and about itself in that world. Section 38.5 presents several different classes of learning methods for behavior-based systems, validated on single-robot and multi-robot systems. Section 38.6 provides an overview of various robotics problems and application domains that have successfully been addressed with behavior-based control. Finally, Sect. 38.7 concludes the chapter.},
author = {Matari, Maja J and Matari{\'{c}}, MajaJ and Michaud, Fran{\c{c}}ois},
booktitle = {Springer Handbook of Robotics},
doi = {10.1007/978-3-540-30301-5_39},
editor = {Siciliano, Bruno and Khatib, Oussama},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Matari, Matari{\'{c}}, Michaud/2008/Behavior-Based Systems.pdf:pdf},
isbn = {978-3-540-23957-4},
pages = {891--909},
publisher = {Springer Berlin Heidelberg},
title = {{Behavior-Based Systems}},
url = {http://dx.doi.org/10.1007/978-3-540-30301-5{\_}39{\%}5Cnhttp://link.springer.com/static-content/0.5480/pdf/226/chp:10.1007/978-3-540-30301-5{\_}39.pdf?token=1350549054544--122ebaddec4dac9fd256e387955adc88e8fcf10b7024158e19c7a3cbe9ae727bb1e85ec450386a0e24b038d38b1480},
year = {2008}
}
@incollection{Hoffmann2011,
abstract = {Domain-independent planning is one of the long-standing sub-areas of Artificial Intelligence (AI), aiming at approaching human problem-solving flexibility. The area has long had an affinity towards playful illustrative examples, imprinting it on the mind of many a student as an area concerned with the rearrangement of blocks, and with the order in which to put on socks and shoes (not to mention the disposal of bombs in toilets). Working on the assumption that this “student” is you – the readers in earlier stages of their careers – I herein aim to answer three questions that you surely desired to ask back then already:What is it good for? Does it work? Is it interesting to do research in? Answering the latter two questions in the affirmative (of course!), I outline some of the major developments of the last decade, revolutionizing the ability of planning to scale up, and the understanding of the enabling technology. Answering the first question, I point out that modern planning proves to be quite useful for solving practical problems - including, perhaps, yours.},
author = {Hoffmann, J{\"{o}}rg},
booktitle = {KI 2011: Advances in Artificial Intelligence},
doi = {10.1007/978-3-642-24455-1_1},
editor = {Bach, Joscha and Edelkamp, Stefan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hoffmann/2011/Everything you always wanted to know about planning (but were afraid to ask).pdf:pdf},
isbn = {9783642244544},
issn = {03029743},
keywords = {plan},
mendeley-tags = {plan},
pages = {1--13},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Everything you always wanted to know about planning (but were afraid to ask)}},
year = {2011}
}
@inproceedings{Rudenko2017,
author = {Rudenko, Andrey and Palmieri, Luigi and Arras, Kai O},
booktitle = {ICRA 2017 Workshop on AI Planning and Robotics: Challenges and Methods},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rudenko, Palmieri, Arras/2017/Predictive Planning for a Mobile Robot in Human Environments.pdf:pdf},
title = {{Predictive Planning for a Mobile Robot in Human Environments}},
year = {2017}
}
@article{Hoffmann2001,
author = {Hoffmann, Jorg and Nebel, Bernhard},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hoffmann, Nebel/2001/The FF Planning System Fast Plan Generation Through Heuristic Search.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {253--302},
title = {{The FF Planning System: Fast Plan Generation Through Heuristic Search}},
volume = {14},
year = {2001}
}
@article{Luo2015,
author = {Luo, Jiangfeng and Zhu, Cheng and Zhang, Weiming and Liu, Zhong},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Luo et al/2015/Planning with Multistep Forward Search with Forced Goal-Ordering Constraints.pdf:pdf},
journal = {Computational Intelligence},
keywords = {automated planning,plan,search,search heuristics},
mendeley-tags = {plan},
number = {2},
pages = {233--255},
title = {{Planning with Multistep Forward Search with Forced Goal-Ordering Constraints}},
volume = {31},
year = {2015}
}
@book{Dmap2015,
address = {Jerusalem},
editor = {Komenda, Anton{\'{i}}n and {\v{S}}tolba, Michal and Kovacs, D{\'{a}}niel L and P{\v{e}}chou{\v{c}}ek, Michal},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/ICAPS Proceedings of the 3rd Workshop on Distributed and Multi-Agent Planning (DMAP-2015).pdf:pdf},
keywords = {plan},
mendeley-tags = {plan},
pages = {94},
title = {{ICAPS Proceedings of the 3rd Workshop on Distributed and Multi-Agent Planning (DMAP-2015)}},
year = {2015}
}
@article{Veloso1993,
abstract = {Expertise consists of rapid selection and application of compiled experience. Robust reasoning, however, requires adaptation to new contingencies and intelligent modification of past experience. And novel or creative reasoning, by its real nature, necessitates general problem-solving abilities unconstrained by past behavior. This article presents a comprehensive computational model of analogical (case-based) reasoning that transitions smoothly between case replay, case adaptation, and general problem solving, exploiting and modifying past experience when available and resorting to general problem-solving methods when required. Learning occurs by accumulation of new cases, especially in situations that required extensive problem solving, and by tuning the indexing structure of the memory model to retrieve progressively more appropriate cases. The derivational replay mechanism is discussed in some detail, and extensive results of the first full implementation are presented. These results show up to a large performance improvement in a simple transportation domain for structurally similar problems, and smaller improvements when less strict similarity metrics are used for problems that share partial structure in a process-job planning domain and in an extended version of the strips robot domain.},
author = {Veloso, Manuela M. and Carbonell, Jaime G.},
doi = {10.1023/A:1022686910523},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Veloso, Carbonell/1993/Derivational analogy in PRODIGY. Automating case acquisition, storage, and utilization.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {case-based reasoning,derivational analogy,general problem solving,learning by analogy,plan,replay,search and retrieval costs},
mendeley-tags = {plan},
number = {3},
pages = {249--278},
title = {{Derivational analogy in PRODIGY. Automating case acquisition, storage, and utilization}},
volume = {10},
year = {1993}
}
@article{Freedman2017,
author = {Freedman, Richard G and Zilberstein, Shlomo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Freedman, Zilberstein/2017/Integration of Planning with Recognition for Responsive Interaction Using Classical Planners.pdf:pdf},
journal = {Proceedings of the 31th Conference on Artificial Intelligence (AAAI 2017)},
keywords = {Special Track on Integrated Systems},
pages = {4581--4588},
title = {{Integration of Planning with Recognition for Responsive Interaction Using Classical Planners}},
year = {2017}
}
@inproceedings{Kaelbling2011,
author = {Kaelbling, Leslie Pack},
booktitle = {Proceedings og 2011 IEEE International Conference on Robotics and Automation},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kaelbling/2011/Hierarchical task and motion planning in the now.pdf:pdf},
isbn = {9781612843858},
keywords = {plan},
mendeley-tags = {plan},
pages = {1470--1477},
publisher = {IEEE},
title = {{Hierarchical task and motion planning in the now}},
year = {2011}
}
@incollection{Vattam2014,
abstract = {We present SET-PR, a novel case-based plan recognition algorithm that is tolerant to missing and misclassified actions in its input action sequences. SET-PR uses a novel representation called action sequence graphs to represent stored plans in its plan library and a similarity metric that uses a combination of graph degree sequences and object similarity to retrieve relevant plans from its library. We evaluated SET-PR by measuring plan recognition convergence and precision with increasing levels of missing and misclassified actions in its input. In our experiments, SET-PR tolerated 20{\%}-30{\%} of input errors without compromising plan recognition performance.},
author = {Vattam, Swaroop S. and Aha, David W. and Floyd, Michael},
booktitle = {Case-Based Reasoning Research and Development},
doi = {10.1007/978-3-319-11209-1_35},
editor = {Vattam, Swaroop S. and Aha, David W. and Floyd, Michael},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vattam, Aha, Floyd/2014/Case-Based Plan Recognition Using Action Sequence Graphs.pdf:pdf},
isbn = {978-3-319-11208-4, 978-3-319-11209-1},
issn = {16113349},
keywords = {approximate graph matching,case-based reasoning,error tolerance,graph,plan recognition,representation of plans},
pages = {495--510},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Case-Based Plan Recognition Using Action Sequence Graphs}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-11209-1{\_}35 http://link.springer.com/10.1007/978-3-319-11209-1{\_}35},
year = {2014}
}
@inproceedings{Roberts2014,
abstract = {Goal Reasoning (GR) concerns actors that assume the responsibility for dynamically selecting the goals they pursue. Our focus is on modeling an actor{\{}$\backslash$textquoteright{\}}s decision making when they encounter notable events. We model GR as an iterative refinement process, where constraints introduced for each abstraction layer shape the solutions for successive layers. Our model provides a conceptual framework for robotics researchers and practitioners. We present a goal lifecycle and define a formal model for GR that (1) relates distinct disciplines concerning actors that operate on goals, and (2) provides a way to evaluate actors. We introduce GR using an example on waypoint navigation and outline its application, in three projects, for controlling simulated and real-world vehicles. We emphasize the relation of GR to planning, and encourage PlanRob researchers to collaborate in exploring this exciting frontier.},
author = {Roberts, Mark and Vattam, Swaroop and Alford, Ronald and Auslander, Bryan and Karneeb, Justin and Molineaux, Matthew and Apker, Thomas and Wilson, Mark and McMahon, James and Aha, David W.},
booktitle = {Working Notes of the Planning and Robotics Workshop at ICAPS},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Roberts et al/2014/Iterative Goal Refinement for Robotics.pdf:pdf},
title = {{Iterative Goal Refinement for Robotics}},
year = {2014}
}
@article{Kaelbling2013,
abstract = {We describe an integrated strategy for planning, perception, state estimation and action in complex mobile manipulation domains based on planning in the belief space of probability distributions over states using hierarchical goal regression (pre-image back-chaining). We develop a vocabulary of logical expressions that describe sets of belief states, which are goals and subgoals in the planning process. We show that a relatively small set of symbolic operators can give rise to task-oriented perception in support of the manipulation goals. An implementation of this method is demonstrated in simulation and on a real PR2 robot, showing robust, flexible solution of mobile manipulation problems with multiple objects and substantial uncertainty.},
author = {Kaelbling, Leslie Pack and Lozano-P{\'{e}}rez, Tomas},
doi = {10.1177/0278364913484072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Kaelbling, Lozano-P{\'{e}}rez/2013/Integrated task and motion planning in belief space.pdf:pdf},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
number = {9-10},
pages = {1194--1227},
title = {{Integrated task and motion planning in belief space}},
url = {http://ijr.sagepub.com/content/32/9-10/1194.abstract?etoc},
volume = {32},
year = {2013}
}
@article{DeLaRosa2013,
abstract = {Most of the great success of heuristic search as an approach to AI Planning is due to the right design of domain-independent heuristics. Although many heuris- tic planners perform reasonablywell, the computational cost of computing the heuristic function in every search node is very high, causing the planner to scale poorly when increas- ing the size of the planning tasks. For tackling this prob- lem, planners can incorporate additional domain-dependent heuristics in order to improve their performance. Learning- based planners try to automatically acquire these domain- dependent heuristics using previous solved problems. In this work, we present a case-based reasoning approach that learns abstracted state transitions that serve as domain con- trol knowledge for improving the planning process. The rec- ommendations from the retrieved cases are used as guidance for pruning or ordering nodes in different heuristic search al- gorithms applied to planning tasks. We show that the CBR guidance is appropriate for a considerable number of plan- ning benchmarks.},
author = {{De La Rosa}, Tomas and Garcia-Olaya, Angel and Borrajo, Daniel},
doi = {10.1007/s10489-012-0404-6},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/De La Rosa, Garcia-Olaya, Borrajo/2013/A case-based approach to heuristic planning.pdf:pdf},
issn = {0924669X},
journal = {Applied Intelligence},
keywords = {Automated planning,Case-based reasoning,Search algorithms},
number = {1},
pages = {184--201},
title = {{A case-based approach to heuristic planning}},
volume = {39},
year = {2013}
}
@article{Blum1997,
abstract = {We introduce a new approach to planning in STRIPS-like domains based on constructing and analyzing a compact structure we call a Planning Graph. We describe a new planner, Graphplan, that uses this paradigm. Graphplan always returns a shortest possible partial-order plan, or states that no valid plan exists. We provide empirical evidence in favor of this approach, showing that Graphplan outperforms the total-order planner, Prodigy, and the partial-order planner, UCPOP, on a variety of interesting natural and artificial planning problems. We also give empirical evidence that the plans produced by Graphplan are quite sensible. Since searches made by this approach are fundamentally different from the searches of other common planning methods, they provide a new perspective on the planning problem.},
author = {Blum, Avrim L. and Frust, Merrick L.},
doi = {10.1016/S0004-3702(96)00047-1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Blum, Frust/1997/Fast planning through planning graph analysis.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {general purpose planning,graph algorithms,planning,strips planning},
number = {1-2},
pages = {281--300},
title = {{Fast planning through planning graph analysis}},
volume = {90},
year = {1997}
}
@article{Milde2017,
author = {Milde, Moritz B. and Blum, Hermann and Dietm{\"{u}}ller, Alexander and Sumislawska, Dora and Conradt, J{\"{o}}rg and Indiveri, Giacomo and Sandamirskaya, Yulia},
doi = {10.3389/fnbot.2017.00028},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Milde et al/2017/Obstacle Avoidance and Target Acquisition for Robot Navigation Using a Mixed Signal AnalogDigital Neuromorphic Processing System.pdf:pdf},
issn = {1662-5218},
journal = {Frontiers in Neurorobotics},
keywords = {Dynamic neural fields,Dynamic vision sensor,Neuromorphic controller,Neurorobotics,Obstacle avoidance,Target acquisition},
month = {jul},
pages = {1--17},
title = {{Obstacle Avoidance and Target Acquisition for Robot Navigation Using a Mixed Signal Analog/Digital Neuromorphic Processing System}},
url = {http://journal.frontiersin.org/article/10.3389/fnbot.2017.00028/full},
volume = {11},
year = {2017}
}
@techreport{Gerevini2005,
author = {Gerevini, Alfonso E and Long, Derek},
booktitle = {Technical Report},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gerevini, Long/2005/Plan Constraints and Preferences in PDDL3.pdf:pdf},
institution = {Department of Electronics for Automation, University of Brescia},
isbn = {RT 2005-08-47},
pages = {1--12},
title = {{Plan Constraints and Preferences in PDDL3}},
year = {2005}
}
@article{Richter2010,
abstract = {LAMA is a classical planning system based on heuristic forward search. Its core feature is the use of a pseudo-heuristic derived from landmarks, propositional formulas that must be true in every solution of a planning task. LAMA builds on the Fast Downward planning system, using finite-domain rather than binary state variables and multi-heuristic search. The latter is employed to combine the landmark heuristic with a variant of the well-known FF heuristic. Both heuristics are cost-sensitive, focusing on high-quality solutions in the case where actions have non-uniform cost. A weighted A* search is used with iteratively decreasing weights, so that the planner continues to search for plans of better quality until the search is terminated. LAMA showed best performance among all planners in the sequential satisficing track of the International Planning Competition 2008. In this paper we present the system in detail and investigate which features of LAMA are crucial for its performance. We present individual results for some of the domains used at the competition, demonstrating good and bad cases for the techniques implemented in LAMA. Overall, we find that using landmarks improves performance, whereas the incorporation of action costs into the heuristic estimators proves not to be beneficial. We show that in some domains a search that ignores cost solves far more problems, raising the question of how to deal with action costs more effectively in the future. The iterated weighted A* search greatly improves results, and shows synergy effects with the use of landmarks.},
archivePrefix = {arXiv},
arxivId = {1401.3839},
author = {Richter, Silvia and Westphal, Matthias},
doi = {10.1613/jair.2972},
eprint = {1401.3839},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Richter, Westphal/2010/The LAMA planner Guiding cost-based anytime planning with landmarks.pdf:pdf},
isbn = {1076-9757},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {127--177},
title = {{The LAMA planner: Guiding cost-based anytime planning with landmarks}},
volume = {39},
year = {2010}
}
@article{Garrett2015,
abstract = {In this paper we address planning problems in high-dimensional hybrid configuration spaces, with a particular focus on manipulation planning problems involving many objects. We present the hybrid backward-forward (HBF) planning algorithm that uses a backward identification of constraints to direct the sampling of the infinite action space in a forward search from the initial state towards a goal configuration. The resulting planner is probabilistically complete and can effectively construct long manipulation plans requiring both prehensile and nonprehensile actions in cluttered environments.},
author = {Garrett, Caelan Reed and Lozano-P{\'{e}}rez, Tom{\'{a}}s and Kaelbling, Leslie Pack},
doi = {10.1109/IROS.2015.7354287},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Garrett, Lozano-P{\'{e}}rez, Kaelbling/2015/Backward-forward search for manipulation planning.pdf:pdf},
isbn = {9781479999941},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Heuristic algorithms,Intelligent robots,Ovens,Planning,Probabilistic logic,Search problems},
number = {grant 1420927},
pages = {6366--6373},
title = {{Backward-forward search for manipulation planning}},
volume = {2015-Decem},
year = {2015}
}
@article{2009a,
author = {Карпов, В. Э. and Вальцев, В. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Карпов, Вальцев/2009/Динамическое планирование поведения робота на основе сети ``интеллектуальных'' нейронов.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {plan},
language = {russian},
mendeley-tags = {plan},
number = {2},
pages = {58--69},
title = {{Динамическое планирование поведения робота на основе сети ``интеллектуальных'' нейронов}},
year = {2009}
}
@article{Vattam2013,
abstract = {Goal-directed behavior is a hallmark of intelligence. While the majority of artificial intelligence research assumes goals are static and externally provided, many real-world applications involve unanticipated changes in the environment that may require changes to the goals themselves. Goal reasoning, which emphasizes the explicit representation of goals, their automatic formulation and dynamic management, is considered an important aspect of high-level autonomy. Building from these three basic requirements, we describe and apply a framework for surveying research related to goal reasoning that focuses on triggers and methods for goal formulation and goal management. We also summarize current research and highlight potential areas of future work.},
author = {Vattam, Swaroop and Klenk, Matthew and Molineaux, Matthew and Aha, David W},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vattam et al/2013/Breadth of Approaches to Goal Reasoning A Research Survey.pdf:pdf},
journal = {Goal Reasoning: Papers from the ACS Workshop},
pages = {111--126},
title = {{Breadth of Approaches to Goal Reasoning : A Research Survey}},
year = {2013}
}
@article{Vezhnevets2016,
abstract = {We present a novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting. The network builds an internal plan, which is continuously updated upon observation of the next input from the environment. It can also partition this internal representation into contiguous sub- sequences by learning for how long the plan can be committed to - i.e. followed without re-planing. Combining these properties, the proposed model, dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally abstracted macro- actions of varying lengths that are solely learnt from data without any prior information. These macro-actions enable both structured exploration and economic computation. We experimentally demonstrate that STRAW delivers strong improvements on several ATARI games by employing temporally extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same time a general algorithm that can be applied on any sequence data. To that end, we also show that when trained on text prediction task, STRAW naturally predicts frequent n-grams (instead of macro-actions), demonstrating the generality of the approach.},
archivePrefix = {arXiv},
arxivId = {1606.04695},
author = {Alexander and Vezhnevets and Mnih, Volodymyr and Agapiou, John and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Kavukcuoglu, Koray},
eprint = {1606.04695},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Alexander et al/2016/Strategic Attentive Writer for Learning Macro-Actions.pdf:pdf},
journal = {arXiv},
month = {jun},
title = {{Strategic Attentive Writer for Learning Macro-Actions}},
url = {http://arxiv.org/abs/1606.04695},
year = {2016}
}
@inproceedings{Bisson2015,
abstract = {Plan recognition, the problem of inferring the goals or plans of an observed agent, is a key el- ement of situation awareness in human-machine and machine-machine interactions for many appli- cations. Some plan recognition algorithms require knowledge about the potential behaviours of the observed agent in the form of a plan library, to- gether with a decision model about how the ob- served agent uses the plan library to make deci- sions. It is however difficult to elicit and specify the decision model a priori. In this paper, we present a recursive neural network model that learns such a decision model automatically. We discuss promis- ing experimental results of the approach with com- parisons to selected state-of-the-art plan recogni- tion algorithms on three benchmark domains. 1},
author = {Bisson, Francis and Larochelle, Hugo and Kabanza, Froduald},
booktitle = {Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI 2015)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bisson, Larochelle, Kabanza/2015/Using a Recursive Neural Network to Learn an Agent's Decision Model for Plan Recognition.pdf:pdf},
isbn = {978-1-57735-738-4},
issn = {10450823},
pages = {918--924},
title = {{Using a Recursive Neural Network to Learn an Agent's Decision Model for Plan Recognition}},
year = {2015}
}
@article{Hsu2014,
author = {Hsu, Yuan Pao and Jiang, Wei Cheng},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hsu, Jiang/2014/A fast learning agent based on the dyna architecture.pdf:pdf},
issn = {10162364},
journal = {Journal of Information Science and Engineering},
keywords = {CMAC,Dyna agent ?? 2014, institute of information scien,Prioritized sweeping,Q-learning,Reinforcement learning},
number = {6},
pages = {1807--1823},
title = {{A fast learning agent based on the dyna architecture}},
volume = {30},
year = {2014}
}
@article{Gerevini2009,
abstract = {The international planning competition (IPC) is an important driver for planning research. The general goals of the IPC include pushing the state of the art in planning technology by posing new scientific challenges, encouraging direct comparison of planning systems and techniques, developing and improving a common planning domain definition language, and designing new planning domains and problems for the research community. This paper focuses on the deterministic part of the fifth international planning competition (IPC5), presenting the language and benchmark domains that we developed for the competition, as well as a detailed experimental evaluation of the deterministic planners that entered IPC5, which helps to understand the state of the art in the field. We present an extension of pddl, called pddl3, allowing the user to express strong and soft constraints about the structure of the desired plans, as well as strong and soft problem goals. We discuss the expressive power of the new language focusing on the restricted version that was used in IPC5, for which we give some basic results about its compilability into pddl2. Moreover, we study the relative performance of the IPC5 planners in terms of solved problems, CPU time, and plan quality; we analyse their behaviour with respect to the winners of the previous competition; and we evaluate them in terms of their capability of dealing with soft goals and constraints, and of finding good quality plans in general. Overall, the results indicate significant progress in the field, but they also reveal that some important issues remain open and require further research, such as dealing with strong constraints and computing high quality plans in metric-time domains and domains involving soft goals or constraints. ?? 2009 Elsevier B.V.},
author = {Gerevini, Alfonso E. and Haslum, Patrik and Long, Derek and Saetti, Alessandro and Dimopoulos, Yannis},
doi = {10.1016/j.artint.2008.10.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gerevini et al/2009/Deterministic planning in the fifth international planning competition PDDL3 and experimental evaluation of the planners.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Automated planning,Benchmarks for planning,Experimental evaluation of planning systems,International planning competition,Knowledge representation in planning,PDDL,Plan constraints,Planning languages,Planning systems,Preferences in planning},
number = {5-6},
pages = {619--668},
publisher = {Elsevier B.V.},
title = {{Deterministic planning in the fifth international planning competition: PDDL3 and experimental evaluation of the planners}},
url = {http://dx.doi.org/10.1016/j.artint.2008.10.012},
volume = {173},
year = {2009}
}
@article{Fox2006,
abstract = {In this paper we present pddl+, a planning domain description language for modelling mixed discrete-continuous planning domains. We describe the syntax and modelling style of pddl+, showing that the language makes convenient the modelling of complex time-dependent effects. We provide a formal semantics for pddl+ by mapping planning instances into constructs of hybrid automata. Using the syntax of HAs as our semantic model we construct a semantic mapping to labelled transition systems to complete the formal interpretation of pddl+ planning instances. An advantage of building a mapping from pddl+ to HA theory is that it forms a bridge between the Planning and Real Time Systems research communities. One consequence is that we can expect to make use of some of the theoretical properties of HAs. For example, for a restricted class of HAs the Reachability problem (which is equivalent to Plan Existence) is decidable. pddl+ provides an alternative to the continuous durative action model of pddl2.1, adding a more flexible and robust model of time-dependent behaviour.},
author = {Fox, Maria and Long, Derek},
doi = {10.1613/jair.2044},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fox, Long/2006/Modelling mixed discrete-continuous domains for planning.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {235--297},
title = {{Modelling mixed discrete-continuous domains for planning}},
volume = {27},
year = {2006}
}
@inproceedings{Powell2011,
abstract = {If given manually-crafted goal selection knowledge, goal reasoning agents can dynamically determine which goals they should achieve in complex environments. These agents should instead learn goal selection knowledge through expert interaction. We describe T-ARTUE, a goal reasoning agent that performs case-based active and interactive learning to discover goal selection knowledge. We also report tests of its performance in a complex environment. We found that, under some conditions, T-ARTUE can quickly learn goal selection knowledge.},
author = {Powell, Jay and Molineaux, Matthew and Aha, David W},
booktitle = {Proceedings of the Twenty-Fourth International Florida Artificial Intelligence Research Society Conference Active},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Powell, Molineaux, Aha/2011/Active and Interactive Discovery of Goal Selection Knowledge.pdf:pdf},
isbn = {9781577355014},
keywords = {Special Track on Case-Based Reasoning},
pages = {413--418},
title = {{Active and Interactive Discovery of Goal Selection Knowledge}},
year = {2011}
}
@book{Tampra2012,
address = {Atibaia},
editor = {Cirillo, Marcello and Gerkey, Brian and Pecora, Federico and Stilman, Mike},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2012/TAMPRA'12 Proceedings of the 2012 ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications.pdf:pdf},
keywords = {plan},
mendeley-tags = {plan},
pages = {61},
title = {{TAMPRA'12: Proceedings of the 2012 ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications}},
year = {2012}
}
@article{Paxton2017,
abstract = {We consider task and motion planning in complex dynamic environments for problems expressed in terms of a set of Linear Temporal Logic (LTL) constraints, and a reward function. We propose a methodology based on reinforcement learning that employs deep neural networks to learn low-level control policies as well as task-level option policies. A major challenge in this setting, both for neural network approaches and classical planning, is the need to explore future worlds of a complex and interactive environment. To this end, we integrate Monte Carlo Tree Search with hierarchical neural net control policies trained on expressive LTL specifications. This paper investigates the ability of neural networks to learn both LTL constraints and control policies in order to generate task plans in complex environments. We demonstrate our approach in a simulated autonomous driving setting, where a vehicle must drive down a road in traffic, avoid collisions, and navigate an intersection, all while obeying given rules of the road.},
archivePrefix = {arXiv},
arxivId = {1703.07887},
author = {Paxton, Chris and Raman, Vasumathi and Hager, Gregory D. and Kobilarov, Marin},
eprint = {1703.07887},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Paxton et al/2017/Combining Neural Networks and Tree Search for Task and Motion Planning in Challenging Environments.pdf:pdf},
journal = {ArXiv: 1703.07887},
title = {{Combining Neural Networks and Tree Search for Task and Motion Planning in Challenging Environments}},
url = {http://arxiv.org/abs/1703.07887},
year = {2017}
}
@article{Guerin2013a,
abstract = {In this paper, we review current knowledge on tool use development in infants in order to provide relevant information to cognitive developmental roboticists seeking to design artiﬁ- cial systems that develop tool use abilities.This information covers: 1) sketching developmental pathways leading to tool use competences; 2) the characterization of learning and test situations; 3) the crystallization of seven mechanisms underlying the developmental process; and 4) the formulation of a number of challenges and recommendations for designing artiﬁcial systems that exhibit tool use abilities in complex contexts},
author = {Guerin, Frank and Kruger, Norbert and Kraft, Dirk},
doi = {10.1109/TAMD.2012.2209879},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Guerin, Kruger, Kraft/2013/A survey of the ontogeny of tool Use From sensorimotor experience to planning.pdf:pdf},
isbn = {1943-0604},
issn = {19430604},
journal = {IEEE Transactions on Autonomous Mental Development},
keywords = {Developmental psychology,Developmental robotics,Infant behavior,Tool use},
number = {1},
pages = {18--45},
title = {{A survey of the ontogeny of tool Use: From sensorimotor experience to planning}},
volume = {5},
year = {2013}
}
@article{Alterman1988,
abstract = {Adaptive Planning is an approach to planning in the cammansense domain. An adaptive planner takes advantage of the habitual nature of many of the planning situations for which tt plans by basing its activities on a memory of pre-stored plans. A critical issue, and the subject of this paper, is the question of flexibility: How does an adaptive plonner refit an old plan in order to meet the demands of some new planning situation? An adaptive planner refits prestored plans by constructing on interpretation of the situation in which it is engaged. Key elements in the theory of adoptive planning are its treatment of specific plans and o notion of situation matching. The theory of adaptive planning has been modeled by a computer program called PLEXUS.},
author = {Alterman, R.},
doi = {10.1207/s15516709cog1203_3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Alterman/1988/Adaptive planning.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {plan},
mendeley-tags = {plan},
pages = {393--421},
pmid = {20619553},
title = {{Adaptive planning}},
volume = {12},
year = {1988}
}
@article{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
doi = {10.1016/0004-3702(71)90010-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fikes, Nilsson/1971/STRIPS A new approach to the application of theorem proving to problem solving.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {plan},
mendeley-tags = {plan},
number = {3-4},
pages = {189--208},
title = {{STRIPS: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}
@article{Billing2015,
abstract = {A technique for simultaneous planning and action based on dynamic field theory is presented. The model builds on previous work on representation of sequential behavior as attractors in dynamic neural fields. Here, we demonstrate how chains of competing attractors can be used to represent dynamic plans towards a goal state. The present work can be seen as an addition to a growing body of work that demonstrates the role of dynamic field theory as a bridge between low-level reactive approaches and high-level symbol processing mechanisms. The architecture is evaluated on a set of planning problems using a simulated e-puck robot, including analysis of the system's behavior in response to noise and temporary blockages of the planned route. The system makes no explicit distinction between planning and execution phases, allowing continuous adaptation of the planned path. The proposed architecture exploits the dynamic field theory property of stability in relation to noise and changes in the environment. The neural dynamics are also exploited such that stay-or-switch action selection emerges where blockage of a planned path occurs; stay until the transient blockage is removed versus switch to an alternative route to the goal.},
author = {Billing, E. and Lowe, R. and Sandamirskaya, Y.},
doi = {10.1177/1059712315601188},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Billing, Lowe, Sandamirskaya/2015/Simultaneous planning and action neural-dynamic sequencing of elementary behaviors in robot navigation.pdf:pdf},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {dynamic field theory,goal directed behavior,plan,simultaneous planning and action},
mendeley-tags = {plan},
number = {5},
pages = {243--264},
title = {{Simultaneous planning and action: neural-dynamic sequencing of elementary behaviors in robot navigation}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/1059712315601188},
volume = {23},
year = {2015}
}
@inproceedings{Nasbe2014,
abstract = {Special issue with a variety of articles exploring the topic Deeper Learning},
author = {van Seijen, Harm and Sutton, Richard S.},
booktitle = {Proceedings of The 32nd International Conference on Machine Learning},
editor = {Bach, Francis and Blei, David},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/van Seijen, Sutton/2015/A Deeper Look at Planning as Learning from Replay.pdf:pdf},
keywords = {learning},
pages = {2314--2322},
series = {JMLR Workshop and Conference Proceedings},
title = {{A Deeper Look at Planning as Learning from Replay}},
url = {http://www.nasbe.org/wp-content/uploads/Standard{\_}Mar2014{\_}full{\_}online.pdf},
year = {2015}
}
@inproceedings{Niveau2010,
author = {Niveau, Alexandre and Fargier, Helen and Pralet, Cedric and Verfaillie, Gerard},
booktitle = {ECAI 2010: 19th European Conference on Artificial Intelligence, 16-20 August 2010, Lisbon, Portugal : Including Prestigious Applications of Artificial Intelligence (PAIS-2010) : Proceedings},
doi = {10.3233/978-1-60750-606-5-459},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Niveau et al/2010/Knowledge Compilation Using Interval Automata and Applications to Planning.pdf:pdf},
isbn = {9781607506065},
pages = {459--464},
title = {{Knowledge Compilation Using Interval Automata and Applications to Planning}},
year = {2010}
}
@article{Santos2012,
abstract = {In a role-playing game, finding optimal trajectories is one of the most important tasks. In fact, the strategy decision system becomes a key component of a game engine. Determining the way in which decisions are taken (e.g. online, batch or simulated) and the consumed resources in decision making (e.g. execution time, memory) will influence, to a major degree, the game performance. When classical search algorithms such as A * can be used, they are the very first option. Nevertheless, such methods rely on precise and complete models of the search space so there are many interesting scenarios where its application is not possible, and hence, model free methods for sequential decision making under uncertainty are the best choice. In this paper, we propose a heuristic planning strategy to incorporate, into a Dyna agent, the ability of heuristic-search in path-finding. The proposed Dyna-H algorithm selects branches more likely to produce outcomes than other branches, just as A * does. However, unlike A *, it has the advantages of a model-free online reinforcement learning algorithm. We evaluate our proposed algorithm against the one-step Q-learning and Dyna-Q algorithms and found that the Dyna-H, with its advantages, produced clearly superior results. ?? 2011 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1101.4003v3},
author = {Santos, Matilde and {Martin H.}, Jose Antonio and Lopez, Victoria and Botella, Guillermo},
doi = {10.1016/j.knosys.2011.09.008},
eprint = {arXiv:1101.4003v3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Santos et al/2012/Dyna-H A heuristic planning reinforcement learning algorithm applied to role-playing game strategy decision systems.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {A-star,Decision-making,Heuristic-search,Path-finding,Reinforcement-learning},
pages = {28--36},
publisher = {Elsevier B.V.},
title = {{Dyna-H: A heuristic planning reinforcement learning algorithm applied to role-playing game strategy decision systems}},
url = {http://dx.doi.org/10.1016/j.knosys.2011.09.008},
volume = {32},
year = {2012}
}
@incollection{Leake1997,
abstract = {Case-based reasoning depends on multiple knowledge sources beyond the case library, including knowledge about case adaptation and criteria for similarity assessment. Because hand coding this knowledge accounts for a large part of the knowledge acquisition burden for developing CBR systems, it is appealing to acquire it by learning, and CBR is a promising learning method to apply. This observation suggests developing case-based CBR systems, CBR systems whose components themselves use CBR. However, despite early interest in case-based approaches to CBR, this method has received comparatively little attention. Open questions include how case-based components of a CBR system should be designed, the amount of knowledge acquisition effort they require, and their effectiveness. This paper investigates these questions through a case study of issues addressed, methods used, and results achieved by a case-based planning system that uses CBR to guide its case adaptation and similarity assessment. The paper discusses design considerations and presents empirical results that support the usefulness of case-based CBR, that point to potential problems and tradeoffs, and that directly demonstrate the overlapping roles of different CBR knowledge sources. The paper closes with general lessons about case-based CBR and areas for future research.},
author = {Leake, David and Kinley, Andrew and Wilson, David},
booktitle = {Case-Based Reasoning Research and Development},
doi = {10.1007/3-540-63233-6_507},
editor = {Leake, David B. and Plaza, Enric},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Leake, Kinley, Wilson/1997/A case study of case-based CBR.pdf:pdf},
isbn = {3-540-63233-6},
keywords = {plan},
mendeley-tags = {plan},
pages = {371--382},
series = {Lecture Notes in Computer Science},
title = {{A case study of case-based CBR}},
url = {http://dx.doi.org/10.1007/3-540-63233-6{\_}507{\%}5Cnhttp://link.springer.com/chapter/10.1007{\%}2F3-540-63233-6{\_}507},
year = {1997}
}
@inproceedings{Hertle2012,
author = {Hertle, Andreas and Dornhege, Christian and Keller, Thomas and Nebel, Bernhard},
booktitle = {ECAI 2012: 20h European Conference on Artificial Intelligence: Proceedings},
doi = {10.3233/978-1-61499-098-7-402},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hertle et al/2012/Planning with Semantic Attachments An Object-Oriented View.pdf:pdf},
isbn = {9781614990987},
keywords = {plan},
mendeley-tags = {plan},
pages = {402--407},
title = {{Planning with Semantic Attachments : An Object-Oriented View}},
year = {2012}
}
@inproceedings{Panteleev2012,
address = {Белгород},
author = {Пантелеев, М. Г.},
booktitle = {Тринадцатая национальная конференция по искусственному интеллекту с международным участием КИИ-2012 (16-20 октября 2012 г., г. Белгород, Россия): Труды конференции},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Пантелеев/2012/Концепция построения интеллектуальных агентов реального времени на основе модели опережающего итеративного планирования.pdf:pdf},
keywords = {plan},
language = {russian},
mendeley-tags = {plan},
pages = {25--33},
publisher = {Изд-во БГТУ},
title = {{Концепция построения интеллектуальных агентов реального времени на основе модели опережающего итеративного планирования}},
volume = {3},
year = {2012}
}
@inproceedings{Bylander1992,
author = {Bylander, Tom},
booktitle = {Proceedings of the First Conference (AIPS 92)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bylander/1992/Complexity Results for Planning.pdf:pdf},
pages = {20--27},
title = {{Complexity Results for Planning}},
url = {http://www.ijcai.org/Past Proceedings/IJCAI-91-VOL1/PDF/043.pdf},
year = {1992}
}
@incollection{Palamara2009,
author = {Palamara, Pier Francesco and Ziparo, Vittorio a and Iocchi, Luca and Nardi, Daniele and Lima, Pedro},
booktitle = {RoboCup 2008: Robot Soccer World Cup XII},
editor = {Iocchi, Luca and Matsubara, Hitoshi and Weitzenfeld, Alfredo and Zhou, Changjiu},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Palamara et al/2009/Teamwork Design Based on Petri Net Plans.pdf:pdf},
pages = {200--211},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Teamwork Design Based on Petri Net Plans}},
year = {2009}
}
@article{Borrajo2015,
abstract = {Case-based planning (CBP) is an approach to automated planning that tries to save computational effort by reusing previously found solutions. In 2001, Spalazzi published a survey of work in CBP; here, we present an updated overview of systems that have contributed to the evolution of the field or addressed some issues related to planning by reuse in a novel way. The article presents relevant planners so that readers gain insight into the operation of these systems. This analysis will allow readers to understand the approaches both in the quality of the solutions and in the complexity of finding them.},
author = {Borrajo, Daniel and Roub{\'{i}}{\v{c}}kov{\'{a}}, Anna and Serina, Ivan},
doi = {10.1145/2674024},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Borrajo, Roub{\'{i}}{\v{c}}kov{\'{a}}, Serina/2015/Progress in Case-Based Planning.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {Case-based planning,automated planning},
number = {2},
pages = {1--39},
title = {{Progress in Case-Based Planning}},
url = {http://doi.acm.org/10.1145/2674024},
volume = {47},
year = {2015}
}
@article{Slaney2001,
abstract = {Contemporary AI shows a healthy trend away from artificial problems towards real-world applications. Less healthy, however, is the fashionable disparagement of `toy' domains: when properly approached, these domains can at the very least support meaningful systematic experiments, and allow features relevant to many kinds of reasoning to be abstracted and studied. A major reason why they have fallen into disrepute is that superficial understanding of them has resulted in poor experimental methodology and consequent failure to extract useful information. This paper presents a sustained investigation of one such toy: the (in)famous Blocks World planning problem, and provides the level of understanding required for its effective use as a benchmark. Our results include methods for generating random problems for systematic experimentation, the best domain-specific planning algorithms against which AI planners can be compared, and observations establishing the average plan quality of near-optimal methods. We also study the distribution of hard/easy instances, and identify the structure that AI planners must be able to exploit in order to approach Blocks World successfully.},
author = {Slaney, John and Thi{\'{e}}baux, Sylvie},
doi = {10.1016/S0004-3702(00)00079-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Slaney, Thi{\'{e}}baux/2001/Blocks World revisited.pdf:pdf},
isbn = {5006598239},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {approximation algorithms,blocks world,hard problems,planning benchmarks,random},
month = {jan},
number = {1-2},
pages = {119--153},
title = {{Blocks World revisited}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370200000795},
volume = {125},
year = {2001}
}
@article{Auslander2014a,
abstract = {Executing complex plans for coordinating the behaviors of multiple heterogeneous agents often requires setting several parameters. For example, we are developing a decision aid for deploying a set of autonomous vehicles to perform situation assessment in a disaster relief operation. Our system, the Situated Decision Process (SDP), uses parameterized plans to coordinate these vehicles. However, no model exists for setting the values of these parameters. We describe a case-based reasoning solution for this problem and report on its utility in simulated scenarios, given a case library that represents only a small percentage of the problem space. We found that our agents, when executing plans generated using our case-based algorithm on problems with high uncertainty, performed significantly better than when executing plans using baseline approaches.},
author = {Auslander, Brian and Apker, Thomas and Aha, David W},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Auslander, Apker, Aha/2014/Case-Based Parameter Selection for Plans Coordinating Autonomous Vehicle Teams.pdf:pdf},
isbn = {03029743 (ISSN)},
issn = {16113349},
journal = {Proceedings of the Twenty-Second International Conference on Case-Based Reasoning},
keywords = {case-based reasoning,parameter selection,robotic control},
pages = {32--47},
title = {{Case-Based Parameter Selection for Plans: Coordinating Autonomous Vehicle Teams}},
volume = {2},
year = {2014}
}
@article{Bonet2009,
abstract = {Point-based algorithms and RTDP-Bel are approximate methods for solving POMDPs that replace the full updates of parallel value iteration by faster and more effective updates at selected beliefs. An important difference between the two methods is that the former adopt Sondik's representation of the value function, while the latter uses a tabular representation and a discretization function. The algorithms, however, have not been compared up to now, because they target different POMDPs: discounted POMDPs on the one hand, and Goal POMDPs on the other. In this paper, we bridge this representational gap, showing how to transform discounted POMDPs into Goal POMDPs, and use the transformation to compare RTDP-Bel with point-based algorithms over the existing discounted benchmarks. The results appear to contradict the conventional wisdom in the area showing that RTDP-Bel is competitive, and sometimes superior to point-based algorithms in both quality and time. 1},
author = {Bonet, Blai and Geffner, H{\'{e}}ctor},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bonet, Geffner/2009/Solving POMDPs RTDP-Bel vs. point-based algorithms.pdf:pdf},
isbn = {9781577354260},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Planning and Scheduling},
pages = {1641--1646},
title = {{Solving POMDPs: RTDP-Bel vs. point-based algorithms}},
year = {2009}
}
@article{DeGiacomo2015,
abstract = {This work proposes a novel high-level paradigm, agent planning programs, for modeling agents behavior, which suitably mixes automated planning with agent-oriented programming. Agent planning programs are finite-state programs, possibly containing loops, whose atomic instructions consist of a guard, a maintenance goal, and an achievement goal, which act as precondition-invariance-postcondition assertions in program specification. Such programs are to be executed in possibly nondeterministic planning domains and their execution requires generating plans that meet the goals specified in the atomic instructions, while respecting the program control flow. In this paper, we define the problem of automatically synthesizing the required plans to execute an agent planning program, propose a solution technique based on model checking of two-player game structures, and use it to characterize the worst-case computational complexity of the problem as EXPTIME-complete. Then, we consider the case of deterministic domains and propose a different technique to solve agent planning programs, which is based on iteratively solving classical planning problems and on exploiting goal preferences and plan adaptation methods. Finally, we study the effectiveness of this approach for deterministic domains through an experimental analysis on well-known planning domains.},
author = {{De Giacomo}, Giuseppe and Gerevini, Alfonso Emilio and Patrizi, Fabio and Saetti, Alessandro and Sardina, Sebastian},
doi = {10.1016/j.artint.2015.10.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/De Giacomo et al/2015/Agent planning programs.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {agent-oriented programming,plan},
mendeley-tags = {plan},
pages = {64--106},
publisher = {Elsevier B.V.},
title = {{Agent planning programs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370215001563},
volume = {231},
year = {2015}
}
@article{Rankooh2015,
author = {Rankooh, Masood Feyzbakhsh},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rankooh/2015/ITSAT An Efficient SAT-Based Temporal Planner.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
keywords = {plan},
mendeley-tags = {plan},
pages = {541--632},
title = {{ITSAT: An Efficient SAT-Based Temporal Planner}},
volume = {53},
year = {2015}
}
@article{McAllester1991,
abstract = {This paper presents a simple, sound, complete, and systematic algorithm for domain independent STRIPS planning. Simplicity is achieved by starting with a ground procedure and then applying a general, and independently verifiable, lifting transformation. Previous planners have been designed directly as lifted procedures. Our ground procedure is a ground version of Tate's NONLINE procedure. In Tate's procedure one is not required to determine whether a prerequisite of a step in an unfinished plan is guarateed to hold in all linearizations. This allows Tate's procedure to avoid the use of Chapman's modal truth criterion. Systematicity is the property that the same plan, or partial plan, is never examined more than once. Systematicity is achieved through a simple modification of Tate's procedure.},
author = {McAllester, David and Rosenblitt, David},
doi = {10.1.1.52.5065},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/McAllester, Rosenblitt/1991/Systematic Nonlinear Planning.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/McAllester, Rosenblitt/1991/Systematic Nonlinear Planning(2).pdf:pdf},
isbn = {0262510596},
journal = {Proceedings of the Ninth National Conference on Artificial Intelligence AAAI-91},
keywords = {plan},
mendeley-tags = {plan},
pages = {634--639},
title = {{Systematic Nonlinear Planning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4442{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {1991}
}
@incollection{Borges2015,
author = {Borges, Andr{\'{e}} P. and Dordal, Osmar B. and Ribeiro, Richardson and {\'{A}}vila, Br{\'{a}}ulio C. and Scalabrin, Edson E.},
booktitle = {Enterprise Information Systems},
doi = {10.1007/978-3-319-29133-8_10},
editor = {Hammoudi, Slimane and Maciaszek, Leszek and Teniente, Ernest and Camp, Olivier and Cordeiro, Jos{\'{e}}},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Borges et al/2015/Generation of Economical Driving Plans Using Continuous Case-Based Planning.pdf:pdf},
isbn = {9783319291321},
issn = {18651348},
pages = {192--213},
publisher = {Springer International Publishing},
series = {Lecture Notes in Business Information Processing},
title = {{Generation of Economical Driving Plans Using Continuous Case-Based Planning}},
url = {http://link.springer.com/10.1007/978-3-319-29133-8{\_}10},
year = {2015}
}
