Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Donadello2017,
abstract = {Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that the use of background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.},
archivePrefix = {arXiv},
arxivId = {1705.08968},
author = {Donadello, Ivan and Serafini, Luciano and d'Avila Garcez, Artur},
eprint = {1705.08968},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)/Donadello, Serafini, Garcez/Donadello, Serafini, Garcez - 2017 - Logic Tensor Networks for Semantic Image Interpret.pdf:pdf},
journal = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)},
keywords = {Machine Learning: Knowledge-based Learning,Robotics and Vision: Vision and Perception,Uncertainty in AI: Uncertainty in AI},
pages = {1596--1602},
title = {{Logic Tensor Networks for Semantic Image Interpretation}},
url = {http://arxiv.org/abs/1705.08968},
year = {2017}
}
@article{Besold2017,
abstract = {The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.},
archivePrefix = {arXiv},
arxivId = {1711.03902},
author = {Besold, Tarek R. and d'Avila Garcez, Artur and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and Kuehnberger, Kai-Uwe and Lamb, Luis C. and Lowd, Daniel and Lima, Priscila Machado Vieira and de Penning, Leo and Pinkas, Gadi and Poon, Hoifung and Zaverucha, Gerson},
eprint = {1711.03902},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Besold et al/Besold et al. - 2017 - Neural-Symbolic Learning and Reasoning A Survey and Interpretation.pdf:pdf},
pages = {1--58},
title = {{Neural-Symbolic Learning and Reasoning: A Survey and Interpretation}},
url = {http://arxiv.org/abs/1711.03902},
year = {2017}
}
@article{Smolensky2014,
abstract = {Mental representations have continuous as well as discrete, combinatorial aspects. For example, while predominantly discrete, phonological representations also vary continuously, as evidenced by instrumental studies of both grammatically-­‐‑induced sound alternations and speech errors. Can an integrated theoretical framework address both aspects of structure? The framework we introduce here, Gradient Symbol Processing, characterizes the emergence of grammatical macrostructure from the Parallel Distributed Processing microstructure (McClelland {\&} Rumelhart, 1986) of language processing. The mental representations that emerge, Distributed Symbol Systems, have both combinatorial and gradient structure. They are processed through Subsymbolic Optimization-­‐‑Quantization, in which an optimization process favoring representations that satisfy well-­‐‑formedness constraints operates in parallel with a distributed quantization process favoring discrete symbolic structures. We apply a particular instantiation of this framework, $\lambda$-­‐‑ Diffusion Theory, to phonological production. Simulations of the resulting model suggest that Gradient Symbol Processing offers a way to unify accounts of discrete grammatical competence with both discrete and continuous patterns in language performance.},
author = {Smolensky, Paul and Goldrick, Matthew and Mathis, Donald},
doi = {10.1111/cogs.12047},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Smolensky, Goldrick, Mathis/Smolensky, Goldrick, Mathis - 2014 - Optimization and quantization in gradient symbol systems A framework for integrating the continuous.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Combinatorial structure,Distributed representation,Harmonic grammar,Optimization,Selection,Speech errors},
number = {6},
pages = {1102--1138},
pmid = {23802807},
title = {{Optimization and quantization in gradient symbol systems: A framework for integrating the continuous and the discrete in cognition}},
volume = {38},
year = {2014}
}
