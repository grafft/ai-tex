Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Bolotova2011,
author = {Болотова, Ю. А. and Спицын, В. Г. and Фомин, А. Э.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Известия Томского политехнического университета/Болотова, Спицын, Фомин/Болотова, Спицын, Фомин - 2011 - Применение модели иерархической временной памяти в распознавании изображений.pdf:pdf},
journal = {Известия Томского политехнического университета},
keywords = {evolutionary algorithm,hierarchical temporal memory model,in vision,pattern recognition,time and hierarchical components,в пространстве,задачи распознавания образов,понимания речи и ориентации,чтения текстов,яв},
language = {russian},
number = {5},
pages = {60--63},
title = {{Применение модели иерархической временной памяти в распознавании изображений}},
volume = {318},
year = {2011}
}
@unpublished{Byrne2015,
abstract = {In the decade since Jeff Hawkins proposed Hierarchical Temporal Memory (HTM) as a model of neocortical computation, the theory and the algorithms have evolved dramatically. This paper presents a detailed description ofHTM's Cortical Learning Algorithm (CLA), including for the first time a rigorous mathematical formulation of all aspects of the computations. Prediction As- sisted CLA (paCLA), a refinement of the CLA, is presented, which is both closer to the neuroscience and adds significantly to the computational power. Finally, we summarise the key functions of neocortex which are expressed in paCLA implementations. An Open Source project, Comportex, is the leading implementation of this evolving theory of the brain.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.08255v2},
author = {Byrne, Fergal},
eprint = {arXiv:1509.08255v2},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Byrne/Byrne - 2015 - Encoding Reality Prediction-Assisted Cortical Learning Algorithm in Hierarchical Temporal Memory.pdf:pdf},
pages = {1--28},
title = {{Encoding Reality: Prediction-Assisted Cortical Learning Algorithm in Hierarchical Temporal Memory}},
year = {2015}
}
@phdthesis{Bolotova2013,
author = {Болотова, Ю. А.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Болотова/Болотова - 2013 - Алгоритмы обработки и анализа изображений иерархической временной сетью.pdf:pdf},
language = {russian},
pages = {24},
school = {Томский Государственный университет},
title = {{Алгоритмы обработки и анализа изображений иерархической временной сетью}},
year = {2013}
}
@article{Bitzer2015,
abstract = {Even for simple perceptual decisions, the mechanisms that the brain employs are still under debate. Although current consensus states that the brain accumulates evidence extracted from noisy sensory information, open questions remain about how this simple model relates to other perceptual phenomena such as flexibility in decisions, decision-dependent modulation of sensory gain, or confidence about a decision. We propose a novel approach of how perceptual decisions are made by combining two influential formalisms into a new model. Specifically, we embed an attractor model of decision making into a probabilistic framework that models decision making as Bayesian inference. We show that the new model can explain decision making behaviour by fitting it to experimental data. In addition, the new model combines for the first time three important features: First, the model can update decisions in response to switches in the underlying stimulus. Second, the probabilistic formulation accounts for top-down effects that may explain recent experimental findings of decision-related gain modulation of sensory neurons. Finally, the model computes an explicit measure of confidence which we relate to recent experimental evidence for confidence computations in perceptual decision tasks.},
author = {Bitzer, Sebastian and Bruineberg, Jelle and Kiebel, Stefan J},
doi = {10.1371/journal.pcbi.1004442},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/PLoS computational biology/Bitzer, Bruineberg, Kiebel/Bitzer, Bruineberg, Kiebel - 2015 - A Bayesian Attractor Model for Perceptual Decision Making.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
number = {8},
pages = {e1004442},
pmid = {26267143},
publisher = {Public Library of Science},
title = {{A Bayesian Attractor Model for Perceptual Decision Making}},
url = {http://dx.doi.org/10.1371/journal.pcbi.1004442},
volume = {11},
year = {2015}
}
@article{CatenacciVolpi2014,
abstract = {We propose a computational model of perceptual categorization that fuses elements of grounded and sensorimotor theories of cognition with dynamic models of decision-making. We assume that category information consists in anticipated patterns of agent-environment interactions that can be elicited through overt or covert (simulated) eye movements, object manipulation, etc. This information is firstly encoded when category information is acquired, and then re-enacted during perceptual categorization. The perceptual categorization consists in a dynamic competition between attractors that encode the sensorimotor patterns typical of each category; action prediction success counts as "evidence" for a given category and contributes to falling into the corresponding attractor. The evidence accumulation process is guided by an active perception loop, and the active exploration of objects (e.g., visual exploration) aims at eliciting expected sensorimotor patterns that count as evidence for the object category. We present a computational model incorporating these elements and describing action prediction, active perception, and attractor dynamics as key elements of perceptual categorizations. We test the model in three simulated perceptual categorization tasks, and we discuss its relevance for grounded and sensorimotor theories of cognition. {\textcopyright} 2014 Elsevier Ltd.},
author = {{Catenacci Volpi}, Nicola and Quinton, Jean Charles and Pezzulo, Giovanni},
doi = {10.1016/j.neunet.2014.06.008},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural Networks/Catenacci Volpi, Quinton, Pezzulo/Catenacci Volpi, Quinton, Pezzulo - 2014 - How active perception and attractor dynamics shape perceptual categorization A computational.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Active vision,Dynamic choice,Hopfield networks,Perceptual categorization,Prediction},
pages = {1--16},
pmid = {25105744},
publisher = {Elsevier Ltd},
title = {{How active perception and attractor dynamics shape perceptual categorization: A computational model}},
url = {http://dx.doi.org/10.1016/j.neunet.2014.06.008},
volume = {60},
year = {2014}
}
@article{Sergin2006,
author = {Сергин, А. В.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Нейроинформатика/Сергин/Сергин - 2006 - Компьютерная модель восприятия иерархия объемлющих сенсорных характеристик.pdf:pdf},
journal = {Нейроинформатика},
language = {russian},
number = {06},
pages = {189--195},
title = {{Компьютерная модель восприятия: иерархия объемлющих сенсорных характеристик}},
volume = {26},
year = {2006}
}
@inproceedings{Suri2003a,
abstract = {A novel concept is proposed that uses active information gathering for recognizing objects on images. This novel concept mimics recent neurobiological insights on human control of eye movements (TD algorithm). TD algorithms are predictive reinforcement algorithms for learning of action sequences. In the proposed framework, standard techniques, such as template matching, are used as processing steps. Each processing step compares a template of one part of the object with image locations and computes a value that describes how well the template matches. A TD algorithm is trained on many images to optimize the sequence of processing steps by providing feedback whether the final object recognition was correct or incorrect. After training, the algorithm searches for template matches with the sequence of templates and locations that are most promising for recognition of a certain object. This object recognition strategy resembles active information gathering by saccadic eye movements.},
author = {Suri, Roland E.},
booktitle = {International Conference on Integration of Knowledge Intensive Multi-Agent Systems, 2003.},
doi = {10.1109/KIMAS.2003.1245074},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/International Conference on Integration of Knowledge Intensive Multi-Agent Systems, 2003/Suri/Suri - 2003 - A biologically-inspired concept for active image recognition.pdf:pdf},
keywords = {active,algorithm,algorithms,analysis,artificial,concept,eye,gathering,image,information,intelligence},
pages = {379--384},
title = {{A biologically-inspired concept for active image recognition}},
year = {2003}
}
@inproceedings{Morse,
author = {Morse, Anthony F and Ziemke, Tom},
booktitle = {Proceedings of the 31th Annual Conference of the Cognitive Sosciety},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 31th Annual Conference of the Cognitive Sosciety/Morse, Ziemke/Morse, Ziemke - 2009 - Action, Detection, and Perception A Computational Model of the Relation Between Movement and Orientatio.pdf:pdf},
keywords = {action,actionism,computational modeling,cortical,detection,embodiment,enaction,perception},
pages = {585--590},
title = {{Action, Detection, and Perception: A Computational Model of the Relation Between Movement and Orientation Selectivity in the Cerebral Cortex}},
year = {2009}
}
@article{Dehaene2003,
abstract = {The subjective experience of perceiving visual stimuli is accompanied by objective neuronal activity patterns such as sustained activity in primary visual area (V1), amplification of perceptual processing, correlation across distant regions, joint parietal, frontal, and cingulate activation, gamma-band oscillations, and P300 waveform. We describe a neuronal network model that aims at explaining how those physiological parameters may cohere with conscious reports. The model proposes that the step of conscious perception, referred to as access awareness, is related to the entry of processed visual stimuli into a global brain state that links distant areas including the prefrontal cortex through reciprocal connections, and thus makes perceptual information reportable by multiple means. We use the model to simulate a classical psychological paradigm: the attentional blink. In addition to reproducing the main objective and subjective features of this paradigm, the model predicts an unique property of nonlinear transition from nonconscious processing to subjective perception. This all-or-none dynamics of conscious perception was verified behaviorally in human subjects.},
author = {Dehaene, Stanislas and Sergent, Claire and Changeux, Jean-Pierre},
doi = {10.1073/pnas.1332574100},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Dehaene, Sergent, Changeux/Dehaene, Sergent, Changeux - 2003 - A neuronal network model linking subjective reports and objective.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Animals,Attention,Attention: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Consciousness,Consciousness: physiology,Haplorhini,Humans,Models,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Psychological,Visual Perception,Visual Perception: physiology},
number = {14},
pages = {8520--5},
pmid = {12829797},
title = {{A neuronal network model linking subjective reports and objective physiological data during conscious perception}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=166261{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {100},
year = {2003}
}
@article{Carpenter1987,
author = {Carpenter, Gaila and Grossberg, Stephen},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Computer Vision, Graphics and Image Processing/Carpenter, Grossberg/Carpenter, Grossberg - 1987 - A Massively Parallel Architecture for a Self-Organizing Neural Pattern Recognition Machine.pdf:pdf},
journal = {Computer Vision, Graphics and Image Processing},
keywords = {nn},
pages = {54--115},
title = {{A Massively Parallel Architecture for a Self-Organizing Neural Pattern Recognition Machine}},
volume = {37},
year = {1987}
}
@article{Oliva2001,
author = {Oliva, Aude and Torralba, Antonio},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/International Journal of Computer Vision/Oliva, Torralba/Oliva, Torralba - 2001 - Modeling the Shape of the Scene A Holistic Representation of the Spatial Envelope.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {energy spectrum,natural images,principal components,scene recognition,spatial layout},
number = {3},
pages = {145--175},
title = {{Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope}},
volume = {42},
year = {2001}
}
@article{Friston2009,
abstract = {This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs.},
author = {Friston, Karl and Kiebel, Stefan},
doi = {10.1098/rstb.2008.0300},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Philosophical transactions of the Royal Society of London. Series B, Biological sciences/Friston, Kiebel/Friston, Kiebel - 2009 - Predictive coding under the free-energy principle.pdf:pdf},
isbn = {0962-8436},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {birdsong,generative models,hierarchical,predictive coding},
number = {1521},
pages = {1211--1221},
pmid = {19528002},
title = {{Predictive coding under the free-energy principle}},
volume = {364},
year = {2009}
}
@article{Yu2014,
abstract = {We introduce the proto-object model of visual clutter perception. This unsupervised model segments an image into superpixels, then merges neighboring superpixels that share a common color cluster to obtain proto-objects-defined here as spatially extended regions of coherent features. Clutter is estimated by simply counting the number of proto-objects. We tested this model using 90 images of realistic scenes that were ranked by observers from least to most cluttered. Comparing this behaviorally obtained ranking to a ranking based on the model clutter estimates, we found a significant correlation between the two (Spearman's $\rho$ = 0.814, p {\textless} 0.001). We also found that the proto-object model was highly robust to changes in its parameters and was generalizable to unseen images. We compared the proto-object model to six other models of clutter perception and demonstrated that it outperformed each, in some cases dramatically. Importantly, we also showed that the proto-object model was a better predictor of clutter perception than an actual count of the number of objects in the scenes, suggesting that the set size of a scene may be better described by proto-objects than objects. We conclude that the success of the proto-object model is due in part to its use of an intermediate level of visual representation-one between features and objects-and that this is evidence for the potential importance of a proto-object representation in many common visual percepts and tasks.},
author = {Yu, Chen-Ping and Samaras, Dimitris and Zelinsky, Gregory J.},
doi = {10.1167/14.7.4},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Journal of vision/Yu, Samaras, Zelinsky/Yu, Samaras, Zelinsky - 2014 - Modeling visual clutter perception using proto-object segmentation.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Computer Simulation,Crowding,Eye Movements,Eye Movements: physiology,Humans,Visual Perception,Visual Perception: physiology,Young Adult},
number = {7},
pages = {1--16},
pmid = {24904121},
title = {{Modeling visual clutter perception using proto-object segmentation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24904121},
volume = {14},
year = {2014}
}
@article{Efremova2013,
author = {Ефремова, Н А and Инуи, Тошио},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Искусственный интеллект и принятие решений/Ефремова, Инуи/Ефремова, Инуи - 2013 - Модель зрительной коры головного мозга для распознавания и классификации образов.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
language = {russian},
number = {1},
pages = {55--62},
title = {{Модель зрительной коры головного мозга для распознавания и классификации образов}},
year = {2013}
}
@article{Yu2015,
author = {Yu, Qiang and Member, Student and Yan, Rui and Tang, Huajin and Tan, Kay Chen and Li, Haizhou},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE transactions on neural networks and learning systems/Yu et al/Yu et al. - 2015 - A Spiking Neural Network System for Robust Sequence Recognition.pdf:pdf},
journal = {IEEE transactions on neural networks and learning systems},
pages = {1--15},
title = {{A Spiking Neural Network System for Robust Sequence Recognition}},
year = {2015}
}
@unpublished{Cui2015,
abstract = {The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, a recent study proposed hierarchical temporal memory (HTM) sequence memory as a theoretical framework for sequence learning in the cortex. In this paper, we analyze properties of HTM sequence memory and apply it to various sequence learning and prediction problems. We show the model is able to continuously learn a large number of variable-order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory and other sequence learning algorithms, including the autoregressive integrated moving average (ARIMA) model and long short-term memory (LSTM), on sequence prediction problems with both artificial and real-world data. The HTM model not only achieves comparable or better accuracy than state-of-the-art algorithms, but also exhibits a set of properties that is critical for sequence learning. These properties include continuous online learning, the ability to handle multiple predictions and branching sequences, robustness to sensor noise and fault tolerance, and good performance without task-specific hyper-parameters tuning. Therefore the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem, but is also applicable to a wide range of real-world problems such as discrete and continuous sequence prediction, anomaly detection, and sequence classification.},
archivePrefix = {arXiv},
arxivId = {1512.05463},
author = {Cui, Yuwei and Surpur, Chetan and Ahmad, Subutai and Hawkins, Jeff},
eprint = {1512.05463},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Cui et al/Cui et al. - 2015 - Continuous online sequence learning with an unsupervised neural network model.pdf:pdf},
pages = {12},
title = {{Continuous online sequence learning with an unsupervised neural network model}},
year = {2015}
}
@phdthesis{Greff2010,
abstract = {This thesis tackles the problem of sequence learning using Hierarchical Temporal Memory as a first step towards a framework for combined temoral and spatial inference. Hierarchical Temporal Memory (HTM) is a quite new technology (2008) inspired by the human cortex to do (spatial) classification. In this thesis, we extend the theoretical framework of HTMs enabling them to do sequence classification. The improved framework is implemented and used to evaluate the algorithms on artificial data. We show this approach to be a viable first step towards a joint inference.},
author = {Greff, Klaus},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Greff/Greff - 2010 - Extending Hierarchical Temporal Memory for Sequence Classification.pdf:pdf},
keywords = {HTM,Master Thesis,lista{\_}filtrada},
pages = {93},
school = {Technische Universit{\"{a}}t Kaiserslautern},
title = {{Extending Hierarchical Temporal Memory for Sequence Classification}},
url = {http://trac.assembla.com/qhtm/export/114/Thesis/DiplomaThesis.pdf},
year = {2010}
}
@article{Sergin2009,
author = {Сергин, В. Я.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Успехи физиологических наук/Сергин/Сергин - 2009 - Психофизиологические механизмы восприятия концепция объемлющих сенсорных характеристик.pdf:pdf},
journal = {Успехи физиологических наук},
language = {russian},
number = {4},
pages = {42--63},
title = {{Психофизиологические механизмы восприятия: концепция объемлющих сенсорных характеристик}},
volume = {40},
year = {2009}
}
@article{McCall2013,
abstract = {Human-level intelligent agents must autonomously navigate complex, dynamic, uncertain environments with bounded time and memory. This requires that they continually update a hierarchical, dynamic, probabilistic (uncertain) internal model of their current situation, via approximate Bayesian inference, incorporating both the sensory data and a generative model of its causes. Such modeling requires suitable representation at multiple levels of abstraction from the sub-symbolic, sensory level to the most abstract conceptual representation. To guide our approach, we identify principles for perceptual representation, perceptual inference, and the associated learning processes. Based on these, a predictive coding extension to the HTM Cortical Learning Algorithms, termed PC-CLA, is proposed as a foundational building block for the systems-level LIDA cognitive architecture. PC-CLA fleshes out LIDA's internal representations, memory, learning and attentional processes; and takes an initial step towards the comprehensive use of distributed and probabilistic (uncertain) representation throughout the architecture.},
author = {McCall, Ryan James and Franklin, Stan},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Second Annual Conference on Advances in Cognitive Systems/McCall, Franklin/McCall, Franklin - 2013 - Cortical Learning Algorithms with Predictive Coding for a Systems-Level Cognitive Architecture.pdf:pdf},
journal = {Second Annual Conference on Advances in Cognitive Systems},
pages = {149--166},
title = {{Cortical Learning Algorithms with Predictive Coding for a Systems-Level Cognitive Architecture}},
year = {2013}
}
@article{Cariani2004,
abstract = {This paper considers a space of possible temporal codes, surveys neurophysiological and psychological evidence for their use in nervous systems, and presents examples of neural timing networks that operate in the time-domain. Sensory qualities can be encoded temporally by means of two broad strategies: stimulus-driven temporal correlations (phase-locking) and stimulus-triggering of endogenous temporal response patterns. Evidence for stimulus-related spike timing patterns exists in nearly every sensory modality, and such information can be potentially utilized for representation of stimulus qualities, localization of sources, and perceptual grouping. Multiple strategies for temporal (time, frequency, and code-division) multiplexing of information for transmission and grouping are outlined. Using delays and multiplications (coincidences), neural timing networks perform time-domain signal processing operations to compare, extract and separate temporal patterns. Separation of synthetic double vowels by a recurrent neural timing network is used to illustrate how coherences in temporal fine structure can be exploited to build up and separate periodic signals with different fundamentals. Timing nets constitute a time-domain scene analysis strategy based on temporal pattern invariance rather than feature-based labeling, segregation and binding of channels. Further potential implications of temporal codes and computations for new kinds of neural networks are explored.},
author = {Cariani, Peter A.},
doi = {10.1109/TNN.2004.833305},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE transactions on neural networks a publication of the IEEE Neural Networks Council/Cariani/Cariani - 2004 - Temporal codes and computations for sensory representation and scene analysis.pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Action Potentials,Action Potentials: physiology,Afferent,Afferent: physiology,Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Taste,Taste: physiology,Time Factors,Visceral Afferents,Visceral Afferents: physiology,Visual Perception,Visual Perception: physiology},
number = {5},
pages = {1100--11},
pmid = {15484887},
title = {{Temporal codes and computations for sensory representation and scene analysis}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15484887},
volume = {15},
year = {2004}
}
@article{Kording2007,
abstract = {Perceptual events derive their significance to an animal from their meaning about the world, that is from the information they carry about their causes. The brain should thus be able to efficiently infer the causes underlying our sensory events. Here we use multisensory cue combination to study causal inference in perception. We formulate an ideal-observer model that infers whether two sensory cues originate from the same location and that also estimates their location(s). This model accurately predicts the nonlinear integration of cues by human subjects in two auditory-visual localization tasks. The results show that indeed humans can efficiently infer the causal structure as well as the location of causes. By combining insights from the study of causal inference with the ideal-observer approach to sensory cue combination, we show that the capacity to infer causal structure is not limited to conscious, high-level cognition; it is also performed continually and effortlessly in perception.},
author = {K{\"{o}}rding, Konrad P. and Beierholm, Ulrik and Ma, Wei Ji and Quartz, Steven and Tenenbaum, Joshua B. and Shams, Ladan},
doi = {10.1371/journal.pone.0000943},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/PloS ONE/K{\"{o}}rding et al/K{\"{o}}rding et al. - 2007 - Causal inference in multisensory perception.pdf:pdf},
issn = {1932-6203},
journal = {PloS ONE},
keywords = {Afferent,Afferent: physiology,Auditory Perception,Auditory Perception: physiology,Bayes Theorem,Brain,Brain: physiology,Cues,Humans,Neurons,Space Perception,Space Perception: physiology,Task Performance and Analysis,Visual Perception,Visual Perception: physiology},
number = {9},
pages = {e943},
pmid = {17895984},
title = {{Causal inference in multisensory perception}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1978520{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2007}
}
@article{Pietron2016,
author = {Pietron, Marcin and Wielgosz, Maciej and Wiatr, Kazimierz},
doi = {10.5220/0005706603460353},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 8th International Conference on Agents and Artificial Intelligence/Pietron, Wielgosz, Wiatr/Pietron, Wielgosz, Wiatr - 2016 - Parallel Implementation of Spatial Pooler in Hierarchical Tempo.pdf:pdf},
isbn = {978-989-758-172-4},
journal = {Proceedings of the 8th International Conference on Agents and Artificial Intelligence},
number = {Icaart},
pages = {346--353},
title = {{Parallel Implementation of Spatial Pooler in Hierarchical Temporal Memory}},
url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005706603460353},
volume = {2},
year = {2016}
}
@article{Briscoe2012,
author = {Briscoe, Robert and Schwenkler, John},
doi = {10.1111/cogs.12226},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Briscoe, Schwenkler/Briscoe, Schwenkler - 2012 - Conscious Vision in Action.pdf:pdf},
issn = {03640213},
keywords = {attention,consciousness,dorsal stream,dual visual systems,motor control,vision},
pages = {1--21},
title = {{Conscious Vision in Action}},
year = {2012}
}
@article{Rachkovskij2013,
abstract = {We present a new cognitive architecture named Associative-Projective Neural Networks (APNNs). APNNs have a multi-module, multi-level, and multi-modal design that works with an original scheme of sparse binary distributed representations to construct world models of varied complexity required for both task-specific and more general cognitive modeling. APNNs provide scalability and flexibility due to a number of design features. Internal representations of APNNs are sparse binary vectors of fixed dimensionality for items of various complexity and generality. Representations of input scalars, vectors, or compositional relational structures are constructed on-the-fly, so that similar items produce representations similar in terms of vector dot-products. Thus, for example, similarity of relational structures (taking into account similarity of their components, their grouping and order) can be estimated by dot-products of their representations, without the need to follow edges or to match vertices of underlying graphs. Decoding distributed representations through the input representations is also possible. Storage, retrieval, and decoding of distributed representations are implemented by efficient auto-associative memories; using distributed memories based on the idea of Hebb's cell assemblies additionally provides a natural tool for emergence of generalization hierarchies. In addition, we consider how APNNs account for representation grounding, deal with recent challenges for distributed representations, and present some open problems. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Rachkovskij, Dmitri A. and Kussul, Ernst M. and Baidyk, Tatiana N.},
doi = {10.1016/j.bica.2012.09.004},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/Rachkovskij, Kussul, Baidyk/Rachkovskij, Kussul, Baidyk - 2013 - Building a world model with structure-sensitive sparse binary distributed representations.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Associative memory,Associative-Projective Neural Networks,Binding,Distributed representations,Hierarchical relational structures,Vector symbolic architectures},
month = {jan},
pages = {64--86},
title = {{Building a world model with structure-sensitive sparse binary distributed representations}},
url = {http://dx.doi.org/10.1016/j.bica.2012.09.004 http://linkinghub.elsevier.com/retrieve/pii/S2212683X12000552},
volume = {3},
year = {2013}
}
@article{Hinton2013,
abstract = {It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine (RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights.},
author = {Hinton, Geoffrey},
doi = {10.1111/cogs.12049},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Science/Hinton/Hinton - 2013 - Where Do Features Come From.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Backpropagation,Boltzmann machines,Contrastive divergence,Deep learning,Distributed representations,Learning features,Learning graphical models,Variational learning},
pages = {1--24},
pmid = {23800216},
title = {{Where Do Features Come From?}},
year = {2013}
}
@article{Seen2008,
author = {Gorder, P. F.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Computing in Science and Engineering/Gorder/Gorder - 2008 - Computer Vision, Inspared by the Human Brain.pdf:pdf},
journal = {Computing in Science and Engineering},
title = {{Computer Vision, Inspared by the Human Brain}},
volume = {6},
year = {2008}
}
@article{Ferro2010,
author = {Ferro, Marcello and Ognibene, Dimitri and Pezzulo, Giovanni and Pirrelli, Vito},
doi = {10.3389/fnbot.2010.00006},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Frontiers in Neurorobotics/Ferro et al/Ferro et al. - 2010 - Reading as active sensing a computational model of gaze planning in word recognition.pdf:pdf},
journal = {Frontiers in Neurorobotics},
keywords = {active sensing,lexical representation network,prediction,reading,serial order encoding,som},
number = {June},
pages = {1--16},
title = {{Reading as active sensing : a computational model of gaze planning in word recognition}},
volume = {4},
year = {2010}
}
@article{Serre2007,
abstract = {We introduce a new general framework for the recognition of complex visual scenes, which is motivated by biology: We describe a hierarchical system that closely follows the organization of visual cortex and builds an increasingly complex and invariant feature representation by alternating between a template matching and a maximum pooling operation. We demonstrate the strength of the approach on a range of recognition tasks: From invariant single object recognition in clutter to multiclass categorization problems and complex scene understanding tasks that rely on the recognition of both shape-based as well as texture-based objects. Given the biological constraints that the system had to satisfy, the approach performs surprisingly well: It has the capability of learning from only a few training examples and competes with state-of-the-art systems. We also discuss the existence of a universal, redundant dictionary of features that could handle the recognition of most object categories. In addition to its relevance for computer vision, the success of this approach suggests a plausibility proof for a class of feedforward models of object recognition in cortex.},
author = {Serre, Thomas and Wolf, Lior and Bileschi, Stanley and Riesenhuber, Maximilian and Poggio, Tomaso},
doi = {10.1109/TPAMI.2007.56},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Transactions on Pattern Analysis and Machine Intelligence/Serre et al/Serre et al. - 2007 - Robust object recognition with cortex-like mechanisms.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Model,Neural network,Object recognition,Scene understanding,Visual cortex},
number = {3},
pages = {411--426},
pmid = {17224612},
title = {{Robust object recognition with cortex-like mechanisms}},
volume = {29},
year = {2007}
}
@article{Zhdanov2011,
author = {Жданов, А. А.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Механика, управление и информатика/Жданов/Жданов - 2011 - Биологически инспирированное техническое зрение в системах автономного искусственного интеллекта.pdf:pdf},
journal = {Механика, управление и информатика},
language = {russian},
number = {6},
pages = {245--267},
title = {{Биологически инспирированное техническое зрение в системах автономного искусственного интеллекта}},
year = {2011}
}
@inproceedings{Mai2013,
abstract = {This paper presents a simple strategy for perception-action of robots in indoor environments using Hierarchical Temporal Memory which is the theory of modeling the rationale of the neocortex. The main idea of the present study is that the input of the HTM network is images of objects that robot perceives in environment, and the output of HTM network is action, such as moving along the wall, moving away, opening, and moving forward, etc. Experiments results show that the proposed method can be applied for robot learning and navigation because it imitates humans' thinking mode to process the information it receives.},
author = {Mai, Xiaochun and Zhang, Xinzheng and Jin, Yichen and Yang, Yi and Zhang, Jianfen},
booktitle = {Proceeding of the IEEE International Conference on Robotics and Biomimetics (ROBIO)},
doi = {10.1109/ROBIO.2013.6739722},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceeding of the IEEE International Conference on Robotics and Biomimetics (ROBIO)/Mai et al/Mai et al. - 2013 - Simple Perception-Action Strategy Based on Hierarchical Temporal Memory.pdf:pdf},
isbn = {9781479927449},
pages = {1759--1764},
title = {{Simple Perception-Action Strategy Based on Hierarchical Temporal Memory}},
year = {2013}
}
@article{Kostavelis2012,
author = {Kostavelis, Ioannis and Gasteratos, Antonios},
doi = {10.1016/j.patrec.2011.11.017},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Pattern Recognition Letters/Kostavelis, Gasteratos/Kostavelis, Gasteratos - 2012 - On the optimization of Hierarchical Temporal Memory.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
number = {5},
pages = {670--676},
publisher = {Elsevier B.V.},
title = {{On the optimization of Hierarchical Temporal Memory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865511004077},
volume = {33},
year = {2012}
}
@inproceedings{Zou2011,
abstract = {Natural scenes in a video stream contain rich collections of visual transformations. In this paper, a generic neural network is built to learn visual invariance from videos in an unsupervised manner. We use temporal coherence to learn both visual transformations and features with complex invariances. Without fine tuning with labels, our invariant features are superior for classifying object in still images. The learned features out-perform features learned with sparsity in vision benchmarks Caltech-101, STL-10 and COIL-100.},
author = {Zou, Will Y. and Ng, Andrew Y. and Yu, Kai},
booktitle = {Neural Information Processing Systems (NIPS) Workshop on Deep Learning and Unsupervised Feature Learning},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neural Information Processing Systems (NIPS) Workshop on Deep Learning and Unsupervised Feature Learning/Zou, Ng, Yu/Zou, Ng, Yu - 2011 - Unsupervised learning of visual invariance with temporal coherence.pdf:pdf},
keywords = {Temporal Coherence},
title = {{Unsupervised learning of visual invariance with temporal coherence}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Unsupervised+learning+of+visual+invariance+with+temporal+coherence{\#}3},
year = {2011}
}
@article{Nguen2012,
author = {Нгуен, Т. Т. and Болотова, Ю. А. and Спицын, В. Г.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Научный вестник НГТУ/Нгуен, Болотова, Спицын/Нгуен, Болотова, Спицын - 2012 - Обработка данных видеопоследовательности в режиме реального времени на основе иерархической временной с.pdf:pdf},
journal = {Научный вестник НГТУ},
language = {russian},
number = {2},
pages = {33--43},
title = {{Обработка данных видеопоследовательности в режиме реального времени на основе иерархической временной сети}},
volume = {47},
year = {2012}
}
@article{Ma2012,
abstract = {Probability has played a central role in models of perception for more than a century, but a look at probabilistic concepts in the literature raises many questions. Is being Bayesian the same as being optimal? Are recent Bayesian models fundamentally different from classic signal detection theory models? Do findings of near-optimal inference provide evidence that neurons compute with probability distributions? This review aims to disentangle these concepts and to classify empirical evidence accordingly.},
author = {Ma, Wei Ji},
doi = {10.1016/j.tics.2012.08.010},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Trends in cognitive sciences/Ma/Ma - 2012 - Organizing probabilistic models of perception.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Algorithms,Bayes Theorem,Decision Making,Humans,Models,Perception,Perception: physiology,Psychological,Signal Detection,Statistical},
number = {10},
pages = {511--8},
pmid = {22981359},
publisher = {Elsevier Ltd},
title = {{Organizing probabilistic models of perception}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22981359},
volume = {16},
year = {2012}
}
@article{Lee2003,
abstract = {Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.},
author = {Lee, Tai Sing and Mumford, David},
doi = {10.1364/JOSAA.20.001434},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Journal of the Optical Society of America. A, Optics, image science, and vision/Lee, Mumford/Lee, Mumford - 2003 - Hierarchical Bayesian inference in the visual cortex.pdf:pdf},
isbn = {1084-7529 (Print)},
issn = {1084-7529},
journal = {Journal of the Optical Society of America. A, Optics, image science, and vision},
number = {7},
pages = {1434--1448},
pmid = {12868647},
title = {{Hierarchical Bayesian inference in the visual cortex}},
volume = {20},
year = {2003}
}
@article{Garalevicius2007,
abstract = {This paper explores an inferential system for recognizing visual patterns. The system is inspired by a recent memory- prediction theory and models the high-level architecture of the human neocortex. The paper describes the hierarchical architecture and recognition performance of this Bayesian model. A number of possibilities are analyzed for bringing the model closer to the theory, making it uniform, scalable, less biased and able to learn a larger variety of images and their transformations. The effect of these modifications on recognition accuracy is explored. We identify and discuss a number of both conceptual and practical challenges to the Bayesian approach as well as missing details in the theory that are needed to design a scalable and universal model.},
author = {Garalevicius, Saulius J},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/LAIRS Conference, Florida/Garalevicius/Garalevicius - 2007 - Memory-Prediction Framework for Pattern Recognition Performance and Suitability of the Bayesian Model of Visual Co.pdf:pdf},
journal = {LAIRS Conference, Florida},
keywords = {HTM,Hierarchical Temporal Memory,Jeff Hawkins,MPF,Memory-Prediction Framework,Numenta,On Intelligence,Saulius Garalevicius,artificial intelligence,belief propagation,belief revision,computer vision,cortical modeling,lista{\_}filtrada,neocortex,neural networks,neuroscience,pattern recognition},
pages = {92--97.},
title = {{Memory-Prediction Framework for Pattern Recognition: Performance and Suitability of the Bayesian Model of Visual Cortex}},
url = {https://www.aaai.org/Papers/FLAIRS/2007/Flairs07-018.pdf{\%}5Cnhttp://www.phillylac.org/prediction/Memory-Prediction paper.pdf{\%}5Cnhttp://www.phillylac.org/prediction/Memory-Prediction{\%}5Cnpaper.pdf},
year = {2007}
}
@article{Vityaev2012,
author = {Витяев, Е. Е. and Неупокоев, Н. В.},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Нейроинформатика/Витяев, Неупокоев/Витяев, Неупокоев - 2012 - Формальная модель восприятия и образа как неподвижной точки предвосхищений.pdf:pdf},
journal = {Нейроинформатика},
language = {russian},
number = {1},
pages = {28--41},
title = {{Формальная модель восприятия и образа как неподвижной точки предвосхищений}},
volume = {6},
year = {2012}
}
@inproceedings{Teo,
author = {Teo, Ching L. and Myers, Austin and Ferm, Cornelia and Aloimonos, Yiannis},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE International Conference on Robotics and Automation (ICRA)/Teo et al/Teo et al. - 2013 - Embedding High-Level Information into Low Level Vision Efficient Object Search in Clutter.pdf:pdf},
pages = {126--132},
title = {{Embedding High-Level Information into Low Level Vision: Efficient Object Search in Clutter}},
year = {2013}
}
@article{Wang2015a,
author = {Wang, Jinjun and Hou, Qiqi and Liu, Nan and Zhang, Shizhou},
doi = {10.1109/BigMM.2015.29},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/2015 IEEE International Conference on Multimedia Big Data/Wang et al/Wang et al. - 2015 - Model of Human Visual Cortex Inspired Computational Models for Visual Recognition.pdf:pdf},
isbn = {978-1-4799-8688-0},
journal = {2015 IEEE International Conference on Multimedia Big Data},
pages = {88--91},
title = {{Model of Human Visual Cortex Inspired Computational Models for Visual Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7153860},
year = {2015}
}
@article{Hawkins2009,
abstract = {In this paper, we propose a mechanism which the neocortex may use to store sequences of patterns. Storing and recalling sequences are necessary for making predictions, recognizing time-based patterns and generating behaviour. Since these tasks are major functions of the neocortex, the ability to store and recall time-based sequences is probably a key attribute of many, if not all, cortical areas. Previously, we have proposed that the neocortex can be modelled as a hierarchy of memory regions, each of which learns and recalls sequences. This paper proposes how each region of neocortex might learn the sequences necessary for this theory. The basis of the proposal is that all the cells in a cortical column share bottom-up receptive field properties, but individual cells in a column learn to represent unique incidences of the bottom-up receptive field property within different sequences. We discuss the proposal, the biological constraints that led to it and some results modelling it.},
author = {Hawkins, Jeff and George, Dileep and Niemasik, Jamie},
doi = {10.1098/rstb.2008.0322},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Philosophical transactions of the Royal Society of London. Series B, Biological sciences/Hawkins, George, Niemasik/Hawkins, George, Niemasik - 2009 - Sequence memory for prediction, inference and behaviour.pdf:pdf},
isbn = {0962-8436},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {1,during,function of the brain,hierarchical temporal memory,prediction,prediction and sequence memory,prediction is a ubiquitous,sequence memory,state-splitting,variable-order markov model},
pages = {1203--1209},
pmid = {19528001},
title = {{Sequence memory for prediction, inference and behaviour}},
volume = {364},
year = {2009}
}
@article{Zhang2012,
abstract = {Bio-inspired mapping methods have started a new trend in the robotics navigation area. In this paper, we propose a new map building framework based on the neocortex model: Hierarchical Temporary Memory (HTM). HTM has tree-shaped hierarchical structure and demonstrates structural and algorithmic properties of the human brain neocortex. We first treat the mapping problem as the object recognition problem, and design HTM network hierarchical structure. Secondly, the Speed Up Robust Features (SURF) descriptors were extracted from the grabbed images. These descriptors were further projected into visual words. The presence or absence of visual words consists of input data of HTM in the form of binary sequences. With the binary visual words sequences, HTM network stored or recognized the scene information which were reflected in the visual words, and the output of HTM was the related environment map. After training the HTM network, we evaluated it by two sets of environment data. The results show that the HTM based mapping strategy can build the environment map successfully and handle the loop closing problem with high performance.},
author = {Zhang, Xinzheng and Zhang, Jianfen and Rad, Ahmad B. and Mai, Xiaochun and Jin, Yichen},
doi = {10.1109/ROBIO.2012.6491012},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics/Zhang et al/Zhang et al. - 2012 - A novel mapping strategy based on neocortex model Pre-liminary results by hierarchical tempo.pdf:pdf},
isbn = {9781467321273},
journal = {Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics},
pages = {476--481},
title = {{A novel mapping strategy based on neocortex model: Pre-liminary results by hierarchical temporal memory}},
year = {2012}
}
@unpublished{Goertzel2011,
author = {Goertzel, Ben and Chen, Shuo},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Goertzel, Chen/Goertzel, Chen - 2016 - Notes on Semantic Hierarchical Temporal Memory for Perceptual, Motoric and Intentional Intelligence.pdf:pdf},
title = {{Notes on Semantic Hierarchical Temporal Memory for Perceptual, Motoric and Intentional Intelligence}},
year = {2016}
}
@article{Lerner2012,
abstract = {Localist models of spreading activation (SA) and models assuming distributed representations offer very different takes on semantic priming, a widely investigated paradigm in word recognition and semantic memory research. In this study, we implemented SA in an attractor neural network model with distributed representations and created a unified framework for the two approaches. Our models assume a synaptic depression mechanism leading to autonomous transitions between encoded memory patterns (latching dynamics), which account for the major characteristics of automatic semantic priming in humans. Using computer simulations, we demonstrated how findings that challenged attractor-based networks in the past, such as mediated and asymmetric priming, are a natural consequence of our present model's dynamics. Puzzling results regarding backward priming were also given a straightforward explanation. In addition, the current model addresses some of the differences between semantic and associative relatedness and explains how these differences interact with stimulus onset asynchrony in priming experiments.},
author = {Lerner, Itamar and Bentin, Shlomo and Shriki, Oren},
doi = {10.1111/cogs.12007},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive science/Lerner, Bentin, Shriki/Lerner, Bentin, Shriki - 2012 - Spreading activation in an attractor network with latching dynamics automatic semantic priming revisited.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {Humans,Memory,Neural Networks (Computer),Reaction Time,Repetition Priming,Semantics},
number = {8},
pages = {1339--82},
pmid = {23094718},
title = {{Spreading activation in an attractor network with latching dynamics: automatic semantic priming revisited}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3490422{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {36},
year = {2012}
}
@article{Rebhan2011,
abstract = {Humans selectively process and store details about the vicinity based on their knowledge about the scene, the world and their current task. In doing so, only those pieces of information are extracted from the visual scene that is required for solving a given task. In this paper, we present a flexible system architecture along with a control mechanism that allows for a task-dependent representation of a visual scene. Contrary to existing approaches, our system is able to acquire information selectively according to the demands of the given task and based on the system's knowledge. The proposed control mechanism decides which properties need to be extracted and how the independent processing modules should be combined, based on the knowledge stored in the system's long-term memory. Additionally, it ensures that algorithmic dependencies between processing modules are resolved automatically, utilizing procedural knowledge which is also stored in the long-term memory. By evaluating a proof-of-concept implementation on a real-world table scene, we show that, while solving the given task, the amount of data processed and stored by the system is considerably lower compared to processing regimes used in state-of-the-art systems. Furthermore, our system only acquires and stores the minimal set of information that is relevant for solving the given task.},
author = {Rebhan, Sven and Eggert, Julian},
doi = {10.1007/s12559-010-9077-9},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive computation/Rebhan, Eggert/Rebhan, Eggert - 2011 - Dynamic, Task-Related and Demand-Driven Scene Representation.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive computation},
keywords = {30,attention {\'{a}} visual search,carl-legien-str,control {\'{a}},eggert,honda research institute europe,rebhan,s,scene representation {\'{a}} cognitive,{\'{a}} j},
number = {1},
pages = {124--145},
pmid = {21475691},
title = {{Dynamic, Task-Related and Demand-Driven Scene Representation}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3059823{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2011}
}
