Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Deco2015,
abstract = {The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks - in particular, network communities and hubs - support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.},
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L},
doi = {10.1038/nrn3963},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Deco et al/2015/Rethinking segregation and integration contributions of whole-brain modelling.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
number = {7},
pages = {430--439},
pmid = {26081790},
publisher = {Nature Publishing Group},
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}},
url = {http://www.nature.com.sire.ub.edu/nrn/journal/v16/n7/full/nrn3963.html},
volume = {16},
year = {2015}
}
@article{Glenberg2012,
abstract = {Evolution and the brain have done a marvelous job solving many tricky problems in action control, including problems of learning, hierarchical control over serial behavior, continuous recalibration, and fluency in the face of slow feedback. Given that evolution tends to be conservative, it should not be surprising that these solutions are exploited to solve other tricky problems, such as the design of a communication system. We propose that a mechanism of motor control, paired controller/predictor models, has been exploited for language learning, comprehension, and production. Our account addresses the development of grammatical regularities and perspective, as well as how linguistic symbols become meaningful through grounding in perception, action, and emotional systems. ?? 2011 Elsevier Srl.},
author = {Glenberg, Arthur M. and Gallese, Vittorio},
doi = {10.1016/j.cortex.2011.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Glenberg, Gallese/2012/Action-based language A theory of language acquisition, comprehension, and production.pdf:pdf},
isbn = {1973-8102 (Electronic)$\backslash$r0010-9452 (Linking)},
issn = {00109452},
journal = {Cortex},
keywords = {Embodiment,HMOSAIC model of action control,Language,Mirror neurons},
number = {7},
pages = {905--922},
pmid = {21601842},
publisher = {Elsevier Srl},
title = {{Action-based language: A theory of language acquisition, comprehension, and production}},
url = {http://dx.doi.org/10.1016/j.cortex.2011.04.010},
volume = {48},
year = {2012}
}
@article{Sandamirskaya2013,
abstract = {Dynamic Field Theory (DFT) is an established framework for modeling embodied cognition. In DFT, elementary cognitive functions such as memory formation, formation of grounded representations, attentional processes, decision making, adaptation, and learning emerge from neuronal dynamics. The basic computational element of this framework is a Dynamic Neural Field (DNF). Under constraints on the time-scale of the dynamics, the DNF is computationally equivalent to a soft winner-take-all (WTA) network, which is considered one of the basic computational units in neuronal processing. Recently, it has been shown how a WTA network may be implemented in neuromorphic hardware, such as analog Very Large Scale Integration (VLSI) device. This paper leverages the relationship between DFT and soft WTA networks to systematically revise and integrate established DFT mechanisms that have previously been spread among different architectures. In addition, I also identify some novel computational and architectural mechanisms of DFT which may be implemented in neuromorphic VLSI devices using WTA networks as an intermediate computational layer. These specific mechanisms include the stabilization of working memory, the coupling of sensory systems to motor dynamics, intentionality, and autonomous learning. I further demonstrate how all these elements may be integrated into a unified architecture to generate behavior and autonomous learning.},
author = {Sandamirskaya, Yulia},
doi = {10.3389/fnins.2013.00276},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Sandamirskaya/2014/Dynamic neural fields as a step toward cognitive neuromorphic architectures.pdf:pdf},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {Dynamic Neural Fields,autonomous learning,cognitive neuromorphic architecture,neural dynamics,soft winner take all},
pages = {276},
pmid = {24478620},
title = {{Dynamic neural fields as a step toward cognitive neuromorphic architectures}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnins.2013.00276/abstract{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3898057/},
volume = {7},
year = {2014}
}
@article{Fu2014a,
author = {Fu, XiaoLan and Cai, LianHong and Liu, Ye YongJin and Jia, Jia and Chen, WenFeng and Yi, Zhang and Zhao, GuoZhen and Liu, Ye YongJin and Wu, ChangXu},
doi = {10.1007/s11432-013-4911-9},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fu et al/2014/A computational cognition model of perception, memory, and judgment.pdf:pdf},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {computational cognition model,judgment,memory,perception},
language = {english},
number = {3},
pages = {1--15},
title = {{A computational cognition model of perception, memory, and judgment}},
url = {http://link.springer.com/10.1007/s11432-013-4911-9},
volume = {57},
year = {2014}
}
@inproceedings{Tarasov2016,
author = {Тарасов, В. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Тарасов/2016/От спецификации когнитонов и инженерии интенций к обобщенной архитектуре деятельности агентов.pdf:pdf},
language = {russian},
pages = {94--114},
title = {{От спецификации когнитонов и инженерии интенций к обобщенной архитектуре деятельности агентов}},
year = {2016}
}
@article{Plebe2016a,
abstract = {Neural computation has an influential role in the study of human capacities and behaviors. It has been the dominant approach in the vision science of the last half century, and it is currently one of the fundamental methods of investigation for most higher cognitive func- tions. Yet, neurocomputational approaches to moral behavior are lacking. Computational modeling in general has been scarcely pursued in morality, and existent non-neural attempts have failed to account for the mental processes involved in morality. In this paper we argue that recently the situation has evolved in a way that subverted the insufficient knowledge on the basic organization of moral cognition in brain circuits, making the project of modeling morality in neurocomputational terms feasible. We will present an original architecture that combines reinforcement learning and Hebbian learning, aimed at simulating forms of moral behavior in a simple artificial context. The relationship between language and morality is controversial. In the analytic tradition of philosophy, morality is essentially the lan- guage of morals. On the other side, current cognitive ethology has shown how non human species display behaviors that are surprisingly similar to those prescribed by human ethics. Nevertheless, morality in humans is deeply entrenched with language, and the semantics of words like ‘wrong' resists consensual explanations. The model here proposed includes an auditory processing pathway, with the purpose of showing how the coding of ‘‘wrong”, even if highly simplified with respect to its rich content in natural language, can emerge in the course of moral learning.},
author = {Plebe, Alessio},
doi = {10.1016/j.cogsys.2015.12.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Plebe/2016/What is ‘wrong' in a neural model.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {amygdala,moral cognition,neural computation,orbitofrontal cortex,self-organization},
pages = {4--14},
title = {{What is ‘wrong' in a neural model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041716000085},
volume = {39},
year = {2016}
}
@article{Griffiths2010,
abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.},
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Griffiths et al/2010/Probabilistic models of cognition exploring representations and inductive biases.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Bias (Epidemiology),Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Models,Predictive Value of Tests,Probability,Psychological},
number = {8},
pages = {357--64},
pmid = {20576465},
publisher = {Elsevier Ltd},
title = {{Probabilistic models of cognition: exploring representations and inductive biases}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20576465},
volume = {14},
year = {2010}
}
@article{Pulvermuller2010,
abstract = {Action and perception are functionally linked in the brain, but a hotly debated question is whether perception and comprehension of stimuli depend on motor circuits. Brain language mechanisms are ideal for addressing this question. Neuroimaging investigations have found specific motor activations when subjects understand speech sounds, word meanings and sentence structures. Moreover, studies involving transcranial magnetic stimulation and patients with lesions affecting inferior frontal regions of the brain have shown contributions of motor circuits to the comprehension of phonemes, semantic categories and grammar. These data show that language comprehension benefits from frontocentral action systems, indicating that action and perception circuits are interdependent.},
author = {Pulverm{\"{u}}ller, Friedemann and Fadiga, Luciano},
doi = {10.1038/nrn2811},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Pulverm{\"{u}}ller, Fadiga/2010/Active perception sensorimotor circuits as a cortical basis for language.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Language,Neural Pathways,Neural Pathways: physiology,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology},
number = {5},
pages = {351--360},
pmid = {20383203},
publisher = {Nature Publishing Group},
title = {{Active perception: sensorimotor circuits as a cortical basis for language.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20383203{\%}5Cnhttp://dx.doi.org/10.1038/nrn2811},
volume = {11},
year = {2010}
}
@article{Stankevich2006,
author = {Станкевич, Л. А. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Станкевич, Серебряков/2006/Когнитивные системы и агенты.pdf:pdf},
journal = {Труды СПИИРАН},
language = {russian},
number = {3},
pages = {71--87},
title = {{Когнитивные системы и агенты}},
volume = {1},
year = {2006}
}
@article{Fitch2014,
abstract = {Progress in understanding cognition requires a quantitative, theoretical framework, grounded in the other natural sciences and able to bridge between implementational, algorithmic and computational levels of explanation. I review recent results in neuroscience and cognitive biology that, when combined, provide key components of such an improved conceptual framework for contemporary cognitive science. Starting at the neuronal level, I first discuss the contemporary realization that single neurons are powerful tree-shaped computers, which implies a reorientation of computational models of learning and plasticity to a lower, cellular, level. I then turn to predictive systems theory (predictive coding and prediction-based learning) which provides a powerful formal framework for understanding brain function at a more global level. Although most formal models concerning predictive coding are framed in associationist terms, I argue that modern data necessitate a reinterpretation of such models in cognitive terms: as model-based predictive systems. Finally, I review the role of the theory of computation and formal language theory in the recent explosion of comparative biological research attempting to isolate and explore how different species differ in their cognitive capacities. Experiments to date strongly suggest that there is an important difference between humans and most other species, best characterized cognitively as a propensity by our species to infer tree structures from sequential data. Computationally, this capacity entails generative capacities above the regular (finite-state) level; implementationally, it requires some neural equivalent of a push-down stack. I dub this unusual human propensity "dendrophilia", and make a number of concrete suggestions about how such a system may be implemented in the human brain, about how and why it evolved, and what this implies for models of language acquisition. I conclude that, although much remains to be done, a neurally-grounded framework for theoretical cognitive science is within reach that can move beyond polarized debates and provide a more adequate theoretical future for cognitive biology. {\textcopyright} 2014.},
author = {Fitch, W. Tecumseh},
doi = {10.1016/j.plrev.2014.04.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fitch/2014/Toward a computational framework for cognitive biology Unifying approaches from cognitive neuroscience and comparative cognition.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {Cognitive science,Comparative cognition,Computational neuroscience,Formal language theory,Mathematical psychology,Neurolinguistics},
number = {3},
pages = {329--364},
pmid = {24969660},
publisher = {Elsevier B.V.},
title = {{Toward a computational framework for cognitive biology: Unifying approaches from cognitive neuroscience and comparative cognition}},
url = {http://dx.doi.org/10.1016/j.plrev.2014.04.005},
volume = {11},
year = {2014}
}
@article{Thilakarathne2015a,
abstract = {Human awareness under different circumstances is complex and non-trivial to understand. Nevertheless, due to the importance of awareness for safety and efficiency in many domains (e.g., the aviation domain), it is necessary to study the processes behind situation awareness, to eliminate possible errors in action selection that may lead to disasters. Interesting models for situation awareness have been presented, mainly from an ecological psychology perspective, but they are debatable with respect to the latest neurocognitive evidences. With the developments in brain imaging and recording techniques, more and more detailed information on complex cognitive processes becomes available. This provides room to further investigate the mechanisms behind many cognitive phenomena, including situation awareness. This paper presents a computational cognitive agent model for situation awareness from the perspective of action selection, which is inspired by neurocognitive evidences. The model integrates bottom-up and top-down cognitive processes, related to various cognitive states: perception, desires, attention, intention, (prior and retrospective) awareness, ownership, feeling, and communication. Based on the model, various cognitive effects can be explained, such as perceptual load, predictive processes, inferential processes, cognitive controlling, unconscious bias, and conscious bias. A model like this will be useful in domains that benefit from complex simulations of socio-technical systems (e.g. the aviation domain) based on computational models of human behaviour. In such domains, existing agent-based simulations are limited, since most of the agent models do not include realistic nature-inspired processes. The validity of the model is illustrated based on simulations for the aviation domain, focusing on a particular situation where an agent has biased perception, poor comprehension, habitual driven projection, and conflict between prior and retrospective effects on action execution.},
author = {Thilakarathne, Dilhan J.},
doi = {10.1016/j.bica.2015.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Thilakarathne/2015/Modelling of situation awareness with perception, attention, and prior and retrospective awareness(2).pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Thilakarathne/2015/Modelling of situation awareness with perception, attention, and prior and retrospective awareness.pdf:pdf},
isbn = {2212-683X},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Bottom-up,Cognitive modelling,Prior and retrospective awareness,Situation awareness,Top-down,prior and retrospective,situation awareness},
pages = {77--104},
publisher = {Elsevier B.V.},
title = {{Modelling of situation awareness with perception, attention, and prior and retrospective awareness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000195 http://dx.doi.org/10.1016/j.bica.2015.04.010},
volume = {12},
year = {2015}
}
@article{Chernavsky2012a,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Чернавская et al/2012/Процесс мышления в контексте динамической теории информации. Часть II понятие «образ» и «символ» как инструменты моделирования процесса.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {3},
pages = {46--65},
title = {{Процесс мышления в контексте динамической теории информации. Часть II: понятие «образ» и «символ» как инструменты моделирования процесса мышления средствами нейрокомпьютинга}},
volume = {2},
year = {2012}
}
@article{Vartanov2011,
author = {Вартанов, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вартанов/2011/Механизмы семантики человек - нейрон - модель.pdf:pdf},
journal = {Нейрокомпьютеры: разработка, применение},
keywords = {coding,consciousness,meaning,semantics,sign},
language = {russian},
number = {12},
pages = {54--64},
title = {{Механизмы семантики: человек - нейрон - модель}},
year = {2011}
}
@article{Martin2017,
author = {Martin, Andrea E. and Doumas, Leonidas A. A.},
doi = {10.1371/journal.pbio.2000663},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Martin, Doumas/2017/A mechanism for the cortical computation of hierarchical linguistic structure.pdf:pdf},
isbn = {1111111111},
issn = {1545-7885},
journal = {PLOS Biology},
number = {3},
pages = {e2000663},
title = {{A mechanism for the cortical computation of hierarchical linguistic structure}},
url = {http://dx.plos.org/10.1371/journal.pbio.2000663},
volume = {15},
year = {2017}
}
@inproceedings{Ragni2012,
author = {Ragni, Marco and Neubert, Stefanie},
booktitle = {ECAI 2012: 20h European Conference on Artificial Intelligence: Proceedings},
doi = {10.3233/978-1-61499-098-7-666},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Ragni, Neubert/2012/Solving Raven's IQ-tests An AI and Cognitive Modeling Approach.pdf:pdf},
isbn = {9781614990987},
pages = {666--671},
title = {{Solving Raven's IQ-tests : An AI and Cognitive Modeling Approach}},
year = {2012}
}
@article{Chernavsky2012b,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Чернавская et al/2012/Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {2},
pages = {25--41},
title = {{Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления}},
volume = {1},
year = {2012}
}
@article{2010b,
author = {Кулинич, Александр},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Кулинич/2010/Компьютерные системы моделирования когнитивных карт подходы и методы.pdf:pdf},
journal = {Проблемы Управления},
language = {russian},
pages = {2 -- 16},
title = {{Компьютерные системы моделирования когнитивных карт: подходы и методы}},
url = {https://m.cyberleninka.ru/article/n/kompyuternye-sistemy-modelirovaniya-kognitivnyh-kart-podhody-i-metody},
volume = {№3},
year = {2010}
}
@book{Vityaev2006,
address = {Новосибирск},
author = {Витяев, Е. Е.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Витяев/2006/Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов Монография.pdf:pdf},
language = {russian},
pages = {293},
publisher = {Новосиб. гос. ун-т},
title = {{Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов: Монография}},
year = {2006}
}
@incollection{Dobnik2013,
author = {Dobnik, Simon and Cooper, Robin},
booktitle = {Constraint Solving and Language Processing},
doi = {10.1007/978-3-642-41578-4_5},
editor = {Duchier, Denys and Parmentier, Yannick},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dobnik, Cooper/2013/Modelling language, action, and perception in Type Theory with Records.pdf:pdf},
keywords = {action,formal semantics,language,learning and classification,perception,scriptions,spatial de-},
pages = {70--91},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling language, action, and perception in Type Theory with Records}},
year = {2013}
}
@article{Chernavsky2012c,
abstract = {Рассматривается одна из возможных схем нейропроцессорной конструкции, способной решать задачи, традиционно относимые к мышлению и творчеству. Выделена подсистема, обрабатывающая образную информацию; ее важная составляющая — ―размытое множество‖, содержащее всю образную информацию, доступную системе. Выделена подсистема, способная решать логические задачи. Подсистема распознавания процесса и построения прогноза позволяет ввести понятие континуального времени. Показано, что решение творческих задач (при недостатке информации или противоречивости алгоритмов) в символьной подсистеме невозможно и требует обращения к размытому (образному) множеству.},
author = {Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А. and Чернавская, О. Д.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Чернавский et al/2012/Процесс мышления в контексте динамической теории информации. Часть III один из вариантов конструкции нейропроцессоров для моделирования.pdf:pdf},
journal = {Сложные системы},
keywords = {мышление,научное творчество,нейропроцессор,самоорганизация,символьная система},
language = {russian},
number = {4},
pages = {25--37},
title = {{Процесс мышления в контексте динамической теории информации. Часть III: один из вариантов конструкции нейропроцессоров для моделирования процесса мышления}},
volume = {3},
year = {2012}
}
@article{Habenschuss2013,
abstract = {Experimental data from neuroscience suggest that a substantial amount of knowledge is stored in the brain in the form of probability distributions over network states and trajectories of network states. We provide a theoretical foundation for this hypothesis by showing that even very detailed models for cortical microcircuits, with data-based diverse nonlinear neurons and synapses, have a stationary distribution of network states and trajectories of network states to which they converge exponentially fast from any initial state. We demonstrate that this convergence holds in spite of the non-reversibility of the stochastic dynamics of cortical microcircuits. We further show that, in the presence of background network oscillations, separate stationary distributions emerge for different phases of the oscillation, in accordance with experimentally reported phase-specific codes. We complement these theoretical results by computer simulations that investigate resulting computation times for typical probabilistic inference tasks on these internally stored distributions, such as marginalization or marginal maximum-a-posteriori estimation. Furthermore, we show that the inherent stochastic dynamics of generic cortical microcircuits enables them to quickly generate approximate solutions to difficult constraint satisfaction problems, where stored knowledge and current inputs jointly constrain possible solutions. This provides a powerful new computing paradigm for networks of spiking neurons, that also throws new light on how networks of neurons in the brain could carry out complex computational tasks such as prediction, imagination, memory recall and problem solving.},
author = {Habenschuss, Stefan and Jonke, Zeno and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003311},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Habenschuss, Jonke, Maass/2013/Stochastic Computations in Cortical Microcircuit Models.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pages = {e1003311},
pmid = {24244126},
title = {{Stochastic Computations in Cortical Microcircuit Models}},
volume = {9},
year = {2013}
}
