Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{DeWolf2016,
abstract = {We present a spiking neuron model of the motor cortices and cerebellum of the motor control system. The model consists of anatomically organized spiking neurons encompassing premotor, primary motor, and cerebellar cortices. The model proposes novel neural computations within these areas to control a nonlinear three-link arm model that can adapt to unknown changes in arm dynamics and kinematic structure. We demonstrate the mathematical stability of both forms of adaptation, suggesting that this is a robust approach for common biological problems of changing body size (e.g. during growth), and unexpected dynamic perturbations (e.g. when moving through different media, such as water or mud). To demonstrate the plausibility of the proposed neural mechanisms, we show that the model accounts for data across 19 studies of the motor control system. These data include a mix of behavioural and neural spiking activity, across subjects performing adaptive and static tasks. Given this proposed characterization of the biological processes involved in motor control of the arm, we provide several experimentally testable predictions that distinguish our model from previous work.},
author = {DeWolf, Travis and Stewart, Terrence C. and Slotine, Jean-Jacques and Eliasmith, Chris},
doi = {10.1098/rspb.2016.2134},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the Royal Society B Biological Sciences/DeWolf et al/DeWolf et al. - 2016 - A spiking neural model of adaptive arm control.pdf:pdf},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {computational biology,neuroscience},
month = {nov},
number = {1843},
pages = {20162134},
pmid = {27903878},
title = {{A spiking neural model of adaptive arm control}},
url = {http://rspb.royalsocietypublishing.org/lookup/doi/10.1098/rspb.2016.2134},
volume = {283},
year = {2016}
}
@incollection{2018d,
address = {Ростов-на-Дону},
author = {Дайлиденок, И. Д. and Фроленкова, А. И.},
booktitle = {Информатика, управление и системный анализ: Труды V Всероссийской научной конференции молодых учёных с международным участием},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Информатика, управление и системный анализ Труды V Всероссийской научной конференции молодых учёных с международным участием/Дайлиденок, Фроленкова/Дайлиденок, Фроленкова - 2018 - Биологически правдоподобные.pdf:pdf;:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Информатика, управление и системный анализ Труды V Всероссийской научной конференции молодых учёных с международным участием/Дайлиденок, Фроленкова/Дайлиденок, Фроленкова - 2018 - Биологически правдоподоб(2).docx:docx},
keywords = {17-29-07051},
language = {russian},
mendeley-tags = {17-29-07051},
pages = {169--178},
publisher = {Мини-Тайп},
title = {{Биологически правдоподобные нейронные сети для выявления аномалий во временных последовательностях}},
year = {2018}
}
@article{Hassabis2017,
abstract = {The fields of neuroscience and artificial intelligence (AI) have a long and intertwined history. In more recent times, however, communication and collaboration between the two fields has become less commonplace. In this article, we argue that better understanding biological brains could play a vital role in building intelligent machines. We survey historical interactions between the AI and neuroscience fields and emphasize current advances in AI that have been inspired by the study of neural computation in humans and other animals. We conclude by highlighting shared themes that may be key for advancing future research in both fields. Hassabis et al. review how neuroscience has informed research in artificial intelligence. They argue that a better understanding of biological brains will play a vital role in building intelligent machines.},
archivePrefix = {arXiv},
arxivId = {1404.7282},
author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
doi = {10.1016/j.neuron.2017.06.011},
eprint = {1404.7282},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Neuron/Hassabis et al/Hassabis et al. - 2017 - Neuroscience-Inspired Artificial Intelligence.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
keywords = {artificial intelligence,brain,cognition,learning,neural network},
number = {2},
pages = {245--258},
pmid = {28728020},
publisher = {Elsevier Inc.},
title = {{Neuroscience-Inspired Artificial Intelligence}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.06.011},
volume = {95},
year = {2017}
}
@article{Madl2017,
abstract = {Computational cognitive models of spatial memory often neglect difficulties posed by the real world, such as sensory noise, uncertainty, and high spatial complexity. On the other hand, robotics is unconcerned with understanding biological cognition. Here, we describe a computational framework for robotic architectures aiming to function in realistic environments, as well as to be cognitively plausible. We motivate and describe several mechanisms towards achieving this despite the sensory noise and spatial complexity inherent in the physical world. We tackle error accumulation during path integration by means of Bayesian localization, and loop closing with sequential gradient descent. Finally, we outline a method for structuring spatial representations using metric learning and clustering. Crucially, unlike the algorithms of traditional robotics, we show that these mechanisms can be implemented in neuronal or cognitive models. We briefly outline a concrete implementation of the proposed framework as part of the LIDA cognitive architecture, and argue that this kind of probabilistic framework is well-suited for use in cognitive robotic architectures aiming to combine spatial functionality and psychological plausibility.},
author = {Madl, Tamas and Franklin, Stan and Chen, Ke and Trappl, Robert},
doi = {10.1016/j.cogsys.2017.08.002},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Cognitive Systems Research/Madl et al/Madl et al. - 2017 - A computational cognitive framework of spatial memory in brains and robots.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Bayesian brain,Cognitive architecture,Computational cognitive modeling,LIDA,Spatial memory},
pages = {147--172},
publisher = {Elsevier B.V.},
title = {{A computational cognitive framework of spatial memory in brains and robots}},
url = {https://doi.org/10.1016/j.cogsys.2017.08.002},
volume = {47},
year = {2017}
}
@article{Kansky2017,
abstract = {The recent adaptation of deep neural network-based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an object-oriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.},
archivePrefix = {arXiv},
arxivId = {1706.04317},
author = {Kansky, Ken and Silver, Tom and M{\'{e}}ly, David A. and Eldawy, Mohamed and L{\'{a}}zaro-Gredilla, Miguel and Lou, Xinghua and Dorfman, Nimrod and Sidor, Szymon and Phoenix, Scott and George, Dileep},
eprint = {1706.04317},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Kansky et al/Kansky et al. - 2017 - Schema Networks Zero-shot Transfer with a Generative Causal Model of Intuitive Physics.pdf:pdf},
isbn = {9781510855144},
title = {{Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics}},
url = {http://arxiv.org/abs/1706.04317},
year = {2017}
}
