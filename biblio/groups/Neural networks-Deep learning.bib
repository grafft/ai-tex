Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Mehta2014,
archivePrefix = {arXiv},
arxivId = {1410.3831},
author = {Mehta, Pankaj and Schwab, David J.},
eprint = {1410.3831},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mehta, Schwab/2014/An exact mapping between the Variational Renormalization Group and Deep Learning.pdf:pdf},
title = {{An exact mapping between the Variational Renormalization Group and Deep Learning}},
url = {http://arxiv.org/abs/1410.3831v1},
year = {2014}
}
@inproceedings{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
booktitle = {arXiv: 1312.5602},
eprint = {1312.5602},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mnih et al/2013/Playing Atari with Deep Reinforcement Learning.pdf:pdf},
pages = {1--9},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@book{Haikin2006,
address = {М.},
author = {Хайкин, С.},
edition = {2-е},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Хайкин/2006/Нейронные сети полный курс.djvu:djvu},
language = {russian},
pages = {1104},
publisher = {Издательский дом "Вильямс"},
title = {{Нейронные сети: полный курс}},
year = {2006}
}
@inproceedings{Szegedy2016,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible. We benchmark our methods on the ILSVRC 2012 classification challenge validation set and demonstrate substantial gains over the state of the art via to carefully factorized convolutions and aggressive regularization: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1002/2014GB005021},
eprint = {1512.00567},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Szegedy et al/2016/Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
isbn = {9781617796029},
issn = {08866236},
pages = {2818--2826},
pmid = {8190083},
title = {{Rethinking the Inception Architecture for Computer Vision}},
url = {http://arxiv.org/abs/1512.00567{\%}5Cnhttp://www.cv-foundation.org/openaccess/content{\_}cvpr{\_}2016/html/Szegedy{\_}Rethinking{\_}the{\_}Inception{\_}CVPR{\_}2016{\_}paper.html},
year = {2016}
}
@article{Blundell2016,
abstract = {State of the art deep reinforcement learning algorithms take many millions of interactions to attain human-level performance. Humans, on the other hand, can very quickly exploit highly rewarding nuances of an environment upon first discovery. In the brain, such rapid learning is thought to depend on the hippocampus and its capacity for episodic memory. Here we investigate whether a simple model of hippocampal episodic control can learn to solve difficult sequential decision-making tasks. We demonstrate that it not only attains a highly rewarding strategy significantly faster than state-of-the-art deep reinforcement learning algorithms, but also achieves a higher overall reward on some of the more challenging domains.},
archivePrefix = {arXiv},
arxivId = {1606.04460},
author = {Blundell, Charles and Uria, Benigno and Pritzel, Alexander and Li, Yazhe and Ruderman, Avraham and Leibo, Joel Z and Rae, Jack and Wierstra, Daan and Hassabis, Demis},
eprint = {1606.04460},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Blundell et al/2016/Model-Free Episodic Control.pdf:pdf},
month = {jun},
title = {{Model-Free Episodic Control}},
url = {http://arxiv.org/abs/1606.04460},
year = {2016}
}
@article{Scellier2016,
abstract = {We introduce Equilibrium Propagation (e-prop), a learning algorithm for energy-based models. This algorithm involves only one kind of neural computation both for the first phase (when the prediction is made) and the second phase (after the target is revealed) of training. Contrary to backpropagation in feedforward networks, there is no need for special computation in the second phase of our learning algorithm. Equilibrium Propagation combines features of Contrastive Hebbian Learning and Contrastive Divergence while solving the theoretical issues of both algorithms: the algorithm computes the exact gradient of a well defined objective function. Because the objective function is defined in terms of local perturbations, the second phase of e-prop corresponds to only nudging the first-phase fixed point towards a configuration that has lower cost value. In the case of a multi-layer supervised neural network, the output units are slightly nudged towards their target, and the perturbation introduced at the output layer propagates backward in the network. The theory developed in this paper shows that the signal 'back-propagated' during this second phase actually contains information about the error derivatives, which we use to implement a learning rule proved to perform gradient descent with respect to the objective function. Thus, this work makes it more plausible that a mechanism similar to backpropagation could be implemented by brains.},
archivePrefix = {arXiv},
arxivId = {1602.05179},
author = {Scellier, Benjamin and Bengio, Yoshua},
eprint = {1602.05179},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Scellier, Bengio/2016/Equilibrium Propagation Bridging the Gap Between Energy-Based Models and Backpropagation.pdf:pdf},
month = {feb},
title = {{Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation}},
url = {http://arxiv.org/abs/1602.05179},
year = {2016}
}
@article{Silver2016,
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks' to evaluate board positions and ‘policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8{\%} winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature16961},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Silver et al/2016/Mastering the game of Go with deep neural networks and tree search.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7587},
pages = {484--489},
pmid = {26819042},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go with deep neural networks and tree search}},
url = {http://dx.doi.org/10.1038/nature16961},
volume = {529},
year = {2016}
}
@article{Vinyals2016,
abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6{\%} to 93.2{\%} and from 88.0{\%} to 93.8{\%} on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
archivePrefix = {arXiv},
arxivId = {1606.04080},
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
eprint = {1606.04080},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vinyals et al/2016/Matching Networks for One Shot Learning.pdf:pdf},
journal = {arXiv},
title = {{Matching Networks for One Shot Learning}},
url = {http://arxiv.org/abs/1606.04080},
year = {2016}
}
@article{Fatahi2016,
author = {Fatahi, Mazdak and Ahmadi, Mahmood and Ahmadi, Arash and Shahsavari, Mahyar and Devienne, Philippe},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fatahi et al/2016/Towards an Spiking Deep Belief Network for Face Recognition Application.pdf:pdf},
isbn = {9781509035861},
number = {Iccke},
pages = {153--158},
title = {{Towards an Spiking Deep Belief Network for Face Recognition Application}},
year = {2016}
}
@article{Deng2013a,
abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
author = {Deng, Li and Yu, Dong},
doi = {10.1136/bmj.319.7209.0a},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Deng, Yu/2013/Deep Learning Methods and Applications.pdf:pdf},
isbn = {9781405161251},
issn = {09598138},
journal = {Foundations and Trends in Signal Processing},
number = {3-4},
pages = {197----387},
pmid = {10463930},
title = {{Deep Learning: Methods and Applications}},
volume = {7},
year = {2013}
}
@article{Hinton2006,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hinton, Osindero, Teh/2006/A fast learning algorithm for deep belief nets.pdf:pdf},
journal = {Neural Computation},
number = {7},
pages = {1527--1554},
title = {{A fast learning algorithm for deep belief nets}},
volume = {18},
year = {2006}
}
@inproceedings{Szegedy2014,
abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2015.7298594},
eprint = {1409.4842},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Szegedy et al/2014/Going Deeper with Convolutions.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
pages = {1--9},
pmid = {24920543},
title = {{Going Deeper with Convolutions}},
url = {http://arxiv.org/abs/1409.4842},
year = {2014}
}
@book{2018,
address = {СПб.},
author = {Николенко, С. and Кадурин, А. and Архангельская, Е.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Николенко, Кадурин, Архангельская/2018/Глубокое обучение.pdf:pdf},
isbn = {9785496025362},
pages = {480},
publisher = {Питер},
title = {{Глубокое обучение}},
year = {2018}
}
@book{Bengio2009b,
abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.},
archivePrefix = {arXiv},
arxivId = {submit/0500581},
author = {Bengio, Yoshua},
booktitle = {Foundations and Trends{\textregistered} in Machine Learning},
doi = {10.1561/2200000006},
eprint = {0500581},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bengio/2009/Learning Deep Architectures for AI.pdf:pdf},
isbn = {2200000006},
issn = {1935-8237},
number = {1},
pages = {1--127},
pmid = {17348934},
primaryClass = {submit},
title = {{Learning Deep Architectures for AI}},
volume = {2},
year = {2009}
}
@article{Lillicrap2015,
abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.},
archivePrefix = {arXiv},
arxivId = {1509.02971},
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
doi = {10.1561/2200000006},
eprint = {1509.02971},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Lillicrap et al/2015/Continuous control with deep reinforcement learning.pdf:pdf},
isbn = {2200000006},
issn = {1935-8237},
pmid = {24966830},
title = {{Continuous control with deep reinforcement learning}},
url = {http://arxiv.org/abs/1509.02971},
year = {2015}
}
@article{Cichy2016,
author = {Cichy, Radoslaw Martin and Khosla, Aditya and Pantazis, Dimitrios and Torralba, Antonio and Oliva, Aude},
doi = {10.1038/srep27755},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cichy et al/2016/Deep neural networks predict hierarchical spatio-temporal cortical dynamics of human visual object recognition.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {6},
pmid = {27282108},
title = {{Deep neural networks predict hierarchical spatio-temporal cortical dynamics of human visual object recognition}},
url = {http://dx.doi.org/10.1038/srep27755},
year = {2016}
}
@article{Smith2016,
abstract = {Recent research in the deep learning field has produced a plethora of new architectures. At the same time, a growing number of groups are applying deep learning to new applications. Some of these groups are likely to be composed of inexperienced deep learning practitioners who are baffled by the dizzying array of architecture choices and therefore opt to use an older architecture (i.e., Alexnet). Here we attempt to bridge this gap by mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures. In addition, we describe several architectural innovations, including Fractal of FractalNet network, Stagewise Boosting Networks, and Taylor Series Networks (our Caffe code and prototxt files is available at https://github.com/iPhysicist/CNNDesignPatterns). We hope others are inspired to build on our preliminary work.},
archivePrefix = {arXiv},
arxivId = {1611.00847},
author = {Smith, Leslie N. and Topin, Nicholay},
doi = {10.1051/0004-6361/201527329},
eprint = {1611.00847},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Smith, Topin/2016/Deep Convolutional Neural Network Design Patterns.pdf:pdf},
isbn = {9781611970685},
issn = {0004-6361},
journal = {arXiv},
month = {nov},
pages = {1--15},
title = {{Deep Convolutional Neural Network Design Patterns}},
url = {http://arxiv.org/abs/1511.06434 http://arxiv.org/abs/1611.00847},
year = {2016}
}
@article{Marblestone2016,
archivePrefix = {arXiv},
arxivId = {1606.03813},
author = {Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
doi = {10.1101/058545},
eprint = {1606.03813},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Marblestone, Wayne, Kording/2016/Towards an integration of deep learning and neuroscience.pdf:pdf},
keywords = {cognitive architecture,cost functions,neural networks,neuroscience},
title = {{Towards an integration of deep learning and neuroscience}},
year = {2016}
}
@article{Nøkland2016a,
abstract = {Artificial neural networks are most commonly trained with the back-propagation algorithm, where the gradient for learning is provided by back-propagating the error, layer by layer, from the output layer to the hidden layers. A recently discovered method called feedback-alignment shows that the weights used for propagating the error backward don't have to be symmetric with the weights used for propagation the activation forward. In fact, random feedback weights work evenly well, because the network learns how to make the feedback useful. In this work, the feedback alignment principle is used for training hidden layers more independently from the rest of the network, and from a zero initial condition. The error is propagated through fixed random feedback connections directly from the output layer to each hidden layer. This simple method is able to achieve zero training error even in convolutional networks and very deep networks, completely without error back-propagation. The method is a step towards biologically plausible machine learning because the error signal is almost local, and no symmetric or reciprocal weights are required. Experiments show that the test performance on MNIST and CIFAR is almost as good as those obtained with back-propagation for fully connected networks. If combined with dropout, the method achieves 1.45{\%} error on the permutation invariant MNIST task.},
archivePrefix = {arXiv},
arxivId = {1609.01596},
author = {N{\o}kland, Arild},
eprint = {1609.01596},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/N{\o}kland/2016/Direct Feedback Alignment Provides Learning in Deep Neural Networks.pdf:pdf},
journal = {ArXiv},
month = {sep},
title = {{Direct Feedback Alignment Provides Learning in Deep Neural Networks}},
url = {http://arxiv.org/abs/1609.01596},
year = {2016}
}
@article{Schmidhuber2015,
abstract = {In recent years, deep neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.7828v1},
author = {Schmidhuber, J},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {arXiv:1404.7828v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Schmidhuber/2015/Deep Learning in Neural Networks An Overview.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {85--117},
publisher = {Elsevier Ltd},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://arxiv.org/abs/1404.7828},
volume = {61},
year = {2015}
}
@misc{LeCun1989,
abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the US Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
booktitle = {Neural Computation},
doi = {10.1162/neco.1989.1.4.541},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/LeCun et al/1989/Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
number = {4},
pages = {541--551},
pmid = {1000111957},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
volume = {1},
year = {1989}
}
@article{Bengio2016,
abstract = {We consider deep multi-layered generative models such as Boltzmann machines or Hopfield nets in which computation (which implements inference) is both recurrent and stochastic, but where the recurrence is not to model sequential structure, only to perform computation. We find conditions under which a simple feedforward computation is a very good initialization for inference, after the input units are clamped to observed values. It means that after the feedforward initialization, the recurrent network is very close to a fixed point of the network dynamics, where the energy gradient is 0. The main condition is that consecutive layers form a good auto-encoder, or more generally that different groups of inputs into the unit (in particular, bottom-up inputs on one hand, top-down inputs on the other hand) are consistent with each other, producing the same contribution into the total weighted sum of inputs. In biological terms, this would correspond to having each dendritic branch correctly predicting the aggregate input from all the dendritic branches, i.e., the soma potential. This is consistent with the prediction that the synaptic weights into dendritic branches such as those of the apical and basal dendrites of pyramidal cells are trained to minimize the prediction error made by the dendritic branch when the target is the somatic activity. Whereas previous work has shown how to achieve fast negative phase inference (when the model is unclamped) in a predictive recurrent model, this contribution helps to achieve fast positive phase inference (when the target output is clamped) in such recurrent neural models.},
archivePrefix = {arXiv},
arxivId = {1606.01651},
author = {Bengio, Yoshua and Scellier, Benjamin and Bilaniuk, Olexa and Sacramento, Joao and Senn, Walter},
eprint = {1606.01651},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bengio et al/2016/Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically plausible.pdf:pdf},
title = {{Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically plausible}},
url = {http://arxiv.org/abs/1606.01651},
year = {2016}
}
@inproceedings{Novikov2015,
abstract = {Deep neural networks currently demonstrate state-of-the-art performance in sev- eral domains. At the same time, models of this class are very demanding in terms of computational resources. In particular, a large amount of memory is required by commonly used fully-connected layers, making it hard to use the models on low-end devices and stopping the further increase of the model size. In this paper we convert the dense weight matrices of the fully-connected layers to the Tensor Train [17] format such that the number of parameters is reduced by a huge factor and at the same time the expressive power of the layer is preserved. In particular, for the Very Deep VGG networks [21] we report the compression factor of the dense weight matrix of a fully-connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.06569v1},
author = {Novikov, Alexander and Vetrov, Dmitry and Podoprikhin, Dimitry and Osokin, Anton},
booktitle = {Advances in Neural Information Processing Systems 28 (NIPS 2015)},
eprint = {arXiv:1509.06569v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Novikov et al/2015/Tensorizing Neural Networks.pdf:pdf},
title = {{Tensorizing Neural Networks}},
url = {http://arxiv.org/pdf/1509.06569v1.pdf},
year = {2015}
}
@article{Szegedy2016b,
abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge},
archivePrefix = {arXiv},
arxivId = {1602.07261},
author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
eprint = {1602.07261},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Szegedy et al/2016/Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.pdf:pdf},
journal = {arXiv:1602.07261},
month = {feb},
title = {{Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning}},
url = {http://arxiv.org/abs/1602.07261},
year = {2016}
}
@article{Guo2014,
author = {Guo, Xiaoxiao and Lee, Honglak and Wang, Xiaoshi and Lewis, Richard L},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Guo et al/2014/Deep learning for real-time Atari game play using offline Monte Carlo tree search planning.pdf:pdf},
journal = {Nips},
pages = {1--9},
title = {{Deep learning for real-time Atari game play using offline Monte Carlo tree search planning}},
volume = {2600},
year = {2014}
}
@article{Goodfellow2015,
abstract = {www.deeplearningbook.org},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
doi = {10.1038/nmeth.3707},
eprint = {arXiv:1312.6184v5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Goodfellow, Bengio, Courville/2015/Deep Learning.pdf:pdf},
isbn = {9780521835688},
issn = {1548-7091},
journal = {Nature Methods},
number = {1},
pages = {35--35},
pmid = {10463930},
title = {{Deep Learning}},
url = {http://www.nature.com/doifinder/10.1038/nature14539{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nmeth.3707},
volume = {13},
year = {2015}
}
@article{VanHasselt2015,
abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether this harms performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
archivePrefix = {arXiv},
arxivId = {1509.06461},
author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
eprint = {1509.06461},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/van Hasselt, Guez, Silver/2015/Deep Reinforcement Learning with Double Q-learning.pdf:pdf},
journal = {arXiv:1509.06461 [cs]},
title = {{Deep Reinforcement Learning with Double Q-learning}},
url = {http://arxiv.org/abs/1509.06461{\%}5Cnhttp://www.arxiv.org/pdf/1509.06461.pdf},
year = {2015}
}
