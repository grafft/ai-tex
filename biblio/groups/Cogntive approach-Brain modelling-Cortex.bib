Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Felleman1991,
author = {Felleman, D. J. and van Essen, D. C.},
journal = {Cerebral Cortex},
number = {1},
pages = {1--47},
title = {{Distributed hierarchical processing in the primate cerebral cortex}},
volume = {1},
year = {1991}
}
@article{Riesenhuber1999,
author = {Riesenhuber, Maximilian and Poggio, Tomaso},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Riesenhuber, Poggio/1999/Hierarchical models of object recognition in cortex.pdf:pdf},
journal = {Nature Neuroscience},
number = {11},
pages = {1019--1025},
title = {{Hierarchical models of object recognition in cortex}},
volume = {2},
year = {1999}
}
@article{Martin2015,
abstract = {Neurons at early stages of the visual cortex signal elemental features, such as pieces of contour, but how these signals are organized into perceptual objects is unclear. Theories have proposed that spiking synchrony between these neurons encodes how features are grouped (binding-by-synchrony), but recent studies did not find the predicted increase in synchrony with binding. Here we propose that features are grouped to "proto-objects" by intrinsic feedback circuits that enhance the responses of the participating feature neurons. This hypothesis predicts synchrony exclusively between feature neurons that receive feedback from the same grouping circuit. We recorded from neurons in macaque visual cortex and used border-ownership selectivity, an intrinsic property of the neurons, to infer whether or not two neurons are part of the same grouping circuit. We found that binding produced synchrony between same-circuit neurons, but not between other pairs of neurons, as predicted by the grouping hypothesis. In a selective attention task, synchrony emerged with ignored as well as attended objects, and higher synchrony was associated with faster behavioral responses, as would be expected from early grouping mechanisms that provide the structure for object-based processing. Thus, synchrony could be produced by automatic activation of intrinsic grouping circuits. However, the binding-related elevation of synchrony was weak compared with its random fluctuations, arguing against synchrony as a code for binding. In contrast, feedback grouping circuits encode binding by modulating the response strength of related feature neurons. Thus, our results suggest a novel coding mechanism that might underlie the proto-objects of perception.},
author = {Martin, A. B. and von der Heydt, R.},
doi = {10.1523/JNEUROSCI.3590-14.2015},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Martin, von der Heydt/2015/Spike Synchrony Reveals Emergence of Proto-Objects in Visual Cortex.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {area v2,attention,binding,figure,ground organization,objects,spike synchrony},
number = {17},
pages = {6860--6870},
pmid = {25926461},
title = {{Spike Synchrony Reveals Emergence of Proto-Objects in Visual Cortex}},
url = {http://www.jneurosci.org/content/35/17/6860.short},
volume = {35},
year = {2015}
}
@inproceedings{Ananthanarayanan2009,
author = {Ananthanarayanan, Rajagopal and Esser, Steven K and Simon, Horst D and Modha, Dharmendra S},
booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Ananthanarayanan et al/2009/The Cat is Out of the Bag Cortical Simulations with 10 9 Neurons , 10 13 Synapses.pdf:pdf},
number = {c},
pages = {1--12},
title = {{The Cat is Out of the Bag : Cortical Simulations with 10 9 Neurons , 10 13 Synapses}},
year = {2009}
}
@article{Chalita2016,
author = {Chalita, Mario Andr{\'{e}}s and Lis, Diego and Caverzasi, Agust{\'{i}}n},
doi = {10.1016/j.bica.2016.03.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Chalita, Lis, Caverzasi/2016/Reinforcement learning in a bio-connectionist model based in the thalamo-cortical neural circuit.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {reinforcement learning},
pages = {45--63},
title = {{Reinforcement learning in a bio-connectionist model based in the thalamo-cortical neural circuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300159},
year = {2016}
}
@article{Deco2017,
author = {Deco, Gustavo and Kringelbach, Morten L},
doi = {10.1016/j.neuron.2017.03.028},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Deco, Kringelbach/2017/Hierarchy of Information Processing in the Brain A Novel ‘Intrinsic Ignition' Framework.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = {jun},
number = {5},
pages = {961--968},
pmid = {28595052},
publisher = {Elsevier Inc.},
title = {{Hierarchy of Information Processing in the Brain: A Novel ‘Intrinsic Ignition' Framework}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.03.028 http://linkinghub.elsevier.com/retrieve/pii/S0896627317302404},
volume = {94},
year = {2017}
}
@article{George2005,
abstract = {We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1109/IJCNN.2005.1556155},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George, Hawkins/2005/A hierarchical Bayesian model of invariant pattern recognition in the visual cortex.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)},
keywords = {Bayes methods,Bayesian model,Bayesian network structure,anatomical data,belief networks,cortical circuit,cortical phenomena,invariant visual pattern recognition,large scale architecture,learning (artificial intelligence),learning algorithm,micro-circuits,movement pattern,neural nets,object concept,pattern recognition,probability,probability sequence,temporal stability,visual cortex},
pages = {1812--1817},
pmid = {1556155},
title = {{A hierarchical Bayesian model of invariant pattern recognition in the visual cortex}},
volume = {3},
year = {2005}
}
@article{Pfister2014,
author = {Bauer, Roman and Zubler, Frederic and Pfister, Sabina and Hauri, Andreas and Pfeiffer, Michael and Muir, Dylan R and Douglas, Rodney J},
doi = {10.1371/journal.pcbi.1003994},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bauer et al/2014/Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks.pdf:pdf},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1003994},
title = {{Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks}},
volume = {10},
year = {2014}
}
@article{Lorincz2015b,
abstract = {Ever since the discovery of columnar structures, their function remained enigmatic. As a potential explanation for this puzzling function, we introduce the 'Columnar Machine'. We join two neural network types, Structured Sparse Coding (SSC) of generative nature exploiting sparse groups of neurons and Feed-Forward Networks (FFNs) into one architecture. Memories supporting recognition can be quickly loaded into SSC via supervision or can be learned by SSC in a self-organized manner. However, SSC evaluation is slow. We train FFNs for predicting the sparse groups and then the representation is computed by fast undercomplete methods. This two step procedure enables fast estimation of the overcomplete group sparse representations. The suggested architecture works fast and it is biologically plausible. Beyond the function of the minicolumnar structure it may shed light onto the role of fast feed-forward inhibitory thalamocortical channels and cortico-cortical feed-back connections. We demonstrate the method for natural image sequences where we exploit temporal structure and for a cognitive task where we explain the meaning of unknown words from their contexts.},
author = {Lorincz, Andras and Milacski, Zoltan and Pinter, Bal{\'{a}}zs and Vero, Anita L.},
doi = {10.1016/j.bica.2015.10.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Lorincz et al/2016/Columnar Machine Fast estimation of structured sparse codes.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Feed-forward inhibition,Minicolumns,Sparsity,Structured representation},
pages = {19--33},
title = {{Columnar Machine: Fast estimation of structured sparse codes}},
volume = {15},
year = {2016}
}
@article{Alexander2011,
abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
author = {Alexander, William H and Brown, Joshua W},
doi = {10.1038/nn.2921},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Alexander, Brown/2011/Medial prefrontal cortex as an action-outcome predictor.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Brain Mapping,Choice Behavior,Choice Behavior: physiology,Cognition,Cognition: physiology,Computer Simulation,Computer-Assisted,Conflict (Psychology),Humans,Image Processing,Magnetic Resonance Imaging,Models,Movement,Movement: physiology,Neurological,Oxygen,Oxygen: blood,Photic Stimulation,Predictive Value of Tests,Prefrontal Cortex,Prefrontal Cortex: blood supply,Prefrontal Cortex: physiology,Reward,Time Factors,Visual Perception},
number = {10},
pages = {1338--44},
pmid = {21926982},
publisher = {Nature Publishing Group},
title = {{Medial prefrontal cortex as an action-outcome predictor}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3183374{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@book{Mountcastle1998,
address = {Cambridge},
author = {Mountcastle, V. B.},
pages = {512},
publisher = {Harvard University Press},
title = {{Perceptual Neuroscience. The Cerebral Cortex}},
year = {1998}
}
@article{Holtmaat2009,
abstract = {Synaptic plasticity in adult neural circuits may involve the strengthening or weakening of existing synapses as well as structural plasticity, including synapse formation and elimination. Indeed, long-term in vivo imaging studies are beginning to reveal the structural dynamics of neocortical neurons in the normal and injured adult brain. Although the overall cell-specific morphology of axons and dendrites, as well as of a subpopulation of small synaptic structures, are remarkably stable, there is increasing evidence that experience-dependent plasticity of specific circuits in the somatosensory and visual cortex involves cell type-specific structural plasticity: some boutons and dendritic spines appear and disappear, accompanied by synapse formation and elimination, respectively. This Review focuses on recent evidence for such structural forms of synaptic plasticity in the mammalian cortex and outlines open questions.},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Holtmaat, Anthony and Svoboda, Karel},
doi = {10.1038/nrn2721},
eprint = {1309.2848v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Holtmaat, Svoboda/2009/Experience-dependent structural synaptic plasticity in the mammalian brain.pdf:pdf},
isbn = {1471-0048},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
number = {9},
pages = {647--658},
pmid = {19693029},
title = {{Experience-dependent structural synaptic plasticity in the mammalian brain.}},
volume = {10},
year = {2009}
}
@article{Solari2011,
abstract = {Interactions between the cerebral cortex, thalamus, and basal ganglia form the basis of cognitive information processing in the mammalian brain. Understanding the principles of neuroanatomical organization in these structures is critical to understanding the functions they perform and ultimately how the human brain works. We have manually distilled and synthesized hundreds of primate neuroanatomy facts into a single interactive visualization. The resulting picture represents the fundamental neuroanatomical blueprint upon which cognitive functions must be implemented. Within this framework we hypothesize and detail 7 functional circuits corresponding to psychological perspectives on the brain: consolidated long-term declarative memory, short-term declarative memory, working memory/information processing, behavioral memory selection, behavioral memory output, cognitive control, and cortical information flow regulation. Each circuit is described in terms of distinguishable neuronal groups including the cerebral isocortex (9 pyramidal neuronal groups), parahippocampal gyrus and hippocampus, thalamus (4 neuronal groups), basal ganglia (7 neuronal groups), metencephalon, basal forebrain, and other subcortical nuclei. We focus on neuroanatomy related to primate non-primary cortical systems to elucidate the basis underlying the distinct homotypical cognitive architecture. To display the breadth of this review, we introduce a novel method of integrating and presenting data in multiple independent visualizations: an interactive website (http://www.frontiersin.org/files/cognitiveconsilience/index.html) and standalone iPhone and iPad applications. With these tools we present a unique, annotated view of neuroanatomical consilience (integration of knowledge).},
author = {Solari, Soren Van Hout and Stoner, Rich},
doi = {10.3389/fnana.2011.00065},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Solari, Stoner/2011/Cognitive consilience Primate non-primary neuroanatomical circuits underlying cognition.pdf:pdf},
isbn = {1662-5129},
issn = {1662-5129},
journal = {Frontiers in Neuroanatomy},
keywords = {basal ganglia,cerebral cortex,circuitr,circuitry,cognition,consilience,isocortex,review{\_}neurophis,thalamus},
mendeley-tags = {review{\_}neurophis},
pages = {1--23},
pmid = {22194717},
title = {{Cognitive consilience: Primate non-primary neuroanatomical circuits underlying cognition}},
volume = {5},
year = {2011}
}
@article{Schwalger2017,
abstract = {Neural population equations such as neural mass or field models are widely used to study brain activity on a large scale. However, the relation of these models to the properties of single neurons is unclear. Here we derive an equation for several interacting populations at the mesoscopic scale starting from a microscopic model of randomly connected generalized integrate-and-fire neuron models. Each population consists of 50 -- 2000 neurons of the same type but different populations account for different neuron types. The stochastic population equations that we find reveal how spike-history effects in single-neuron dynamics such as refractoriness and adaptation interact with finite-size fluctuations on the population level. Efficient integration of the stochastic mesoscopic equations reproduces the statistical behavior of the population activities obtained from microscopic simulations of a full spiking neural network model. The theory describes nonlinear emergent dynamics like finite-size-induced stochastic transitions in multistable networks and synchronization in balanced networks of excitatory and inhibitory neurons. The mesoscopic equations are employed to rapidly simulate a model of a local cortical microcircuit consisting of eight neuron types. Our theory establishes a general framework for modeling finite-size neural population dynamics based on single cell and synapse parameters and offers an efficient approach to analyzing cortical circuits and computations.},
author = {Schwalger, Tilo and Deger, Moritz and Gerstner, Wulfram},
doi = {10.1371/journal.pcbi.1005507},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Schwalger, Deger, Gerstner/2017/Towards a theory of cortical columns From spiking neurons to interacting neural populations of finite size.pdf:pdf},
journal = {PLoS Computational biology},
number = {4},
pages = {1--63},
title = {{Towards a theory of cortical columns: From spiking neurons to interacting neural populations of finite size}},
url = {http://arxiv.org/abs/1611.00294{\%}0Ahttp://dx.doi.org/10.1371/journal.pcbi.1005507},
volume = {13},
year = {2017}
}
@article{Markram2015,
abstract = {We present a first-draft digital reconstruction of the microcircuitry of somatosensory cortex of juvenile rat. The reconstruction uses cellular and synaptic organizing principles to algorithmically reconstruct detailed anatomy and physiology from sparse experimental data. An objective anatomical method defines a neocortical volume of 0.29 ± 0.01 mm3 containing ∼31,000 neurons, and patch-clamp studies identify 55 layer-specific morphological and 207 morpho-electrical neuron subtypes. When digitally reconstructed neurons are positioned in the volume and synapse formation is restricted to biological bouton densities and numbers of synapses per connection, their overlapping arbors form ∼8 million connections with ∼37 million synapses. Simulations reproduce an array of in vitro and in vivo experiments without parameter tuning. Additionally, we find a spectrum of network states with a sharp transition from synchronous to asynchronous activity, modulated by physiological mechanisms. The spectrum of network states, dynamically reconfigured around this transition, supports diverse information processing strategies. PaperClip Video Abstract},
author = {Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael W. and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Kahou, Guy Antoine Atenekeng and Berger, Thomas K. and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean Denis and Delalondre, Fabien and Delattre, Vincent and Druckmann, Shaul and Dumusc, Raphael and Dynes, James and Eilemann, Stefan and Gal, Eyal and Gevaert, Michael Emiel and Ghobril, Jean Pierre and Gidon, Albert and Graham, Joe W. and Gupta, Anirudh and Haenel, Valentin and Hay, Etay and Heinis, Thomas and Hernando, Juan B. and Hines, Michael and Kanari, Lida and Keller, Daniel and Kenyon, John and Khazen, Georges and Kim, Yihwa and King, James G. and Kisvarday, Zoltan and Kumbhar, Pramod and Lasserre, S{\'{e}}bastien and {Le B{\'{e}}}, Jean Vincent and Magalh{\~{a}}es, Bruno R C and Merch{\'{a}}n-P{\'{e}}rez, Angel and Meystre, Julie and Morrice, Benjamin Roy and Muller, Jeffrey and Mu{\~{n}}oz-C{\'{e}}spedes, Alberto and Muralidhar, Shruti and Muthurasa, Keerthan and Nachbaur, Daniel and Newton, Taylor H. and Nolte, Max and Ovcharenko, Aleksandr and Palacios, Juan and Pastor, Luis and Perin, Rodrigo and Ranjan, Rajnish and Riachi, Imad and Rodr{\'{i}}guez, Jos{\'{e}} Rodrigo and Riquelme, Juan Luis and R{\"{o}}ssert, Christian and Sfyrakis, Konstantinos and Shi, Ying and Shillcock, Julian C. and Silberberg, Gilad and Silva, Ricardo and Tauheed, Farhan and Telefont, Martin and Toledo-Rodriguez, Maria and Tr{\"{a}}nkler, Thomas and {Van Geit}, Werner and D{\'{i}}az, Jafet Villafranca and Walker, Richard and Wang, Yun and Zaninetta, Stefano M. and Defelipe, Javier and Hill, Sean L. and Segev, Idan and Sch{\"{u}}rmann, Felix},
doi = {10.1016/j.cell.2015.09.029},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Markram et al/2015/Reconstruction and Simulation of Neocortical Microcircuitry.pdf:pdf},
isbn = {1097-4172 (Electronic)$\backslash$r0092-8674 (Linking)},
issn = {10974172},
journal = {Cell},
number = {2},
pages = {456--492},
pmid = {26451489},
title = {{Reconstruction and Simulation of Neocortical Microcircuitry}},
volume = {163},
year = {2015}
}
@article{OReilly2014,
abstract = {We present a comprehensive, novel framework for understanding how the neocortex, including the thalamocortical loops through the deep layers, can support a temporal context representation in the service of predictive learning. Many have argued that predictive learning provides a compelling, powerful source of learning signals to drive the development of human intelligence: if we constantly predict what will happen next, and learn based on the discrepancies from our predictions (error-driven learning), then we can learn to improve our predictions by developing internal representations that capture the regularities of the environment (e.g., physical laws governing the time-evolution of object motions). Our version of this idea builds upon existing work with simple recurrent networks (SRN's), which have a discretely-updated temporal context representations that are a direct copy of the prior internal state representation. We argue that this discretization of temporal context updating has a number of important computational and functional advantages, and further show how the strong alpha-frequency (10hz, 100ms cycle time) oscillations in the posterior neocortex could reflect this temporal context updating. We examine a wide range of data from biology to behavior through the lens of this LeabraTI model, and find that it provides a unified account of a number of otherwise disconnected findings, all of which converge to support this new model of neocortical learning and processing. We describe an implemented model showing how predictive learning of tumbling object trajectories can facilitate object recognition with cluttered backgrounds.},
archivePrefix = {arXiv},
arxivId = {1407.3432},
author = {O'Reilly, Randall C. and Wyatte, Dean and Rohrlich, John},
eprint = {1407.3432},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/O'Reilly, Wyatte, Rohrlich/2014/Learning Through Time in the Thalamocortical Loops.pdf:pdf},
keywords = {review{\_}neurophis},
mendeley-tags = {review{\_}neurophis},
month = {jul},
title = {{Learning Through Time in the Thalamocortical Loops}},
url = {http://arxiv.org/abs/1407.3432},
year = {2014}
}
@article{Cadieu2014,
abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise, the number of neural recording sites, and the number trials, and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
archivePrefix = {arXiv},
arxivId = {1406.3284},
author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L. K. and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan a. and Majaj, Najib J. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.1003963},
eprint = {1406.3284},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cadieu et al/2014/Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition.pdf:pdf},
issn = {15537358},
journal = {Arxiv},
number = {12},
pages = {35},
pmid = {25521294},
title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
url = {http://arxiv.org/abs/1406.3284},
volume = {10},
year = {2014}
}
@article{Miller2001,
author = {Miller, Earl K and Cohen, Jonathan D},
doi = {10.1146/annurev.neuro.24.1.167},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Miller, Cohen/2001/An Integrative Theory of Prefrontal Cortex Function.pdf:pdf},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {attention,cognition,cortex has long been,executive control,frontal lobes,has remained a mystery,here,however,important role,in accordance with,in cognitive control,in the ability to,internal goals,its neural basis,orchestrate thought and action,s abstract the prefrontal,suspected to play an,we propose,working memory},
month = {mar},
number = {1},
pages = {167--202},
title = {{An Integrative Theory of Prefrontal Cortex Function}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.24.1.167},
volume = {24},
year = {2001}
}
@article{Funamizu2016,
abstract = {Simultaneous Localization and Mapping (SLAM)consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications, and witnessing a steady transition of this technology to industry. We survey the current state of SLAM. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?},
archivePrefix = {arXiv},
arxivId = {1606.05830},
author = {Funamizu, Akihiro and Kuhn, Bernd and Doya, Kenji},
doi = {10.1038/nn.4390},
eprint = {1606.05830},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Funamizu, Kuhn, Doya/2016/Neural substrate of dynamic Bayesian inference in the cerebral cortex.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {July},
pages = {1--26},
pmid = {27643432},
title = {{Neural substrate of dynamic Bayesian inference in the cerebral cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.4390},
volume = {19},
year = {2016}
}
@unpublished{Project2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02142v1},
author = {Billaudelle, Sebastian and Ahmad, Subutai},
eprint = {arXiv:1505.02142v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Billaudelle, Ahmad/2015/Porting HTM Models to the Heidelberg Neuromorphic Computing Platform.pdf:pdf},
pages = {1--10},
title = {{Porting HTM Models to the Heidelberg Neuromorphic Computing Platform}},
year = {2015}
}
@article{Roland2010,
abstract = {A fundamental goal in vision science is to determine how many neurons in how many areas are required to compute a coherent interpretation of the visual scene. Here I propose six principles of cortical dynamics of visual processing in the first 150 ms following the appearance of a visual stimulus. Fast synaptic communication between neurons depends on the driving neurons and the biophysical history and driving forces of the target neurons. Under these constraints, the retina communicates changes in the field of view driving large populations of neurons in visual areas into a dynamic sequence of feed-forward communication and integration of the inward current of the change signal into the dendrites of higher order area neurons (30-70 ms). Simultaneously an even larger number of neurons within each area receiving feed-forward input are pre-excited to sub-threshold levels. The higher order area neurons communicate the results of their computations as feedback adding inward current to the excited and pre-excited neurons in lower areas. This feedback reconciles computational differences between higher and lower areas (75-120 ms). This brings the lower area neurons into a new dynamic regime characterized by reduced driving forces and sparse firing reflecting the visual areas interpretation of the current scene (140 ms). The population membrane potentials and net-inward/outward currents and firing are well behaved at the mesoscopic scale, such that the decoding in retinotopic cortical space shows the visual areas' interpretation of the current scene. These dynamics have plausible biophysical explanations. The principles are theoretical, predictive, supported by recent experiments and easily lend themselves to experimental tests or computational modeling.},
author = {Roland, Per E},
doi = {10.3389/fnsys.2010.00028},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Roland/2010/Six principles of visual cortical dynamics.pdf:pdf},
isbn = {ISSN 1662-5137},
issn = {16625137},
journal = {Frontiers in Systems Neuroscience},
keywords = {coher-,cortical theory,ent view of cortical,failed to give a,feedback,functions and visual perception,inter-area communication,laminar firing,may be both,membrane potential,object motion,object vision,scientists so far have,the reasons that visual,voltage-sensitive dyes},
pages = {28},
pmid = {20661451},
title = {{Six principles of visual cortical dynamics}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2010.00028/abstract},
volume = {4},
year = {2010}
}
@phdthesis{George2008,
author = {George, Dileep},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George/2008/How the Brain Might Work a Hierarchical and Temporal Model for Learning and Recognition.pdf:pdf},
number = {June},
pages = {191},
school = {Stanford University},
title = {{How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition}},
year = {2008}
}
@article{Gallese1996,
author = {Gallese, Vittorio and Fadiga, Luciano and Fogassi, Leonardo and Rizzolatti, Giacomo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Gallese et al/1996/Action recognition in the premotor cortex.pdf:pdf},
journal = {Brain},
keywords = {action encoding,macaque monkey,premotor cortex,visual responses},
number = {5},
pages = {593--609},
title = {{Action recognition in the premotor cortex}},
volume = {119},
year = {1996}
}
@inproceedings{Rao2005,
author = {Rao, A. Ravishankar and Cecchi, Guillermo and Peck, Charles and Kozloski, James},
booktitle = {Proc. SPIE},
doi = {10.1117/12.585526},
editor = {Rogowitz, Bernice E. and Pappas, Thrasyvoulos N. and Daly, Scott J.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rao et al/2005/A model of the formation of a self-organized cortical representation of color.pdf:pdf},
issn = {0277786X},
month = {mar},
pages = {17},
title = {{A model of the formation of a self-organized cortical representation of color}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.585526},
year = {2005}
}
@phdthesis{Price2011a,
author = {Price, Ryan William},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Price/2011/Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Price/2011/Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures(2).pdf:pdf},
pages = {115},
school = {Portland State University},
title = {{Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures}},
year = {2011}
}
@article{Litvak2009,
abstract = {In this letter, we develop and simulate a large-scale network of spiking neurons that approximates the inference computations performed by graphical models. Unlike previous related schemes, which used sum and product operations in either the log or linear domains, the current model uses an inference scheme based on the sum and maximization operations in the log domain. Simulations show that using these operations, a large-scale circuit, which combines populations of spiking neurons as basic building blocks, is capable of finding close approximations to the full mathematical computations performed by graphical models within a few hundred milliseconds. The circuit is general in the sense that it can be wired for any graph structure, it supports multistate variables, and it uses standard leaky integrate-and-fire neuronal units. Following previous work, which proposed relations between graphical models and the large-scale cortical anatomy, we focus on the cortical microcircuitry and propose how anatomical and physiological aspects of the local circuitry may map onto elements of the graphical model implementation. We discuss in particular the roles of three major types of inhibitory neurons (small fast-spiking basket cells, large layer 2/3 basket cells, and double-bouquet neurons), subpopulations of strongly interconnected neurons with their unique connectivity patterns in different cortical layers, and the possible role of minicolumns in the realization of the population-based maximum operation.},
author = {Litvak, Shai and Ullman, Shimon},
doi = {10.1162/neco.2009.05-08-783},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Litvak, Ullman/2009/Cortical circuitry implementing graphical models.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
number = {11},
pages = {3010--3056},
pmid = {19686065},
title = {{Cortical circuitry implementing graphical models}},
volume = {21},
year = {2009}
}
@inproceedings{Rohrbein2007,
author = {Rohrbein, Florian and Eggert, Julian and Korner, Edgar},
booktitle = {ICCM-2007-Eighth International Conference on Cognitivy Modeling},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rohrbein, Eggert, Korner/2007/Prototypical Relations for Cortex-Inspired Semantic Representations.pdf:pdf},
keywords = {biologically,columnar-like nodes and do,cortical column,detailed modeling of the,knowledge representation,not target at a,relational structures,single cortical column,the},
pages = {307--312},
title = {{Prototypical Relations for Cortex-Inspired Semantic Representations}},
year = {2007}
}
@article{Izhikevich2008,
abstract = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging (DTI) of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic STDP). The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
author = {Izhikevich, Eugene M. and Edelman, Gerald M.},
doi = {10.1073/pnas.0712231105},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Izhikevich, Edelman/2008/Large-scale model of mammalian thalamocortical systems.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Animals,Biological,Brain,Brain: anatomy {\&} histology,Cats,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Computer Simulation,Humans,Mammals,Models,Neurological,Neurons,Synapses,Thalamic Nuclei,Visual Cortex,Visual Cortex: anatomy {\&} histology,review{\_}neurophis},
mendeley-tags = {review{\_}neurophis},
number = {9},
pages = {3593--8},
pmid = {18292226},
title = {{Large-scale model of mammalian thalamocortical systems}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2265160{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2008}
}
@techreport{Cortical2014,
author = {Hawkins, Jeff and Ahmad, Subutai and Byrne, Fergal and Surpur, Chetan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hawkins et al/2014/Hierarchical Temporal Memory including HTM Cortical Learning Algorithms.pdf:pdf},
institution = {Numenta},
pages = {62},
title = {{Hierarchical Temporal Memory including HTM Cortical Learning Algorithms}},
url = {numenta.org},
year = {2014}
}
@article{Rinkus2010,
abstract = {No generic function for the minicolumn - i.e., one that would apply equally well to all cortical areas and species - has yet been proposed. I propose that the minicolumn does have a generic functionality, which only becomes clear when seen in the context of the function of the higher-level, subsuming unit, the macrocolumn. I propose that: (a) a macrocolumn's function is to store sparse distributed representations of its inputs and to be a recognizer of those inputs; and (b) the generic function of the minicolumn is to enforce macrocolumnar code sparseness. The minicolumn, defined here as a physically localized pool of approximately 20 L2/3 pyramidals, does this by acting as a winner-take-all (WTA) competitive module, implying that macrocolumnar codes consist of approximately 70 active L2/3 cells, assuming approximately 70 minicolumns per macrocolumn. I describe an algorithm for activating these codes during both learning and retrievals, which causes more similar inputs to map to more highly intersecting codes, a property which yields ultra-fast (immediate, first-shot) storage and retrieval. The algorithm achieves this by adding an amount of randomness (noise) into the code selection process, which is inversely proportional to an input's familiarity. I propose a possible mapping of the algorithm onto cortical circuitry, and adduce evidence for a neuromodulatory implementation of this familiarity-contingent noise mechanism. The model is distinguished from other recent columnar cortical circuit models in proposing a generic minicolumnar function in which a group of cells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of the sparse distributed macrocolumnar code.},
author = {Rinkus, Gerard J},
doi = {10.3389/fnana.2010.00017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Rinkus/2010/A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in neuroanatomy},
keywords = {learning,macrocolumn,memory,minicolumn,novelty detection,population coding,sparse distributed representations,winner-take-all},
number = {June},
pages = {17},
pmid = {20577587},
title = {{A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2889687{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/George, Hawkins/2009/Towards a mathematical theory of cortical micro-circuits.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Markov Chains,Memory,Memory: physiology,Models,Neurological,Pattern Recognition,Pyramidal Cells,Pyramidal Cells: physiology},
number = {10},
pages = {e1000532},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2749218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@inproceedings{Dura-Bernal2011,
author = {Dura-Bernal, Salvador and Wennekers, Thomas and Denham, Susan L.},
booktitle = {45th Annual Conference on Information Sciences and Systems},
doi = {10.1109/CISS.2011.5766096},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Dura-Bernal, Wennekers, Denham/2011/Modelling object perception in cortex Hierarchical Bayesian networks and belief propagation.pdf:pdf},
isbn = {978-1-4244-9846-8},
keywords = {bayesian belief propagation,hierarchical percep-},
pages = {1--6},
publisher = {IEEE},
title = {{Modelling object perception in cortex: Hierarchical Bayesian networks and belief propagation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5766096},
year = {2011}
}
@techreport{Hawkins2011,
author = {Hawkins, Jeff and Ahmad, Subutai and Dubinsky, Donna},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hawkins, Ahmad, Dubinsky/2011/Hiearachical Temporal Memory including HTM Cortical Learning Algorithms.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Hawkins, Ahmad, Dubinsky/2011/Hiearachical Temporal Memory including HTM Cortical Learning Algorithms(2).pdf:pdf},
institution = {Numenta},
pages = {1--68},
title = {{Hiearachical Temporal Memory including HTM Cortical Learning Algorithms}},
year = {2011}
}
@article{VandenHeuvel2013,
abstract = {The human brain shows several characteristics of an efficient communication network architecture, including short communication paths and the existence of modules interlinked by a small set of highly connected regions. Studies of structural networks comprising macroscopic white matter projections have shown that these putative hubs are densely interconnected, giving rise to a spatially distributed and topologically central collective called the “rich club.” In parallel, studies of intrinsic brain activity have consistently revealed distinct functional communities or resting-state networks (RSNs), indicative of specialized processing and segregation of neuronal information. However, the pattern of structural connectivity interconnecting these functional RSNs and how such inter-RSN structural connections might bring about functional integration between RSNs remain largely unknown. Combining high-resolution diffusion weighted imaging with resting-state fMRI, we present novel evidence suggesting that the rich club structure plays a central role in cross-linking macroscopic RSNs of the human brain. Rich club hub nodes were present in all functional networks, accounted for a large proportion of “connector nodes,” and were found to coincide with regions in which multiple networks overlap. In addition, a large proportion of all inter-RSN connections were found to involve rich club nodes, and these connections participated in a disproportionate number of communication paths linking nodes in different RSNs. Our findings suggest that the brain's rich club serves as a macroscopic anatomical substrate to cross-link functional networks and thus plays an important role in the integration of information between segregated functional domains of the human cortex.},
author = {van den Heuvel, M. P. and Sporns, O.},
doi = {10.1523/JNEUROSCI.2128-13.2013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/van den Heuvel, Sporns/2013/An Anatomical Substrate for Integration among Functional Networks in Human Cortex.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {36},
pages = {14489--14500},
title = {{An Anatomical Substrate for Integration among Functional Networks in Human Cortex}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2128-13.2013},
volume = {33},
year = {2013}
}
