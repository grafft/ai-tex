Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Schein2015,
abstract = {We present a Bayesian tensor factorization model for inferring latent group structures from dynamic pairwise interaction patterns. For decades, political scientists have collected and analyzed records of the form “country i took action a toward country j at time t”—known as dyadic events—in order to form and test theories of international relations. We represent these event data as a tensor of counts and develop Bayesian Poisson tensor factorization to infer a lowdimensional, interpretable representation of their salient patterns. We demonstrate that our model's predictive performance is better than that of standard non-negative tensor factorization methods. We also provide a comparison of our variational updates to their maximum likelihood counterparts. In doing so, we identify a better way to form point estimates of the latent factors than that typically used in Bayesian Poisson matrix factorization. Finally, we showcase our model as an exploratory analysis tool for political scientists. We show that the inferred latent factor matrices capture interpretable multilateral relations that both conform to and inform our knowledge of international affairs.},
archivePrefix = {arXiv},
arxivId = {1506.03493},
author = {Schein, Aaron and Paisley, John and Blei, David M and Wallach, Hanna},
doi = {10.1145/2783258.2783414},
eprint = {1506.03493},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining/Schein et al/Schein et al. - 2015 - Bayesian Poisson Tensor Factorization for Inferring Multilateral Relation.pdf:pdf},
isbn = {9781450336642},
issn = {9781450336642},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {all or part of,bayesian inference,dyadic data,international relations,or hard copies of,permission to make digital,poisson tensor factorization,this work for per-},
pages = {1045--1054},
title = {{Bayesian Poisson Tensor Factorization for Inferring Multilateral Relations from Sparse Dyadic Event Counts}},
url = {http://www.cs.columbia.edu/{~}blei/papers/ScheinPaisleyBleiWallach2015.pdf},
year = {2015}
}
@article{Andrychowicz2016a,
abstract = {In this paper, we propose and investigate a novel memory architecture for neural networks called Hierarchical Attentive Memory (HAM). It is based on a binary tree with leaves corresponding to memory cells. This allows HAM to perform memory access in O(log n) complexity, which is a significant improvement over the standard attention mechanism that requires O(n) operations, where n is the size of the memory. We show that an LSTM network augmented with HAM can learn algorithms for problems like merging, sorting or binary searching from pure input-output examples. In particular, it learns to sort n numbers in time O(n log n) and generalizes well to input sequences much longer than the ones seen during the training. We also show that HAM can be trained to act like classic data structures: a stack, a FIFO queue and a priority queue.},
archivePrefix = {arXiv},
arxivId = {1602.03218},
author = {Andrychowicz, Marcin and Kurach, Karol},
eprint = {1602.03218},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/International Conference on Machine Learning (ICML)/Andrychowicz, Kurach/Andrychowicz, Kurach - 2016 - Learning Efficient Algorithms with Hierarchical Attentive Memory.pdf:pdf},
journal = {International Conference on Machine Learning (ICML)},
keywords = {ICML,attention,machine learning},
title = {{Learning Efficient Algorithms with Hierarchical Attentive Memory}},
url = {http://arxiv.org/abs/1602.03218},
year = {2016}
}
@book{Bishop2006,
author = {Bishop, Christopher M},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Bishop/Bishop - 2006 - Pattern Recognition and Machine Learning.pdf:pdf},
pages = {758},
publisher = {Springer},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@article{Kleyko2017a,
abstract = {This article proposes the use of Vector Symbolic Architectures for implementing Hierarchical Graph Neuron, an architecture for memorizing patterns of generic sensor stimuli. The adoption of a Vector Symbolic representation ensures a one-layered design for the approach, while maintaining the previously reported properties and performance characteristics of Hierarchical Graph Neuron, and also improving the noise resistance of the architecture. The proposed architecture enables a linear (with respect to the number of stored entries) time search for an arbitrary sub-pattern.},
archivePrefix = {arXiv},
arxivId = {1501.03784},
author = {Kleyko, Denis and Osipov, Evgeny and Senior, Alexander and Khan, Asad I. and Şekercioǧlu, Yaşar Ahmet},
doi = {10.1109/TNNLS.2016.2535338},
eprint = {1501.03784},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/IEEE Transactions on Neural Networks and Learning Systems/Kleyko et al/Kleyko et al. - 2017 - Holographic Graph Neuron A Bioinspired Architecture for Pattern Processing.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Associative memory (AM),holographic graph neuron (HoloGN),hyperdimensional computing,pattern recognition,vector symbolic architectures (VSAs)},
number = {6},
pages = {1250--1252},
title = {{Holographic Graph Neuron: A Bioinspired Architecture for Pattern Processing}},
volume = {28},
year = {2017}
}
@unpublished{Romanenko2014,
abstract = {В работе рассматривается применение аппарата условных случайных (CRF) полей к двум задачам обработки естественного языка: выделению временн´ ых выражений и нормализации цифровой записи числительных. Для решения этих задач применяется линейная модель CRF. Также в работе предлагается способ модификации линейной модели CRF для задач разметки последовательностей некоторого специального вида. Прове- дено сравнение модифицированной и классической моделей на примере задачи нормализации цифровой записи числительного.},
author = {Романенко, Александр Александрович},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Романенко/Романенко - 2014 - Применение условных случайных полей в задачах обработки текстов на естественном языке.pdf:pdf},
language = {russian},
pages = {27},
title = {{Применение условных случайных полей в задачах обработки текстов на естественном языке}},
year = {2014}
}
@article{Tamar2016,
abstract = {We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.},
archivePrefix = {arXiv},
arxivId = {1602.02867},
author = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
eprint = {1602.02867},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/arXiv/Tamar et al/Tamar et al. - 2016 - Value Iteration Networks.pdf:pdf},
journal = {arXiv},
month = {feb},
pages = {1--14},
title = {{Value Iteration Networks}},
url = {http://arxiv.org/abs/1602.02867},
year = {2016}
}
@article{Hochreiter2001,
author = {Hochreiter, Sepp and Younger, A Steven and Conwell, Peter R},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Unknown/Hochreiter, Younger, Conwell/Hochreiter, Younger, Conwell - 2001 - Learning to Learn Using Gradient Descent.pdf:pdf},
pages = {87--94},
title = {{Learning to Learn Using Gradient Descent}},
year = {2001}
}
@article{Sutton2010,
abstract = {Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.},
archivePrefix = {arXiv},
arxivId = {1011.4088},
author = {Sutton, Charles and McCallum, Andrew},
eprint = {1011.4088},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/arXiv/Sutton, McCallum/Sutton, McCallum - 2010 - An Introduction to Conditional Random Fields.pdf:pdf},
journal = {arXiv},
month = {nov},
title = {{An Introduction to Conditional Random Fields}},
url = {http://arxiv.org/abs/1011.4088},
year = {2010}
}
@article{Kleyko2016,
abstract = {This article presents a modification of the recently proposed Holographic Graph Neuron approach for memorizing patterns of generic sensor stimuli. The original approach represents patterns as dense binary vectors, where zeros and ones are equiprobable. The presented modification employs sparse binary distributed representations where the number of ones is less than zeros. Sparse representations are more biologically plausible because activities of real neurons are sparse. Performance was studied comparing approaches for different sizes of dimensionality.},
author = {Kleyko, Denis and Osipov, Evgeny and Rachkovskij, Dmitri A.},
doi = {10.1016/j.procs.2016.07.404},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Procedia Computer Science/Kleyko, Osipov, Rachkovskij/Kleyko, Osipov, Rachkovskij - 2016 - Modification of Holographic Graph Neuron Using Sparse Distributed Representations.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {hyperdimensional computing,sparse distributed representation},
pages = {39--45},
publisher = {The Author(s)},
title = {{Modification of Holographic Graph Neuron Using Sparse Distributed Representations}},
url = {http://dx.doi.org/10.1016/j.procs.2016.07.404},
volume = {88},
year = {2016}
}
@article{Wiering1997,
author = {Wiering, M. and Schmidhuber, J.},
doi = {10.1177/105971239700600202},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Adaptive Behavior/Wiering, Schmidhuber/Wiering, Schmidhuber - 1997 - HQ-Learning.pdf:pdf},
isbn = {1059712397006},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {hierarchical q-learning,non-markov,pomdps,reinforcement learning,subgoal learning},
number = {2},
pages = {219--246},
title = {{HQ-Learning}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/105971239700600202},
volume = {6},
year = {1997}
}
@article{Kleyko2017,
abstract = {Modality corresponding to medical images is a vital filter in medical image retrieval systems. This article presents the classification of modalities of medical images based on the usage of principles of hyper-dimensional computing and reservoir computing. It is demonstrated that the highest classification accuracy of the proposed method is on a par with the best classical method for the given dataset (83{\%} vs. 84{\%}). The major positive property of the proposed method is that it does not require any optimization routine during the training phase and naturally allows for incremental learning upon the availability of new training data},
author = {Kleyko, Denis and Khan, Sumeer and Osipov, Evgeny and Yong, Suet Peng},
doi = {10.1109/ISBI.2017.7950697},
file = {:C$\backslash$:/Users/panov/Documents/Mendeley Desktop/Proceedings - International Symposium on Biomedical Imaging/Kleyko et al/Kleyko et al. - 2017 - Modality classification of medical images with distributed representations based on cellular automata reservoir.pdf:pdf},
isbn = {9781509011711},
issn = {19458452},
journal = {Proceedings - International Symposium on Biomedical Imaging},
keywords = {Classification,Machine learning},
pages = {1053--1056},
title = {{Modality classification of medical images with distributed representations based on cellular automata reservoir computing}},
year = {2017}
}
